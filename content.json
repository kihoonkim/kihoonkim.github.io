{"meta":{"title":"KihoonKim:Dev","subtitle":"Tech note","description":null,"author":"Kihoon Kim","url":"https://kihoonkim.github.io"},"pages":[],"posts":[{"title":"지난 10년. 어떤 기술 흐름속에 살았을까?","slug":"retro/10-years","date":"2021-08-15T15:00:00.000Z","updated":"2021-08-17T00:04:32.704Z","comments":true,"path":"2021/08/16/retro/10-years/","link":"","permalink":"https://kihoonkim.github.io/2021/08/16/retro/10-years/","excerpt":"","text":"8/16. 입사한지 딱 10년이 되었다. 대학생 때 프로그래밍 이라는 것을 접하기 시작한 이후 지금까지 지난 14년이 넘는 기간동안 어떤 기술의 변화 속에서 지내왔는지 정리 해 보려고 한다.각 기술은 개인적으로 접하기 시작한 시점으로 실제 유행했던 시기와 조금 다를 수는 있다. 대학(~ 2011)일단 나는 어려서 부터 코딩을 시작하거나 컴퓨터에 관심이 많지는 않았다.컴퓨터를 전공 했지만, 솔직히 무엇을 배우는지 모르고 입학을 했고, 그져 기술을 배우기위해 공대를 가자는 마음이었던 것 같다.지금 처럼 누구나 손에 컴퓨터 한대씩 들고 있는 시대도 아니었다. 당연히 컴퓨터 관련된 모든 것이 처음이었다.a = a + b 와 a += b 가 같다는 기괴한 프로그래밍 언어의 벽에 막혀서 적응을 못했던것 같다. 사실 변수라는 개념 부터가 어려웠다. 1+2=3 이 올바른 식이 아닌가!?!대학교 때를 생각해 보면 누군가는 해킹 대회에서 우승을 하거나 ACM 에 입상을 하고, 심지어 중고등학교 때부터 게임개발로 유명했던 사람들도 있었던 것 같다.언제나 이세계는 천재들이 존재하는 것 같았다. 프로그래밍 언어그래서 나는 프로그래밍 언어를 배우고 간단히 눈에 보이는 뭔가를 만들어 보는데 시간을 썼던 것 같다.c, c++, java, c# 을 공부했던 것 같고, 객체지향 언어에 빠져서 java와 c#을 주로 사용했었다. 웹 개발 보다는 Swing, WPF 로 윈도우 프로그래밍을 주로 했었다. 선배들 회사에서 개발 알바하는 친구들을 봤을 때, 이당시 현업에서는 php 를 많이 사용했던 것 같다. LAMP (linux, apache, mysql, php) 이라는 말을 사용했던 기억이 있다.연구실에서 프로젝트를 할 때는 EJB 라는 것을 사용했던 것 같고, java를 좋아하던 동기들 사이에서는 Spring 을 공부해 보자는 이야기도 나왔었다. 모바일 개발피처폰 시절에도 모바일 개발자는 있었을 것이다. 하지만 대중적이지 않고 일부 개발자들 만의 어려운 분야였다.아마도 2009년 쯤에 안드로이드 마켓(현재 플레이 스토어)이 국내에 들어오면서 모바일 개발 붐이 일어나기 시작했던 것 같다. 아이폰이 먼저 출시 됐지만, 안드로이드 개발이 더 유행했 던 걸 보면 역시 우리나라는 java 개발이 주를 이뤘던 것 같다. c# 과 .net 개발을 좋아해서 윈도우 폰 개발을 해보겠다고 2010년에 옴니아2 를 거의 100만원을 주고 샀던 기억이 있다. 당시 말이 많던 폰이긴 했지만, 이걸로 MS에서 열리는 이매진 컵에도 나가보고 후회는 하지 않는다……….. 회사(2011 ~)주변 동기나 선배들은 전자 쪽으로 취업을 많이 했다. 아마도 모바일 개발 쪽을 많이 갔던 것 같다. 난 소프트웨어 공학 쪽에 관심이 있었고, 무엇보다 서울에서 근무를 하고 싶었다. 그래서 SDS 로 입사를 하기로 했다. 2011년 8월에 소프트웨어 엔지니어링 팀으로 입사를 하고 3개월 간 길고 긴 신입사원 교육을 받았다.이 때 주로 받았던 교육은 servlet/jsp, java, spring, oracle db, svn, 방법론(waterfall, agile) 등 이었다.신입사원 교육때 배우는 내용들은 그 회사에서 가장 많이 사용하는 기술 일 것이다.아마도 회사내 거의 대부분 java, spring, oracle db 를 사용했을 것 같다.하지만 이때 배운 jsp 는 지금까지 단 한번도 써본적이 없다. servlet 은 spring 공부할 때 도움이 되긴했지만.. 2011-13: 첫 3년입사 후 첫 3년 간 SI 라는 일을 했다. 일반 사용자가 아니라 회사에서 쓰는 업무 시스템을 주로 개발하는 일이다. (대부분의 개발자들이 SDS 하면 떠올리는 일이고 아직도 SI 회사라는 인식이 강한 것 같다.)SI 개발자를 풀스택이라고 부르기는 애매하지만 화면개발, 서버개발, db 설계 까지 다 해야 하는 것을 보면 분명 쉽지 않은 일은 맞는 것 같다. 이 때 주로 사용하던 기술은 화면개발은 miplatform, jquery, 서버 개발은 spring, mybatis, oracle db 를 사용했다. 형상관리는 svn 빌드는 jenkins 를 사용했던 기억이 난다.이때를 생각해 보면 frontend 개발자라는 말은 없었다. Publisher 라는 css만 전문적으로 해주던 역할자 분이 있었던 것 같기는 하다.화면개발시 html, css나 web에 대한 지식이 깊을 필요는 없었다. 그냥 DB에서 필요한 데이터를 원하는 시간안에 잘 가져와서 테이블 형식으로 보여주고 검색을 할 수 있으면 되는 것이었다. 그래서 그냥 UI 개발 혹은 화면개발 이라는 표현을 사용했었다.DB 모델링 잘 하고 SQL을 효율적으로 잘 작성하는 것이 실력있는 개발자 였다. 프레임워크나 기술적으로 어려운 개발은 몇몇 아키텍트나 공통팀 개발자들의 몫이 었다. 나머지 개발자 들은 비즈니스 로직을 작성하거나 SQL 을 짜는 것이 대부분 이었다. 그래서 개발자의 위상이 그리 높지는 않았 던 것 같다. 반면 회사 밖에서는 Web이 주목받고 급격하게 발전하기 시작하고 있던 시기였다.TGIF 라는 트위터, 구글, 아이폰, 페이스북 이라는 신조어가 생기기도 했고, 국내에는 네이버, 다음, 카카오 등의 기업 들이 엄청나게 성장 해 나가는 시기로 기억된다. 국내외로 이런 인터넷 기업들이 성장하면서 웹 생태계를 크게 발전시키는데 기여 했던 것 같다. 회사내 많은 개발자들이 SQL과 스프링에서 벗어나 HTML5, jquery, ajax 등 프론트엔드 기술을 공부하기 시작했고, javascript 도 그저 dom 언어가 아닌 하나의 독립적인 언어로 인정해주기 시작했다. 개인적으로 느끼기에 본격적으로 웹의 위상이 높아지고 frontend 개발이 중요해 지는 시기 였다고 생각된다.Angular.js를 포함해서 웹 MVC 를 지원하는 많은 라이브러리 들이 나오기 시작했고, SPA(single page application) 나 Client-side render 기술이 발전하기 시작했다. 브라우저는 필요한 코드를 모두 받아와야 했기 때문에, 압축, 번들링 등의 기술이 같이 발전하기 시작했다.웹기술이 그져 정보를 표현하는 웹 페이지의 개념에서 사용자 경험을 중시하는 시대로 발전해 나가고 있는 것이었다. 이때쯤 회사에 UX팀이 생겼던 것 같다. 수많은 프레임워크 들이 생기고 없어지기를 반복하고, 그러면서 동시에 많은 커뮤니티 들도 생겨 났던 것 같다. 너무 많고 빠른 발전에 춘추전국시대가 펼쳐진 것 같았다.ember, backbone, ext, angular 등등수많은 웹 프레임워크 들이 나오고 덩달아 Todo app 들이 생겨나기 시작했었다.사실 이쯤되니 따라갈 엄두가 나지 않았던 것 같다. 2013: SI 사업 철수회사에서 더이상 공공, 금융 SI 사업을 하지 않기로 선언했다. 어쩐 이유였는지는 모르겠지만, 솔루션을 만드는 회사가 되기로 한 것 이었다. 진짜로 SI 를 접었는지, 회사 전체를 알 수는 없지만, 개인적으로는 이때 이후로 SI 를 해본적은 없다. 어찌됐든 덕분에 개발자들은 더이상 고객이 원하는 고정된 기술 스택을 고집할 이유가 없었다. 개발자들 사이에 우리도 이제 새로운 트렌드를 따라가자는 노력이 많이 나타났다.이당시 회사내에서 Angular.js나 React.js 스터디 그룹이 꽤 생겼던 것 같다. 이미 빠른 곳은 jsp 로 만들어진 제품을 내부만 React.js로 다시 만들었다더라.. 는 이야기들이 들려 오곤 했다.개인적으로 그당시 관심을 가졌던 건 MEAN stack(MongoDB, Express, Angular, Node) 이었다. 아마도 그 당시에 가장 활성화 된 커뮤니티가 아니었을까 싶다. 2014: 솔루션 사업?솔루션 사업이 라는 게 시장을 만들고 제품을 팔아야 돈이 되는 것이다. 즉 팔리기 전까지는 아껴야 잘 살 수 있었다.회사 입장에서도 기존 oracle, ibm 을 계속 사용하기에는 부담이었을 것이다.그래서 오픈소스를 사용하자는 움직임이 생기기 시작했다. 제일 먼저 mariadb, postgresql, mongodb, elasticsearch 등 다양한 오픈소스 데이터베이스를 사용하려는 시도가 있었다. REST api사실 개발 스택은 jquery, spring 에서 크게 달라지지는 않았었다. 하지만 제일 크게 바뀐것은 REST API 였다.기존에 *.do 패턴 (&lt; url-pattern&gt;*.do&lt;/ url-pattern&gt;) 으로 구현하던 것에서 rest api 로 바뀐 것이었다. openapi 로 만들고 재사용하려는 목적도 일부 있었겠지만, 데이터를 하나의 리소스로 바라보고 api 로 만듦으로써 데이터와 UI 를 분리하기 위함이었다.기존에는 화면 한 페이지가 하나의 controller-service-repository-sql 에 강하게 결합되어 있었다면, 이제는 UI에서 원하는 리소스를 호출하고 조합해서 새로운 UI 를 만들 수 있게 된 것이다.이로써 프론트엔드와 백엔드 개발을 나눌 수 있게 되었다. 2015년 트렌드14년 말 겨울에 사내 메신저로 많이 주고 받았던 질문이 있다.“마이크로서비스라고 들어본적 있어요?”난 임백준 님의 글에서 처음 봤는데 대부분 여기나 마틴파울러의 글에서 시작되었을 것 같다.이후에 회의실을 지나다보면 많은 곳의 빔 프로젝트에서 마틴파울러의 msa 글을 여러사람이 함께 보는 모습을 볼 수 있었다. 하지만 굉장히 추상적이고 실제 구현에 대한 이야기가 많지 않아서 이해하기엔 쉽지 않았던것 같다.이때만 해도 많은 사람들이 MSA가 그냥 짧은 유행으로 그칠 것이라고 생각했었다. 트랜젝션으로 강하게 묶여 있던 당시 개발 패턴으로는 이해하기 어려운 아키텍쳐였다.하지만 스마트폰 사용이 늘어나고 여러 장비들에 IoT 가 작용되면서 서버 입장에서 트래픽을 예측하고 감당하기 어려워 졌다. 자원을 효율적으로 사용할 필요가 생겼고 scale up/down 에서 scale in/out 의 시대로 변하고 있는 것이었다. 2015: docker 란 무엇인가?docker컨테이너 기술을 이해하기 위해 많은 사람들이 애를 썼던 것 같다. 지금이야 vm 위에 컨테이너가 실행되는 개념을 당연하게 받아 들이고 있지만 그당시만 해도 왜? 라는 질문이 많았다. 가상화 기술이 유행하던 시기라 많은 사람들이 굳이 그 위에 컨테이너까지 올려야 하는 지 의문을 가졌었다.그래서 docker를 어디에 어떻게 써야하는지 보다는 namespace, cgroups 등 원리가 무엇인지를 이해하는데 많은 시간을 투자했다.그도 그럴것이 대부분의 시스템이 하나의 모놀리식 애플리케이션이 었고 statefull 했다. 아마도 90% 이상 apache tomcat 위에서 실행되고 있었을 것이다.이러한 거대한 한 덩어리의 앱을 컨테이너로 굳이 올려야 될까? 잘 돌아간다는 보장도 없고, 조금이지만 네트워크 성능도 느려진다는데? SaaS &amp; MSA솔루션을 설치형이 아닌 SaaS로 만들자는 이야기가 나왔다. SaaS라고 해서 거창하게 들리겠지만 그냥 쉽게 말해서 웹을 클라우드에 배포해서 일반 사용자나 테넌트가 접속할 수 있게 만들자는 것이었다. 멀티테넌트 개념을 빼면 일반 웹 개발과 다를게 없었다. 그럼 SaaS를 위한 아키텍처는 뭐가 좋을까? 그 아키텍처가 실행될 인프라는 어떤것이 좋을 까? 에서 많은 것들이 시작됐다. 여기 저기에서 msa 를 공부하고 docker 관련 세미나가 열렸다. 해외의 유명한 분을 데려와서 한달짜리 교육을 만들어 듣기도 했다. 아키텍처랩에 있었을 때 솔루션을 MSA 구조로 바꿔서 Docker 위에 올리는 PoC를 진행하려고 했었다. 하지만 여기 저기 문을 두드려 봤지만 선뜻 나서는 팀은 없었다. 사실 이제와서 이야기 지만, 모든 로직이 db procedure와 sql 에 얽혀서 들어가 있는데.. 그 당시의 지식으로는 msa 로 나눌 자신은 없었다.그리고 그때는 몰랐다. 개발 문화, 빌드, 배포 방식 등등 정말 많은 것을 바꿔야 한다는 것을.. 클라우드와 MSA 가 유행하면서 수많은 버즈워드가 생겨 났던 것 같다. 아니면 이미 있던 개념들이 하나씩 퍼즐이 맞춰지 듯이 자연스레 연결된 것 일 수도 있다. cloud native application, 12factor, docker, msa, reactive system, reactive programming, functional programming,java8, spring boot, spring cloud… 수 많은 개념을 공부하고 이해하려고 노력해보니 결론은 서비스를 어떻게 stateless 하게 만들 것인가였다. git정신을 차리고 세상을 바라보니 엄청난 변화가 있었다. git과 github 이었다.지금이야 개발자라면 누구나 아는 상식 수준의 기술이지만 처음에는 쉽지 않았다. svn 으로 브랜치를 나누는 것은 매우 어렵고 비효율적 이었기 때문에 브랜치 전략이라는 것 자체가 매우 낯선 개념이었다.그리고 오픈소스 라는 것이 활성화되고 개발자들이 코드를 공유하고 서로의 프로젝트에 기여를 하고 있었다.사내에 gitlab 으로 만든 git 레파지토리가 생겼고 사내 표준 툴로 지정되기도 했었다. 2016: 애자일인공지능전세계적으로는 알파고 vs 이세돌의 영향으로 AI가 유행하기 시작했던 것 같다. 이 후로 유명한 뇌 과학자나 AI 관련 석학들을 모시고 세미나를 자주 열었던 것 같다.그 영향으로 많은 개발자들이 파이썬을 공부하거나 텐서플로우를 배우려고 했었다.개인적으로도 인공지능이나 빅데이터 분석 관련 교육을 받아 봤지만 실시간 빅데이터를 다룰 일이 없었어서 였는지 크게 흥미가 생기지는 않았었다. 알고리즘 테스트알파고 때문인지 개발자한테 알고리즘이 중요하다면서 회사에 소프트웨어 검정 시험이 생겼다.비슷한 시기에 다른 회사에서도 코딩테스트를 보는 곳이 많아졌다.자료구조에 대해서 더 고민하고 알고리즘을 공부 하는 것 까지는 좋은 일이 었지만 이것이 개발자의 능력을 판단하는 유일한 기준으로 삼은 것은 이해할 수 없었다.이당시 외부연사에게 하는 단골 질문이 ‘개발을 잘 하려면 알고리즘 잘해야 하나요?’ 였을 정도였다. 애자일, XP개인적으로는 ACT(Agile Core Team)로 팀을 옮기면서 애자일, TDD, 페어프로그래밍 등 XP 에 빠졌던 시기다.지난 몇년동안 기술적으로 아키텍처적으로는 많은 발전 이뤘다. 하지만 제품은 어떻게 만들어야 하고 팀은 어떻게 운영되어야 하는지 고민이 많았던 시기였다. 회사내 누군가는 ThoughtWorks에 교육을 받기도 했고, Pivotal labs에 직접가서 배워오기 했다.공통적인 내용은 PM, Designer, Dev 를 한팀으로 구성하고 Iteration 이라는 짧은 주기로 점진적으로 기능을 추가해 나가는 것이었다.무엇보다 사용자에게 가치있는 기능을 추가해 나가자는 것을 중요하게 여겼다.개발자들은 TDD, Pair programming, Simple design, small release 등 XP에서 많은 것들을 가져와서 실천했었다. AndroidACT로 팀을 옮기고 첫 번째 프로젝트는 안드로이드 앱 개발이었다. 당시 개발 버전이 마시멜로우 였던 것을 생각해 보면 모바일 개발을 늦게 시작하긴 했다.팀원 대부분도 안드로이드가 처음이었지만, 같이 스터디를 하면서 조금씩 배워 나갔던 것 같다. junit, robolectric 을 사용해서 TDD 로 진행했고, DI를 위해서 dagger2 도 사용했다. ci는 gocd를 사용했다.이때 훌륭한 팀원 분들께 안드로이드, 클린코드, TDD, CI/CD 등 정말 많은 것을 배운 것 같다. 무엇보다 페어프로그래밍을 통해서 피드백을 빠르게 자주 받으면서 개발자로서 뿐만 아니라 인간적으로도 많이 성장 할 수 있었던 것 같다. java8java8 이 2014년 쯤 나왔지만 실제 많이 쓰기 시작한 건 이때쯤 인 듯하다.Reactive Functional Programming 이 유행하면서 lambda function, stream api, CompletableFuture 등을 사용해서 개발하기 시작했던 것같다.토비님의 유튜브 방송에서 제너릭에서 시작해서 리액티브 스트림으로 이어지는 라이브 코딩이 올라왔었다. 덕분에 더 깊이 이해하고 쓸 수 있었던 것 같다. 2017: 새로운 언어reactjshtml, jquery 만 사용하다가 react.js를 통해 컴포넌트 기반 웹 개발을 처음 봤다. 사실 제대로된 웹 개발을 처음 해본 것 같다.처음에 mob 개발로 같이 공부하면서 개발을 진행했었는데 모두가 지켜보는 가운데 css로 엄청 헤맸던 기억이 난다.jest, enzyme 을 사용해서 unit test 도 작성했었다. Golang오랜만에 새로운 언어를 사용할 기회가 있었다. golang 은 당시 가장 빠르게 성장하는 언어 중 하나였다.대부분 언어가 10K문제를 고민할 때 go는 1M 은 일상이라며 성능에 엄청난 자신을 보이는 언어였다.duck typing 을 지원하는 언어를 처음 공부 했던 것 같은데, 정말 흥미로운 언어였다.하지만 아직 생태계가 잘 활성화 되진 않았고 유행의 초기단계로 보였다. Gorilla web toolkit 을 사용했었는데 쉽지는 않았었다. 2017, 2018: Microservice2015년 부터 MSA가 유행 하긴 했지만 누구도 제대로 해본 적은 없었다. 거대한 시스템들 여러개를 그냥 api gateway 를 앞에 두고 묶어 놓은 정도였다.그래서 인지 솔루션 하나를 개발하면서 msa 레퍼런스를 확보해 보라는 미션이 내려왔다. Spring Cloud 와 AWS 를 활용해서 구축 했었다.이때 내가 한 제일 큰 기여는 event driven architecture 를 도입하고 eventually consistent 를 적용한 것이다.java8, spring boot, spring data jpa, spring cloud(Eureka, Config, Zuul, Ribbon, Contract..),mariadb, mongodb, rabbitmqaws, gitlab, git, gocd, 이 때쯤 쿠팡, 배민도 msa 구조로 바꾼다고 기사가 많이 났던 것 같다. 지금은 당연한 것들인데 이 당시만 해도 엄청난 도전 과제였다. 2019: vue.jsvue.jsvue.js가 react.js 를 대항해서 핫하게 떠오르고 있었다. jsx 가 싫다며 vue 로 갈아타는 개발자도 많았다. 그래서 인지 회사에서 vue js 를 표준 기술 스택에 넣으려는 움직임이 있었다.그래서 사내 vue 강의 요청이 와서 급하게 짧은 튜토리얼 식 강의를 만들어 진행했었다.확실히 많은 개발자들이 기존 웹개발에서 모던 프레임웍으로 넘어올때 react.js에 비해서 vue.js가 거부 감이 덜했던 것 같다. 이때 lighthouse 성능 지표에 대해서도 공부를 하면서 웹에대해서 그리고 SPA에 대해서 더 많이 이해를 할 수 있는 기회가 되었던 것 같다. atomic design &amp; storybookvue.js, amchart.js 를 사용해서 대쉬보드를 만드는 프로젝트를 진행했다. UI가 비슷한 차트들이 반복되었다. 그래서 조금이라도 재사용을 하고 싶어서 컴포넌트를 atomic 하게 설계 해 보려고 했다. 하지만 atoms, molecules, organisms, templates, pages 각각에 대해서 개발자들 마다 이해하는게 달랐고, 정확하게 나누기도 애매했던 것 같다. 특히 molecules, organisms 사이에서 많은 어려움이 있었다.우리가 정했던 기준은 organisms 는 비즈니스적 의미를 부여하자는 것이었다. 그리고 templete 은 빼버렸다. atomic design을 완벽히 지키는 것이 목적이 아니라 재사용하는 것이 목적이었기 때문이다. 그리고 또 적용했던 것이 Storybook 이었다. 당시 테스트 코드도 작성하고 컴포넌트들의 스토리도 만들어야 해서 귀찮아 하는 개발자 들도 많긴 했다. 하지만 재사용하는 관점에서 봤을때 실제로 화면을 띄워서 그 컴포넌트를 찾아다니지 않아도 되는 것은 장점이었다. 2019. 8. 16: 프로덕트사용자한테 가치 있는 제품을 만들고 애자일하게 일한다고 해도 대기업에서 만드는 제품은 결국 프로젝트로 느껴졌다. 사용자와 더 가까이서 제품을 만들고 싶었다. 애자일은 알겠는데, 애자일 하게 일하는게 무엇인지도 알겠는데, Product를 만드는 팀에 있는 느낌은 아니었다.마침 스타트업에서 좋은 조건으로 오라는 오퍼가 있었지만 여러가지 사정상 끝내 결정을 미루고 말았다. 당시 그룹장님이 회사 안에 스타트업 처럼 일하는 조직을 만들건데 나가지 말고 회사 안에서 해보자는 제안을 주셨다.그것이 지금의 마림바 팀이다.PM 2명, 다자이너 2명, 개발자 3명으로 이뤄진 작은 팀이 었다.온라인 화이트보드를 만드는 것 말고는 아무 것도 정해져 있지 않았다. 2020: marimba.team마림바의 기술 스택은 처음부터 끝까지 우리가 모든 것을 결정 할 수있었다. 이전의 경험으로 풀스택으로 개발 하려면 언어가 하나로 통일되는 게 효율적이라는 것을 알고 있었다.그래서 이번엔 javascript만 사용하기 위해서 프론트엔드는 react로 백엔드는 node 로 정했다. 배포는 처음엔 aws EC2에 하나의 서비스로 구성된 모놀리틱 구조에서 시작해서 점차 MSA구조로 바꿔나갔다.이번에 기술 스택을 정하면서 하나의 목표가 있었다면 kubernetes와 aws 를 사용하는 것 이었다. frontend: react.js, next.js, konva.js, rxjsbackend: nodejs, express, socket.ioInfra: aws, kubernetes, helmci/cd: jenkins, terraform, argocd,log: elastic, datadog 2021 현재여전히 마림바를 개발하고 있고, 기술 스택은 크게 달라지지 않았다. 다른 회사들의 기술 스택을 알고 싶어서 채용공고를 자주 보는 편인데 여전히 React, Spring 이 강세 인 것 같다.frontend는 React.js, backend는 Spring, JPA를 사용하고 대부분 MSA 구조로 AWS 위에서 운영되고 있는 것 같다. 그리고 우대사항으로 typescript, graphql, kotlin, webflux 같은 것들이 보였다.그래서 현재 공부 중이거나 관심을 갖고 있는 기술은 typescript, graphql, svelte이다. 그리고 java를 마지막으로 사용한게 2년 전 쯤이라, java 최신 버전이랑 spring webflux 를 다시 공부해 볼 예정이다. 마무리프로그래머로 일을 한지 딱 10년이 되었다. 더 많은 일들이 있었겠지만 기억나는 키워드들을 정리해 보고 싶었다.개인의 기술 트랜드 변화이지 회사나 IT 업계의 흐름과는 다를 수 있다. 10년 동안 개발을 하면서 느낀 것은 기술은 계속 변하고 새로운 것들이 나온다는 것이다.그런데 그 변화를 만드는 것은 사용자라는 생각이 든다. 10년 아니 5년 전 쯤만 해도 기술의 발전에 사용자들이 맞춰나갔다면, 이제는 사용자들의 더 좋은 경험을 위해 기술이 발전해 나가는 것 같다. 뭘 공부해야 할까?언어도 프레임워크도 아키텍쳐도 점점 다양해지고 발전하는 속도도 빨라지고 있다. 일단 채용공고만 봤을 땐 스타트업 부터 대기업까지 우리가 알만한 기업들은 크게 봤을때 1,2년 차이로 비슷한 기술 스택을 사용하는 것 같다.당장 쓸 기술을 찾는다면 채용공고에 나오는 것을 공부하면 될 것같다. react, typescript, java, jpa, spring, msa, kubernetes, aws 키워드만 보면 사실 엄청 새로운 것은 없어 보인다.하지만 spring도 동시접속 200명을 처리하는 것과 10K 문제를 다루는 것은 매우 다를 것이다. 저 기술로 어떤 문제를 풀고있는지를 배워야한다. 개인적으로 새로운 언어나 프레임워크를 배우는 것을 좋아한다. 하지만 새로운 기술을 배우는 것보다 더 중요하게 생각는 것은 새로운 문제상황에 놓여지게 하는 것이다.특정 기술로 어떤 문제를 해결 할 수 있을까 고민하는 것보다 문제를 해결하기 위해 어떤 기술을 쓸 수 있을지 찾아서 적용하는 것이 더 좋다고 생각기 때문이다. 계속해서 새로운 문제를 만나는 것이 개인의 기술의 흐름을 만드는 제일 좋은 방법이 아닐까?다음 3년을 위해 새로운 문제를 찾아 떠날 생각이다. 요약servlet/jspjqueryhtml5spring mvcapache tomcatmybatisoracle dbsubversionjenkinsrest apidockermsa12factorcloud nativeelk stackgitgo-cdagilexp, tdd, pair programmingandroid, dagger, junit, robolectric,es2015+reactvuejest, enzyme,golang, gorilla web toolkitjava8, functional programmingjpaspring cloudeventually consistentevent driven architecturerabbitmqnodejsmongo dbredisreact hookscanvas apisocket.iorxjswebrtckubernetesaws","categories":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}],"tags":[{"name":"retro","slug":"retro","permalink":"https://kihoonkim.github.io/tags/retro/"},{"name":"기술스택","slug":"기술스택","permalink":"https://kihoonkim.github.io/tags/%EA%B8%B0%EC%88%A0%EC%8A%A4%ED%83%9D/"}],"keywords":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}]},{"title":"2020년 회고","slug":"retro/retro-2020","date":"2020-12-30T15:00:00.000Z","updated":"2021-08-17T00:04:32.706Z","comments":true,"path":"2020/12/31/retro/retro-2020/","link":"","permalink":"https://kihoonkim.github.io/2020/12/31/retro/retro-2020/","excerpt":"","text":"2019년 2018년 2017년 코로나.언제 부터 시작된 건지 이제 기억이 나지 않지만, 지난 일년은 코로나로 인해 많은 것들이 달라졌다. 일단, 7살 딸내미가 유치원에 가지 못했다. 계속 되는 휴원에, 잠깐이라도 등원 할 수 있는 유치원이나 어린이집 등 보육시설을 찾아 여러번 옮긴 것 같다. 그러고 보니, 성당유치원, 교회유치원, 병설유치원, 국공립어린이집 등 참 많이도 바꿨다. 아이가 어디든 적응을 잘하니 믿고 보내봤던 건데, 지금 생각해 보니 참 못할 짓이 었다. 결국 도심을 떠나 산이 보이는 곳으로 이사를 하기로 했다. 신도림을 떠나 구리로 이사를 했다. 한쪽 창문으로는 해가 뜨는 것을 보고 반대 쪽 창문으로는 노을이 지는 것을 볼 수 있다. 계절이 변하는 것과 하늘의 색이 변하는 것을 느끼며 살게 되었다.이사를 하고 제일 불편한 점은 이동네 커피숍은 10시에 연다는 것이다. 모든 것이 느리게 돌아가는 것 같다. 그래서 다들 여유로운 것 같기도 하다. 그다음 달라진 것이 이동 수단이다. 2007년에 면허를 딴 것 같은데, 그 뒤로 운전을 할 일이 없었다.개인 적으로 탐험가 성향이 아니라서, 코로나 이전에도 평생을 집 학교, 집 회사의 반복으로 살아 왔다. 하루 종일 마스크를 쓰고 있다는 것을 빼면 크게 달라진 것이 없는 삶이었다.아이와 놀러 다닐때도 여행을 갈때도 언제나 뚜벅이로 다녔다. 버스를 타고 지하철을 환승하고 유모차를 끌때나 짐이 있을때는 엘리베이터를 찾아 돌아 돌아 길을 가는 경우도 많았다. 그래도 그 순간들이 좋았다. 언제나 아이와 손을 잡고 다니거나 안고 다녔다. 항상 연결되어 있었다.하지만, 코로나로 인해 대중교통을 아이와 함께 탄다는 것은 큰 위험이 었다. 그래서 차를 샀다. 장롱면허 13년 차를 청산하고 운전을 시작했다. 정성스레 초보운전 스티커를 붙이고 시작을 했다. 개인적으로 최근 10년 중 가장 큰 도전이 었던 것 같다. 그래도 조심성 많은 성격때문인지 안전하게 잘 하는 것 같다. 아직 3000km 도 안 탄 초보지만.. 이제 운전하는데 두려움은 없어졌다.운전을 하면서 느낀 것은, 매일 다니던 익숙한 길도 차로 가니까 완전히 다른 길이라는 것이다.처음 운전 할 때, 매일 걸어 다니던 길을 네비게이션으로 미리 보고 머리 속으로도 시뮬레이션을 하고 출발 했지만 언제나 헤맸던 것 같다. There’s a difference between knowing the path and walking the path.2011년에 회사에 입사해서 소프트웨어 엔지니어링 팀에 계속 있었다. ‘개발은 이렇게 해야 한다. 일하는 방법은 이런 방법론을 따라야 한다. 이렇게 하는게 올바른 방법이다.’ 를 주장하는 팀 들에 있었다. 회사 생활 10년간 가장 많이 따라다닌 단어가 Agile 이었다. 애자일 하게 개발하는 것, 애자일하게 일을 하는 것, 많이 공부도 했고 시도도 해봤다. 물론 안전한 공간에서…올해 가장 달랐던 것이 바로, 그 동안 알고 있던 것들로 제품을 만드는 것 이었다. 책도 많이 봤고 강의도 많이 들었었다. 실제 제품을 개발한다면 이렇겠지.. 라고 머리속으로 시뮬레이션도 많이 해봤다. 나름 애자일 전문 개발자라고 생각하고 살았다. 하지만 역시, 길을 아는 것과 걷는 것은 달랐다. 계획대로 되는 것은 없었고, 내가 알고 있던 것들로 일이 해결되는 일도 없었다.그저, 팀원 들과 함께 계속되는 선택의 결과들이 쌓여 가는 것이 었다. 그 순간 최선의 선택을 해가면서 제품을 만들어 가는 것이었다. 선택의 결과가 실망스러울 때도 있었고, 내가 원하지 않는 선택을 해야 하는 경우도 많았다.여전히 많은 것이 엉망이고, 여기 저기 깨진 유리창이 많다. 하지만 이 모든 것들이 우리 스스로 선택해온 결과물 이다. 돌아 보면 어디 내놔도 부끄럽지 않을 선택의 결과들이다. 코로나는 계속 될 것 같다. 최소 일년은 지금과 같을 것이다. 백신으로 모든게 해결되 더라도, 심리적인 것이 해결되려면 몇 년이 더 필요할 것 이다. 2020년은많은 것들이 혼란 스러웠다. 정돈 되지 못하고 불안한 날들이었다.내가 추구하는 가치를 다른 사람들에게 함께하자고 하는 외로운 싸움들의 연속이 었다.그로 인해 나를 좀더 알게 된 한 해였던 것 같다. 2021년에는아이가 초등학교 입학은 하지만 정상적으로 다닐 수 있을 지는 모르겠다.난 계속 같은 회사를 다니고 있겠지만 재택을 하는 날은 더 많아 질 것 같다. 새로운 한 해에 어떤 새로운 일이 펼쳐질지 모르겠다.그래도 다행인 것은, 2020년이 끝나갈 즈음 기술적으로 내가 추구하는 것을 이해해주고 비슷한 선택을 해온 팀원을 만났다는 것이다. 더이상 외로운 싸움은 하지 않아도 되겠다는 기대감이 들었다. 새로운 실패를 해 나가자.","categories":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}],"tags":[{"name":"retro","slug":"retro","permalink":"https://kihoonkim.github.io/tags/retro/"}],"keywords":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}]},{"title":"언젠가 또 힘들어 하고 있을지 모르는 나에게","slug":"life/힘든나에게","date":"2020-09-25T04:30:00.000Z","updated":"2021-08-17T00:04:32.699Z","comments":true,"path":"2020/09/25/life/힘든나에게/","link":"","permalink":"https://kihoonkim.github.io/2020/09/25/life/%ED%9E%98%EB%93%A0%EB%82%98%EC%97%90%EA%B2%8C/","excerpt":"","text":"무언 가에 몰입 하는 것은 많은 정신적 고통을 안겨준다.나는 개발자로서 많은 부분에 몰입을 한다.frontend, backend, modeling, architecture, ci/cd, infra.. 등등..가끔 다른 역할자의 영역을 침범하는 우를 범하기도 한다. 이번 제품을 만들면서 팀과 제품에 대해서 애정이 컸던 것 같다.그 만큼 깊게 몰입해 있었던 것 같다.많은 영역을 다루다 보니 좋든 싫든 많은 사람들과 관계를 맺게 된다.그러다 보니 항상 눈과 귀가 열려있었다. 관계에 대한 스트레스 팀원들이 늘어나고, 제품이 커져가고, 오픈이 다가올 수록사람들은 활기차고 열정적이었다.하지만 모두가 감정적으로 지쳐가고 있었던 것 같다.곳곳에서 한 숨이 늘어갔고, 조금씩 웃음이 사라졌다. 사람이 많고 다양한 만큼 다양한 생각이 모인다.가끔은 그 다름이 너무 많다보면 전체 합에서 봤을때 감당하기 힘들어지기도 한다.그래서 난 작은 팀을 좋아 한다.모두가 같이 생각하고 의사결정 할 수있을 정도의 크기..하지만 조직의 논리는 그렇지 않은 경우가 있다는 것을 배우게 됐다. 지난 일 년을 뒤돌아 보았다.난 왜 그렇게 화를 냈을까.. 왜 그렇게 욕심을 냈을까..다른 사람들은 뭐 그리 대안 없는 불평 불만이 많았던 것일까?이 곳에서 앞으로의 일년은 다를까? 물론 나의 행복은 집에 있다.회사에서 자아실현을 하겠다거나 행복을 찾겠다는 생각을 해본적이 없다.하지만 이번 일년을 몰입해서 지내다보니하루의 절반을 보내는 회사에서 행복하면 안되나? 하는 생각이 들었다. 무언가에 몰두해 본 경험이 처음이었고, 그래서 매우 서툴렀다.일하는 방식, 가치관, 철학, 목표 가 모두 달랐다.모두가 힘들었을 것 같다. 지금도..나 역시 더 이상은 못할 것 같았다.회사로 향하는 발걸음이 무거워 졌고, 자리에 앉아 있는 시간이 답답했다.복잡한 감정들을 느꼈다. 하지만 그 감정들의 의미를 알 수가 없었다.앞으로 무엇을 하고 싶은지, 무엇을 할 수 있을지 방향을 잃어 버린 것 같았다. 그냥 무작정 쉬어야 겠다는 생각이 먼저 들었다.한 곳에 매몰되어 있던 내 생각과 감정을 그 곳에서 떨어뜨려 놔야만 했다. 다른 사람들을 만나보고 싶었다.어쩌다 보니 퇴사자 들과의 만남이 되어버렸지만 몇 명의 사람들을 만났다.정말 좋은 사람들이다. 흔쾌히 시간을 내어주고, 먼저 연락을 주시다니..(연락하고 못 뵌 분들도 있는데, 다음에 시간을 내서 꼭 만나면 좋을 것 같다.) 스스로 사람을 만나러 나가는 일, 내 평생 처음 하는 이상한 짓이었다.만나면 어떤 질문을 해야 할지.. 어떤 대화를 해야 할 지 며칠을 고민했다.결국 그냥 가볍게 만나서 근황 토크만 한, 두 시간 정도씩 나눴다. 정말 다행히 퇴사한 모든 분들이 더 나은 삶을 살고 있었다. 몇 개의 기억에 남는 말들.. 남을 빛나게 해주는 역할이 너무 좋다.내가 잘 하는 것을 하나씩 알아 가는 것에 만족한다.힘들 때면 상황을 바꿔봄으로써 해결되는 것이 있다.스타트업은 워라밸을 포기할 만큼 재미있다.개인적으로 성장하는 속도가 엄청나다.내 시간을 모두 일에만 집중 할 수 있어서 좋다.목적없이 달리는 팀에 미션을 만들어 주고 싶다.제품에 관심을 두는 개발자는 세상에 많지 않다.세상에 나오면 다르고 이상한 사람이 될 수도 있다.개발자로서 커리어를 고민 했을때 무엇에 집중 할 것인지 생각해 봐라무엇을 성취할지 범위를 좁히고 집중 할 필요가 있다.개발자로서 원래 하던 일과 크게 변한 것은 없다. 삶의 만족도는 더 좋다. 많이 걸었고, 많이 움직였다. 많이 생각했다.짧은 만남을 통해서 대단한 깨달음을 얻고 싶었을 수 도 있다.하지만,그저 경쟁없는 가벼운 대화 속에서 스스로 편안해져 가는 것을 느꼈다.무엇을 더 채울 것인가 보다는 무엇을 비워낼 지 결정하는 것이 중요한 순간이 온 것이다. 행복은 달성해야 하는 목표인가? 많은 심리학자들이 말한다.행복은 크기가 아니라, 빈도라고.가끔씩 오는 큰 행복보다는 자주 느낄 수 있는 작은 행복이 더 중요하는 말이다. 그러기 위해서 내가 무엇을 할 때 즐거워 하는지 알아 했다. 난 인정 받는 욕구가 큰 사람이다.윗 사람이 아닌, 같이 일하는 팀원으로 부터 오는 인정을 좋아한다.도전해 볼 만한 기술을 ‘같이’ 탐험해 보거나 어떤 패러다임이나 아키텍쳐를 ‘같이’ 만들어 나가는 것을 좋아한다.내가 작게 나마 한 발 먼저 내딛어 줌으로써 팀을 앞으로 나가게 만드는 과정을 좋아한다.그 과정에서 나를 인정해주고 좋아해주기를 바란다.나로 인해 팀이 자신감을 가지길 바란다. 제품을 세상에 내 놓고 많은 사람이 사용하면 행복 할 거라고 생각한 것 같다.언제 달성 할 지모르는 행복이었다. (물론 엄청나게 큰 즐거움 일 것이다.)하지만 나는 반복되는 도전과 실패 속에서 조금씩 성장하는 나와 팀을 보는 것에 더 행복을 느끼는 것 같다. 자기인식. 감정을 이해하고, 왜 그런 감정을 느끼는지, 그 속에서 내가 가지고 있는 가치관이 무엇인지 생각해 보는 시간을 갖고 있다. 분명 번아웃은 아니었다.내 뜻대로 되지 않는 일들에 화가 났다.내 코드, 내 제품, 내 팀에 하는 안 좋은 얘기들에 화가 많이 났다.내가 집중하고 있던 많은 것들에 부정을 당하고 화가 많이 났다.회사에서 내 삶은 그 게 전부였다.전부가 부정 당하니 감정이 끝없이 떨어져 버린것 같다. 결론은 내가 틀렸다.새로운 고통을 견디고 새로운 가치관을 받아들이지 못한, 내 그릇의 크기가 그정도 뿐이 었을 것 이다.그동안 내가 대단한 사람이라고 허세를 부렸을 수도 있다.내가 뭐든 다 안다고 제멋대로 다른 사람에게 내 생각을 강요했을 수도 있다. 이제 내 안에서 무엇을 비워낼 지를 고민하고 결정해 나가야 할 시간이다.문제는 절대 없어지지 않는다. 다만 조금씩 나아질 뿐. 실수 해도 괜찮아. 그 것 또한 배우고 성장하는 과정이야.내가 있잖아. 그래. 지금 정신 승리 하는 중이다.","categories":[{"name":"Life","slug":"Life","permalink":"https://kihoonkim.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://kihoonkim.github.io/tags/life/"}],"keywords":[{"name":"Life","slug":"Life","permalink":"https://kihoonkim.github.io/categories/Life/"}]},{"title":"React 개발 환경 구성 (react, webstorm)","slug":"react-canvas/react-canvas-day1","date":"2020-02-07T16:00:00.000Z","updated":"2021-08-17T00:04:32.700Z","comments":true,"path":"2020/02/08/react-canvas/react-canvas-day1/","link":"","permalink":"https://kihoonkim.github.io/2020/02/08/react-canvas/react-canvas-day1/","excerpt":"","text":"개발 tool은 webstorm 을 사용하고, react는 create-react-app 을 통해 생성하도록 하겠습니다. npm 5 버전 이상 설치되어 있어야 합니다. Create React App eslint 설정 상대경로 지옥 피하기. jsconfig.json 설정. Unresoulved function or method describe() waring 수정 Create React Appcreate-react-app 을 이용해서 react app 구성을 하겠습니다. 123npm install -g create-react-appnpx create-react-app react-konva-whiteboardcd react-konva-whiteboard 정상적으로 생성 되었다면 아래와 비슷한 구조로 되어 있어야 합니다. create-react-app 버전 마다 조금 다를 수 는 있지만 크게 상관은 없습니다. 123456789101112131415161718192021react-konva-whiteboard├── README.md├── node_modules├── package.json├── .gitignore├── public│ ├── favicon.ico│ ├── index.html│ ├── logo192.png│ ├── logo512.png│ ├── manifest.json│ └── robots.txt└── src ├── App.css ├── App.js ├── App.test.js ├── index.css ├── index.js ├── logo.svg ├── serviceWorker.js └── setupTests.js eslint 설정create-react-app 으로 생성을 했다면 eslint 가 기본으로 설치되어 있습니다.eslint 설정은 .eslintrc.json 또는 package.json 에 할 수 있습니다.개인적으로 별도의 설정 파일로 분리하는 것을 선호 하기 때문에 .eslintrc.json 을 만들겠습니다. root directory에 생성하시면 됩니다. package.json 이랑 같은 위치입니다.그리고 eslint-config-airbnb 를 사용하도록 하겠습니다. eslint-config-airbnb 설치 1npx install-peerdeps --dev eslint-config-airbnb 위 와 같이 설치를 하면 package.json 에서 추가된 dependency를 확인 하실 수 있습니다. 12345678&quot;devDependencies&quot;: &#123; &quot;eslint&quot;: &quot;^6.6.0&quot;, &quot;eslint-config-airbnb&quot;: &quot;^18.0.1&quot;, &quot;eslint-plugin-import&quot;: &quot;^2.18.2&quot;, &quot;eslint-plugin-jsx-a11y&quot;: &quot;^6.2.3&quot;, &quot;eslint-plugin-react&quot;: &quot;^7.14.3&quot;, &quot;eslint-plugin-react-hooks&quot;: &quot;^1.7.0&quot;&#125; .eslintrc.json 에 extends 추가 1234567&#123; &quot;extends&quot;: [ &quot;react-app&quot;, &quot;airbnb&quot;, &quot;airbnb/hooks&quot; ]&#125; webstorm 설정 eslint 설정을 활성화 해 줍니다.File &gt; Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Code Quality Tools &gt; ESLint Fix eslint problems아래 그림과 같이 라인 단위 혹은 현재 파일의 eslint problems 을 고칠 수 있습니다.하지만 자주 발생 하기 때문에 개인적으로는 alt + f shortcut 을 등록해 두고 사용합니다. 상대경로 지옥 피하기. jsconfig.json 설정.react 개발을 하다보면 import 할 때 상대 경로를 사용해야 하는데 해당 위치를 기억하고 매번 찾아야 하기 때문에 매우 불편합니다. 1import MyComponent from &#x27;../../../etc/MyComponent&#x27; babel module resolver를 통해서 alias 를 지정해서 해결 할 수 있지만, create-react-app 은 기본적으로 설정을 custom 할 수 없기 때문에 eject 를 해야지만 가능합니다.(eject 하지 않고 커스텀 설정하는 방법은 react-app-rewired 를 보시면 됩니다.)하지만 jsconfig.json 를 통해서 쉽게 해결 할 수 있습니다. vscode 설정 방법은 많이 나와있는데, webstorm 설정 방법은 찾이 어려워 tip으로 추가해 봅니다. 프로젝트 root 에 jsconfig.json 을 생성합니다. 123456&#123; &quot;compilerOptions&quot;: &#123; &quot;baseUrl&quot;: &quot;src&quot; &#125;, &quot;include&quot;: [&quot;src&quot;]&#125; webstorm 에서 src directory 를 Resource Root 로 설정해 줍니다. 폴더 아이콘이 보라색으로 변경된 것을 볼 수 있습니다. 테스트 해보기 위해 App 컴포넌트를 src/compononts 밑으로 옮겨 보겠습니다. 12345678└── src ├── components │ ├── App.css │ ├── App.js │ └── App.test.js ├── index.css ├── index.js index.js 에서 App.js 를 참조하고 있으니 수정해 보겠습니다. 12345// AS-IS 상대 경로import App from &#x27;./components/App&#x27;;// TO-BE 절대 경로import App from &#x27;components/App&#x27;; eslint problem fix정상적으로 동작은 하지만 eslint에 의해서 import/no-unresolved problem 경고가 나옵니다..eslintrc.json 에 rule 예외를 적용합니다.123456&#123; &quot;extends&quot;: ..., &quot;rules&quot;: &#123; &quot;import/no-unresolved&quot;: 0 &#125;&#125; Unresoulved function or method describe() waringtest code 를 작성 하다보면 잘 동작은 하지만,describe, it, dexpect 등에 밑 줄이 그어지고 경고 메시지가 나옵니다. File &gt; Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Libraries에서 Download 버튼을 누르고 jest 를 찾아서 download 해줍니다. @types/jest 에 체크 되어있는 것을 확인하고 Apply 를 눌러 적용해 줍니다.webstorm 을 재시작 하고 나면 경고가 없어진 것을 확인 하실 수 있습니다. day1 마무리webstorm에 기본적인 react 개발 환경 설정을 해 보았습니다. 당연히 vccode 등 다른 tool에서 개발하셔도 상관없습니다. 이제 본격적으로 react whiteboard 를 만들어 보도록 하겠습니다.","categories":[{"name":"React","slug":"React","permalink":"https://kihoonkim.github.io/categories/React/"}],"tags":[{"name":"reactjs","slug":"reactjs","permalink":"https://kihoonkim.github.io/tags/reactjs/"},{"name":"konvajs","slug":"konvajs","permalink":"https://kihoonkim.github.io/tags/konvajs/"},{"name":"canvas","slug":"canvas","permalink":"https://kihoonkim.github.io/tags/canvas/"},{"name":"whiteboard","slug":"whiteboard","permalink":"https://kihoonkim.github.io/tags/whiteboard/"}],"keywords":[{"name":"React","slug":"React","permalink":"https://kihoonkim.github.io/categories/React/"}]},{"title":"React로 Whiteboard 만들기 overview","slug":"react-canvas/react-canvas-overview","date":"2020-02-07T15:00:00.000Z","updated":"2021-08-17T00:04:32.700Z","comments":true,"path":"2020/02/08/react-canvas/react-canvas-overview/","link":"","permalink":"https://kihoonkim.github.io/2020/02/08/react-canvas/react-canvas-overview/","excerpt":"","text":"React로 online whiteboard를 만들어 보려고 합니다. Web으로 whiteboard를 만드려면 Canvas API 에 대한 이해가 있어야 하지만, konva.js 를 사용할 것이 기 때문에 깊이 알지 못해도 괜찮습니다. Canvas api 에 대해 자세히 알고 싶다면 HTML Canvas Deep Dive 를 살펴 보시는 것도 좋을 것 같습니다. 하지만 React 에 대해서는 이미 알고 있다는 가정하에 진행합니다. React 문법에 대한 설명은 공식 문서를 참조하시면 좋을 것 같습니다. Main Concepts Advanced Guides Hooks 그리고 ES2015+ 문법을 사용 하기 때문에 아래 문서를 가볍게 훑어 보시면 좋을 것 같습니다. ES2015+ cheatsheet","categories":[{"name":"React","slug":"React","permalink":"https://kihoonkim.github.io/categories/React/"}],"tags":[{"name":"reactjs","slug":"reactjs","permalink":"https://kihoonkim.github.io/tags/reactjs/"},{"name":"konvajs","slug":"konvajs","permalink":"https://kihoonkim.github.io/tags/konvajs/"},{"name":"canvas","slug":"canvas","permalink":"https://kihoonkim.github.io/tags/canvas/"},{"name":"whiteboard","slug":"whiteboard","permalink":"https://kihoonkim.github.io/tags/whiteboard/"}],"keywords":[{"name":"React","slug":"React","permalink":"https://kihoonkim.github.io/categories/React/"}]},{"title":"2019년 회고","slug":"retro/retro-2019","date":"2019-12-30T15:00:00.000Z","updated":"2021-08-17T00:04:32.706Z","comments":true,"path":"2019/12/31/retro/retro-2019/","link":"","permalink":"https://kihoonkim.github.io/2019/12/31/retro/retro-2019/","excerpt":"","text":"2018년 2017년 30대가 꺽였다.2019년 마지막 날은 늘 그래왔듯이 가장 평범하게 보냈다.출근하고 개발하고 퇴근하고 가족과 시간을 보내며 특별하지 않게 조용히 지나보냈다. 삶크게 좋은 일도 크게 나쁜일도 없었다. 365일 매일매일이 평범하고 행복했다.늘 일정한 감정상태를 유지했고 욕심부리지 않으려 노력했다.긴 여행는 없었다. 연차 대부분이 남아있다.매주 1번씩 테니스를 쳤다. 크게 실력이 늘지는 않았다. 잘치고 싶은 마음이 크지는 않기 때문에..몸과 마음이 편해서 인지 5킬로 정도 늘었다. 근육량이늘 었길 바라지만…. 아닌것 같다.아이와 아내와 함께 많이 성장하고 행복했다.하루하루가 정말 신나고 즐겁고 행복했다. 일1,2월이 회사에서는 더이상 특별한 일이 일어나지 않을 것 같았다.입사 8년만에 드디어 똑같은 1년이 반복될 것 같은 느낌이 들었다.회사를 옮길 때가 됐다는 생각이 들었다.성과가 중요하지 않은 시기라 그런지 특별히 투입되는 프로젝트도 없었다.남는 시간에 Frontend를 좀 더 깊이 공부해봤다.그리고 몇가지 사이드 프로젝트를 진행해 봤다.스포츠관련 앱도 만들어보고 채팅프로그램도 만들어 보고 팀 홈페이지도 만들었다.react vue nodejs aws 등을 기반으로 진행했다.아쉽게도 제대로 끝까지 릴리즈 해본것은 없다.단지 뭔가 계속 시도해 보고 싶었다. 일종의 발악이 었을까..그리고 그냥 가만히 있기 보다는 주변 사람들에게 긍정적인 영향을 주고 싶었다. 3~8월사내 경영지원 대시보드를 만들어야 하는데 개발자가 없었다.어쩌면 이 일을 마지막으로 팀에 기여하고 나가자라는 생각이었을 것이다.vue.js로 프로젝트를 진행했고, 나름 프론트엔드 개발리딩을 했다. 백엔드는 스프링이었다.계속 미뤄왔던 atomic design, storybook 도 처음으로 도입해봤다.실제로 사용되는 제품을 만든다는 것은 즐겁고 가치있는 일이었다.하지만 수많은 이해관계자가 있었고, 그로인해 진정한 whole team이 되지 못했다.너무 많은 개발자가 동시에 투입되서인지.. 코드 품질을 일정하게 유지시키지 못한 아쉬움이 남은 채 끝났다. 9~12월작년에 감사한 제안을 많은 지인들께 받았었다. 그래서 좀 더 가치를 인정받는 곳으로 가고 싶은 마음이 들었다.하지만 동시에 내가 하고 싶은 일이 무엇인지에 대한 고민을 계속해왔다.결론 적으로 내가 하고 싶은 일은 작지만 하나인 팀에서 제품을 처음부터 끝까지 개발하는 것이었다.그리고 그 안에서 소소하게 배우고 그 경험을 다른 사람과 나누는 것이었다. 더이상 새로울 것이 없을 것 같은 이 회사에서 새로운 기회가 찾아 왔다. 팀원 몇명과 함께 새 팀을 만들어 옮겼다.작은 팀, whole team, small realese, full cycle, full stack으로 개발할 수 있는 곳이었다.회사에서 처음으로 pm, cx, dev가 작지만 한팀으로 이뤄진 곳이었고 기획부터 출시까지 모든 권한과 책임을 가질수 있는 곳이었다.어찌보면 결과를 빠르게 만들어 나가야 하는 부담이 있는 곳이기도 했다. 팀을 옮기고 4개월 정도가 정신없이 지나온 것 같다.한 달만에 WebRTC로 Video Conference를 만들었다. 한국과 미국에서 같이 팀원 모두 접속 해보기도 했다.Canvas api와 socket.io를 통해 동시편집이 가능한 보드도 만들고 있다.업무용 사이트를 개발 할때 거의 사용해보지 못하던 다양한 web api를 많이 써보고 있는 것 같다.짧은 기간에 많은 시도를 해본 것같다. 정신없이 달리다보니 경험을 정리할 시간이 없었던 것 같기도 하다. 귀차니즘에 대한 핑계인 것 같기도 하고..우리에게 얼마의 시간이 더 주어질 지는 모르겠지만 이제는 의미있는 결과를 만들어 보고 싶다.개발자로서 팀이 앞으로 나아갈 수 있게 도와 주고 싶다.올바른 방향으로 나아가는 것은 팀원 들과 함께 찾아 가는 중이다.여기에 좀 더 빠르게 속도를 붙여주는 것이 나의 역할 인 것 같다. 코드 품질은 덤이다. 2019년 정리.일단 푹 쉬어가는 한해였다.딱히 기억에 남게 읽은 책도 없는 것 같다.35살이 지나면서 40살에 대한 고민을 시작하기도 했다.어떤 개발자가 될지, 어떤 사람이 될지 지금은 답이 나오지 않는다.2018년 부터 이직에 대한 고민을 계속 하고 있었지만, 일단은 흘러가는 대로 내버려 두기로 했다.빅데이터나 인공지능 쪽을 공부하려고 했지만, Frontend 개발을 주로 했던 것 같다.이제는 Frontend, Backend 모두 일정 수준 이상으로 할 수 있게 되었다. 2020년 에는..밀려있는 글감으로 블로그를 다시 쓰기 사작해야 겠다.리액티브 프로그래밍 쪽을 좀 더 공부해 제품 개발에 사용해 볼 생각이다.영어는.. 해야되는데.. 나가서 살지 않는 이상 늘지 않을 것 같기도 하고…제주도 가서 1년 정도 살면서 remote work 도 해보고 싶기도 하고…안정적이면서 도전적인 삶을 살고 싶기도 하고… 뭐.. 어찌어찌 또 앞으로 나아가 겠지..?","categories":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}],"tags":[{"name":"retro","slug":"retro","permalink":"https://kihoonkim.github.io/tags/retro/"}],"keywords":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}]},{"title":"(책리뷰) Real World HTTP","slug":"boot_review/realWorldHttp","date":"2019-06-09T05:40:00.000Z","updated":"2021-08-17T00:04:32.694Z","comments":true,"path":"2019/06/09/boot_review/realWorldHttp/","link":"","permalink":"https://kihoonkim.github.io/2019/06/09/boot_review/realWorldHttp/","excerpt":"","text":"제목 : Real World HTTP저자 : 시부카와 요시키역자 : 김성훈출판사: 한빛미디어초판발행: 2019. 04 역사와 코드로 배우는 인터넷과 웹 기술처음 나왔을때 정말 궁금 했던 책이다.요즘 처럼 빠르게 바뀌는 웹 기술에 관한 책이 나오기도 바쁜데, HTTP 의 역사에 대한 책이라니..나 역시도 관심이 가긴 했지만, 쉽게 구매하긴 힘들 었다. 다행히도 이 책은 꽤 재미있고, 좋은 내용으로 가득했다. 첫 장을 읽고 나면 드는 생각이 두가지 있다.‘역시 오라일리 책이구나’와 ‘역시 일본 사람이 쓴 책이구나’ 이다.(일본 번역서 들이 대부분 그렇듯이 번역은 매우 깔끔한 편이다.) 추상적이고 철학적인 내용 보다는 스펙 하나하나에 대해서 꼼꼼하고 깊이 있게 다루고 있었다. 이 책을 통해 얻을 수 있는 것은 크게 세가지 였다. HTTP 1.0 ~ 2.0 까지의 스펙과 추가된 이유 CURL 사용법 http관련 GO 라이브러리 사용법 프론트엔드/백엔드 구분없이 웹을 개발하는 개발자라면 한번 쯤 읽고 공부해 볼만한 책이다.그냥 프레임워크가 해주니까 고민없이 사용하던 것 들에대해서 좀 더 이해하고 개발 할 수 있게 해줄 것이다. curl을 사용할 일이 별로 없거나, Go 언어에 대해 관심이 없다면, 그 부분을 과감히 넘어가고 읽어도 무방한 책이다. HTTP 스펙에 대한 내용만으로도 충분히 가치있는 책이다. 하지만 스펙에 대해서 다루다 보니 한번에 모든 내용을 이해할 수는 없다.한번 읽고 마는 책이라기 보다는 곁어 두고 궁금할 때 찾아 보면 좋을 것 같다. 무엇보다 Web 이 어떤 방향으로 나아가고 있는지도 알 수 있을 것이다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) 알고리즘이 욕망하는 것들","slug":"boot_review/whatAlgorithmWant","date":"2019-04-16T09:06:00.000Z","updated":"2021-08-17T00:04:32.695Z","comments":true,"path":"2019/04/16/boot_review/whatAlgorithmWant/","link":"","permalink":"https://kihoonkim.github.io/2019/04/16/boot_review/whatAlgorithmWant/","excerpt":"","text":"제목 : 알고리즘이 욕망하는 것들저자 : 에드 핀역자 : 이로운출판사: 한빛미디어초판발행: 2019. 03 “알고리즘이 욕망하는 것들” - 우리 삶과 사회 깊숙이 침투한 알고리즘의 내면을 성찰하다. 1장 알고리즘을 아는가2장 스타 트렉 컴퓨터 구축3장 하우스 오브 카드: 추상화의 미학4장 카우 클리커 코딩: 알고리즘이 하는 일5장 비트코인 헤아리기마무리: 알고리즘적 상상 책 제목이랑 각 챕터들의 제목을 정말 기가막히게 뽑은 것 같다. 책을 보고 있는데 주변 사람들한테 정말 재미있을 것 같다는 말을 많이 들었다.나 역시 책 제목과 목차를 보고 비슷한 종류의 책들과 마찬가지로 일상에서 친숙한 주제를 가지고 알고리즘에 대해 알기 쉽게 풀어주는 책이라고 생각했다. 하지만 이 책은 IT관련 책이 아니라 인문학 서적이다. 그 것도 철학에 가까운 것 같다. 인문학, 예술, 철학등의 용어나 기반 지식도 없고, 관심도 없이 살아온 공대 출신의 개발자에게는 매우 어려운 책이었다. 한글자 한글자 곱씹어 읽어보려 했지만 금새 기억속에서 사라져 버릴 정도였다.즉, 가벼운 마음으로 읽을 책이 아니다. 알고리즘이 무엇인지 정의를 하면서 시작한다. 그리고 나서 영화, 넷플릭스, 애플, 구글, 페이스북, 비트코인 등 우리에게 친숙한 주제들을 통해서 알고리즘을 인문학 적 관점에서 바라보고자 한다. 저자는 다양한 사회적 현상의 이면에 있는 “알고리즘”이라는 녀석에 대해서 알려주면서 독자들에게 생각할 거리들을 던져 준다.철학적 주제에 관심이 있다면 꽤 재미있는 책인 것 같다.이런 류의 전개를 하는 책들은 이해를 할 수 있다면 아주 매력적인 책이다. 제목은 “알고리즘이 욕망하는 것” 이지만, 실제 내용은 인간이 욕망하는 것에 대한 내용이다. 인간의 욕망이 알고리즘을 통해 어떻게 서비스화 되어가는지 알고 싶다면 이책은 좋은 선택이 될 수 있다. 이책에서 말하는 “알고리즘”은 인간의 욕망을 추상화한 단어인 듯 하다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) 기계는 어떻게 생각하고 학습하는가","slug":"boot_review/6ai","date":"2019-01-10T09:06:00.000Z","updated":"2021-08-17T00:04:32.693Z","comments":true,"path":"2019/01/10/boot_review/6ai/","link":"","permalink":"https://kihoonkim.github.io/2019/01/10/boot_review/6ai/","excerpt":"","text":"제목 : 기계는 어떻게 생각하고 학습하는가저자 : 뉴 사이언티스트, 닉 보스트롬, 넬로 크리스티아니니, 존 그레이엄 커밍, 앤더스 샌드버그, 피터 노빅, 토비 월시역자 : 김정민출판사: 한빛미디어초판발행: 2018. 12 이 책은 부제 그대로 6명의 위대한 AI 석학이 인공지능의 현재와 미래에 대해서 이야기를 해나가는 책이다. 몇 년전에 알파고와 이세돌의 대국이 있은 이후로 인공지능, 머신러닝, 딥러닝 등의 용어가 많은 곳에서 익숙하게 들려오고 있다.그 때쯤 회사에 뇌과학자 한분이 오셔서 스카이넷같은 인공지능은 오지 않는다. 대신 인간의 많은 일자리가 대체될 것이기 때문에 창의성이 필요로 하는 일을 선택해야 한다고 했던 기억이 난다. 인공지능이라는 단어는 많이 들어 왔지만, 실제로 우리의 삶에 어느정도로 깊숙히 와있는지는 개발자임에도 잘 알지는 못했다.여러 영화의 영향으로 스카이넷이나 자비스, 울트론 같은 인공지능의 이미지가 더 익숙해 있기도 했다. 그럼 과거, 현재, 가까운 미래에 인공지능의 모습을 실제로 어떨까? 이 책은 나 처럼 인공지능을 추상적으로 알고 있는 사람을 위해 쓰여진 것 같다.인공지능이 어떤 식으로 발전해 왔는지, 현재 어느 수준에 머무르고 있는지, 앞으로는 어떤 모습으로 우리에게 영향을 줄 것인지를 6명의 학자가 여러 에피소드를 바탕으로 풀어나간다.인공지능에 대해서 어떻게 되어야 하는지 강하게 주장하는 내용이라기 보다는, 담백해서 사실을 기반으로 쓰여져있다. 1,2 장은 인공지능의 역사를 다루고 있는 것 같고, 3,4 장은 인간의 어떤 부분을 대체할 수 있고 자율주행차나 로봇 전쟁 등 여러 철학적인 주제를 다룬다.5,6,7 장은 기계도 창의적인 일을 할 수 있는지, 인간을 대체하는 것이 아니라 어떻게 도움을 줄 수 있는지에 대해서 이야기를 한다.마지막으로 8장은 인공지능이 가져올 수 있는 위험과 우려에 대해서 이야기를 한다. 전체 적으로 어려운 내용을 가볍게(?) 다루고 있다. 익숙하지 않은 용어들도 있어서 쉽게 읽히지 않는 부분도 있었지만, 인공지능에 대해서 알아야할 다양한 사실에 대해서 알 수 있었다. 머신러닝을 공부하기 전에 읽기 좋은 인문서적 같은 느낌이었다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"2018년 회고","slug":"retro/retro-2018","date":"2018-12-31T00:20:40.000Z","updated":"2021-08-17T00:04:32.705Z","comments":true,"path":"2018/12/31/retro/retro-2018/","link":"","permalink":"https://kihoonkim.github.io/2018/12/31/retro/retro-2018/","excerpt":"","text":"2018년이 끝나는 마지막날, 한해를 돌아보고자 짧게나마 회고를 해볼까 한다. 일단 작년 회고 에 나왔던 Action Item을 보면 “개인 프로젝트 진행”과 “영어” 가 있었다.개인 프로젝트는 어느 정도 진행했 던 것 같은데, 영어와는 아주 멀게 지내왔던 것 같다. 내년이면 6살 되는 딸이 나보다 영어를 더 잘하는 것 같다. 2019년 Action Item으로 계속 가져가야 될 것 같다. (내년의 나는 하겠지..) 유치원올 한해를 돌이켜 봤을때 가장 큰 변화였다. 어린이집도 안 다녀 봤고, 가족들 이외의 사람 손에는 키워본 적이 없던 딸이 유치원을 가게 되었다.출생률은 줄어 든다는데 유치원 보내기는 왜 그렇게 힘이드는 건지 모르겠다. 어린이 집을 못보냈기 때문에 유치원은 꼭 한번에 보내보겠다고, 그 추운날 밤부터 유치원 앞에서 줄을 서서 원서를 내기도 했었다.놀이터에서 다른 아이들 노는것을 빤히 처다만 보고 있는 모습에 마음이 아팠었는데, 이제는 제법 친한 친구도 많아지고 큰 문제없이 잘 크고있는 것 같아 다행인 것 같다.아이와 엄마에게 가장 큰 변화가 있는 시기였기 때문에 개인적으로는 변화보다는 안정을 유지하는 한해가 되도록 노력했다.우리 가족 세명 모두 성장해 나가는 모습에 뿌듯한 한해였던 것 같다. 프로젝트Digital Signage solution 개발(~ 2018.07)디바이스로 컨텐츠 배포 및 스케쥴링 서비스 개발Microservice ArchitectureSpring cloud, java8, mariadb, rabbitmq, reactjs 작년부터 개발해 왔던 큰 프로젝트를 상반기 내내 진행했고, 하반기에는 팀단위 프로젝트 보다는 사내 교육이나 작은 홈페이지 만드는 일들을 작게 진행했 던 것 같다. 되돌아 보면, 기술 적인 문제보다는 소프트 스킬에 대해서 고민을 더 많이 한 것 같다. 개인적으로 제품을 만들면서 팀을 성장시키는 것에 가치를 두고 일을 한다. 하지만 올해는 같이 일하던 분들이 여러 이유로 이직, 휴직을 해서 팀이 유지되지 못했다. 개인적인 사정과 지속되지 않는 팀으로 인해 많은 스트레스를 받았고, 그로 인해 일정한 감정을 유지하기 어려웠던 것 같다. 평정심이 유지되지 않는 상황에서 다른 팀원들에게 안좋은 영향을 줬을 것 같아 많은 반성과 고민을 했던 것 같다. 그래도 결국엔 좋은 경험이었다고 생각된다. 덕분에 사람을 대하는 방법, 다른 팀과 협업하는 방법에 대해서 고민해 볼 수 있었던 것 같다. 평정심을 유지하기 위해 계속해서 내려 놓는 연습을 하고 있다.그리고 첫인상으로 사람을 판단하지 않으려고 노력하고 있다. 책개인적으로 책을 통해 공부하는 것을 좋아한다. 원하는 주제와 구성에 대해서 선택을 할 수 있고, 시간에 구애받지 않고 볼 수 있기 때문이다. 올해는 node.js와 frontend를 공부하는 것이 제일 큰 목표였다.frontend와 backend의 균형을 맞춰 공부해 나가려고 했는데,목록을 정리하고 보니 여전히 backend 쪽으로 치우친 것 같다. 올해 본 책중 제일 기억에 남는 책은 익스트림 프로그래밍 이었다.TDD, Pair를 해왔지만 XP에 대해서 되 돌아보게 만들어 준 것 같다. 이 책은 따로 리뷰를 하고 싶었는데 여전히 못하고 있다. 그 다음으로는 Node.js 교과서 를 뽑을 수 있을 것 같다. 개인적으로 국내 서적보다는 번역서를 위주로 책을 보는 편인데, 이 책은 꽤 잘쓴 것 같다. 주변에 많은 분들께 추천했던 것 같다. 사놓고 못(안?) 본책이 많은데..일단 Node.js 디자인 패턴이랑 구글애널리틱스 실전활용법 책은 1월내에 볼 것 같다.그리고 아마 내년에는 빅데이터나 인공지능 분야의 책을 많이 볼 것 같다. &gt; 읽은 책자바 &amp; 스프링 이것이 자바다 (한빛) 스프링4 입문 (한빛) 자바9 모듈 프로그래밍 (한빛) 스프링 5.0 마이크로서비스 2/e(에이콘) 스프링 5 레시피 (한빛) Node.js 제대로 배우는 Node.js 프로그래밍 (BJ퍼블릭) Node.js 교과서 (길벗) Node.js 마이크로서비스 코딩 공작소 (길벗) Frontend 새로운 CSS 레이아웃 (웹액츄얼리코리아) 반응형 웹디자인 (웹액츄얼리코리아) 리액트 디자인 패턴과 모범 사례 (에이콘) etc 도메인 주도 설계 핵심 (에이콘) 익스트림 프로그래밍 (인사이트) The nature of software development (한빛) 카프카, 데이터 플랫폼의 최강자 (책만) 모던 스타트업 (한빛) &gt; 출판사 리뷰한 책한빛4월 : 이것이자바다5월 : Java9 모듈 프로그래밍8월 : 모던 스타트업10월: 스프링 5 레시피12월: 기계는 어떻게 생각하고 학습하는가 (ing..) 길벗8월 : Node.js 교과서 &gt; 사놓고 아직 안읽은 책실전 AWS 워크북DevOps 핸드북빠른 모바일 앱 개발을 위한 react native인공지능을 위한 수학쿠버네티스 마스터패턴인식아무것도 모르고 시작하는 인공지능 첫걸음Node.js 디자인패턴구글애널리스틱스 실전활용법 블로그블로그를 많이 쓰는 편은 아니지만, 올해는 거의 쓰지 않았던 것 같다.대부분 책 리뷰였던 것 같고,마이크로서비스 아키텍처(MSA). 서비스 개발팀 이야기 가 거의 유일한 듯 하다. 그래도 많은 분들이 관심 가져 주시고 공감해 주셨던 것 같다. 쓰려고 했다가 못쓴 주제들이 있는데, 내년에 시간을 내서 써봐야 겠다.(페어프로그래밍 잘하는 법, AMP, 프론트엔드 테스팅, 프론트엔드 성능..) 발표, 강의강의는 애자일 강의 2일, vuejs 강의 2일 정도 진행한 것 같다. 애자일 강의는 이제 그만해야 할 것 같다. 프랙티스 위주로 자료를 만들기도 했고, 수도 없이 공유해 왔지만 지금은 생각이 많이 달라진 것이 이유일 것 같다. 발표도 강의도, 개인적인 경험과 지식을 공유하는 것은 즐거운 일이지만, 유리성대로 인해 많이 하지는 못한 것 같다. 내년엔 밋업에서 발표하고 싶기도 한데.. 아싸 성향이라 가능할는지… 1월 : Event Driven Architecture4월 : MSA 해본척 하기7월 : CI/CD 맛보기8월 : TDD11월: Frontend Testing더 있나…..? 마무리지금까지는 개인적인 능력으로 모든 팀원을 이끌고 나가야 한다는 부담감을 가지고 일을 했던 것 같다. 하지만 좀 쉬면서 주위를 둘러보니 다양한 능력을 가지고 개성있는 사람들이 많이 있다는 것을 알게되었다. 이제부터는 많이 내려 놓고 여러 팀원들과 함께 가치있는 제품을 만들어 나가고 싶다.2019년에는 한발짝 물러나서 팀의 성장을 지켜 볼 수 있는 한 해를 만들어 볼까한다.","categories":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}],"tags":[{"name":"retro","slug":"retro","permalink":"https://kihoonkim.github.io/tags/retro/"}],"keywords":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}]},{"title":"애자일 코리아 컨퍼런스 2018 참석 후기 - 누가 누가 왔었나?","slug":"Agile/agilekorea2018","date":"2018-11-26T05:30:30.000Z","updated":"2021-08-17T00:04:32.683Z","comments":true,"path":"2018/11/26/Agile/agilekorea2018/","link":"","permalink":"https://kihoonkim.github.io/2018/11/26/Agile/agilekorea2018/","excerpt":"","text":"작년에 이어서 올해도 애자일 코리아 컨퍼런스에 참석하였다. 애자일 컨퍼런스 답게 점 점 더 발전하고 있는 행사인듯 하다. 올해는 더 다양하고 깊이 있는 주제로 꾸며졌던 것 같다. 특히 Riot Games의 Ahmed Sidky의 키노트는 많은 사람들의 찬사를 받았던 것 같다. 지동설, 천동설에 비유해서 customer centric 을 설명해가는 과정은 소름이 돋을 정도 였다. 애자일 마인드셋에 대한 강조와 조직을 어떻게 변화시켜 나가야 하는 지에 대한 내용이었다. 올해는 많은 세션에 참석하지 못했기 때문에 여러 세션에 대한 리뷰는 다른 분들께 맡기고, 다른 관점에서 회고를 해볼 까 한다. 2017년 행사에 자원봉사자로 참석하면서 좋은 사람들도 많이 만나기도 했고, 주변 분들이 운영진으로 활동하고 있어서 올해는 좀 다르게 참가해 보고 싶었다. 애자일에 대해서 발표할 수는 없고, 가지고 있는 거라고는 개발능력 뿐이라 Agile Korea Conference 2018 페이지를 만드는 걸로 컨트리뷰션 하기로 했다. 구글 AMP 로드쇼에 갔다와서 AMP(Accelerated Mobile Pages)를 사용해서 뭔가 정적 페이지를 만들어 보고 싶었다. 때마침 우디에게 컨퍼런스 소개 페이지를 만들어야 한다는 얘기를 들었다. AMP로 만들기 딱 좋은 주제라고 생각했다. 웹 페이지를 만들기 전에 우리가 생각한 몇가지 가정이 있었다. 컨퍼런스 소개 페이지는 대부분 모바일로 접속해서 볼 것이다. 행사 당일 스케쥴 확인을 위해 페이지 접속이 잦을 것이다. 한국이라는 특성상 안드로이드 폰이나 크롬브라우저로 대부분 접속 할 것이다. 그동안 여러 컨퍼런스를 다니며 가장 큰 불만이 스케쥴 표 하나 보기위해서 오랜 시간 렌더링되는 하얀 화면을 지켜만 보고 있었어야 하는 것이었다. (웹 페이지 렌더링 성능이 사용자 경험에 가장 큰 영향을 주는 것 같다.) 우리는 이런 가정과 불만때문에 모바일을 타겟으로 디자인을 하고, 빠르게 렌더링 될 수 있도록 만들기로 했다. (이런 점이 AMP로 만들기 좋다고 생각했다.) 일단, 결론 부터 말하자면 우리의 가정은 모두 잘못되었었다. 지금부터 우리가 만든 웹 사이트에 누가 방문을 했었는지 Google Analytics 를 통해 분석해 보고자 한다. (전 운영진이 아니기 때문에 실제로 어떤 사람들이 행사에 참석했는지는 모릅니다.) 참석자가 330명 정도가 실제 행사에 참여한 것으로 알고 있다. 사이트를 오픈하고 한 달 동안 약 2800명 정도가 접속 한 것으로 보인다. 어느 나라에서 왔나?애자일 “코리아” 행사다 보니 당연하게도 95% 정도는 한국에서 접속했다. 처음에는 일본쪽에서 접속하는 것이 보였는데, 최종 적으로 일본, 미국, 인도 등에서도 접속한 것으로 보인다. 다국어는 지원하지 않아서 딱히 볼 수 있는 내용은 없지 않았을 까… 어느 도시에서 왔나?약 75% 정도가 서울에서 접속했다. 그 다음으로는 IT기업이 몰려있는 성남쪽에서 들어온 것으로 보인다. 수도권을 제외하면 부산에서 일부 들어오기도 했다. 서울에 대부분의 인프라가 몰려있다는 것을 새삼 느낌수 있었다. 다음 해에는 더 많은 곳에서 참여 할 수 있었으면 좋겠다.근데 사포로에서는 왜..?? 누가 일본에 사시나요? 어디를 통해서 왔나?역시 페이스북의 힘이 제일 큰 것 같다. 처음 사이트를 오픈하고 SEO를 위해 meta tag도 열심히 달았는데 구글 검색 상위로 올라가지를 않았다. AMP를 사용하면 검색 상위로 올려주기도 한다던데, 검색어를 아무리 정밀하게 넣어도 세 페이지 정도는 넘어가야 링크가 보였다. agile, korea, conference 모두 너무 일반적인 단어들이기 때문에 더 그런것 같기도 하다. 하지만 페이스북에서 링크가 걸리기 시작하면서 부터 검색시 첫 페이지로 노출되기 시작한 것 같다. IT 홍보는 역시 페이스북인 것 같다. 무엇을 통해 왔나? desktop vs mobile당연히 모바일로 접속 할 것이라고 생각했는데, 시간이 지나도 desktop 으로 접속하는 비율이 더 높았다. 많은 사람이 사내에 링크를 공유하고 업무용 PC로 접속한 것이라고 예상이 된다. 조금씩 모바일로 접속하는 비율이 높아져서 최종적으로는 거의 비슷한 비율로 접속을 했지만, 시간적으로 보면 거의 대부분의 사람들이 데스크탑으로 접속한 것 같다. IT하는 사람들이라 노트북을 항상 들고 다니는 것도 하나의 요인인 것 같기도 하다. 무엇을 통해 왔나? apple vs samsung안드로이드 폰이 압도적일 것이라 생각했다. 일부 아이폰에서 이상하게 동작하는 부분이 있었는데, 별로 없을 것이라고 생각해서 무시했었다. 결과적으로 봤을때 iPhone으로 접속한 비율도 매우 높았다. 총 합으로 보면 거의 반반인 것 같다. (삼성 스마트 폰은 종류가 참 많은 것 같다.) 무엇을 통해 왔나? chrome vs others역시 Chrome의 비율이 40% 정도로 가장 높았다. 하지만 대부분의 메이져 브라우저를 통해서도 무시 못할 비율로 접속했다. Internet Explorer의 비율이 예전에 비해 많이 낮아 진 것 같다. 어떤 단어로 검색했나?앞에서 말한 것 처럼, 처음 오픈했을때는 구글에서 검색하기가 너무 어려웠다. 구글 웹마스터도구나 네이버 웹마스터도구 를 통해 크롤링을 요청했음에도 불구하고 너무 일반적인 단어(agile, korea, conference) 여서 그런지 검색을 통해 접속하는 것이 힘들었던 것 같다.실제 접속한 키워드를 보면 굉장히 디테일한 단어로 검색해야 나오는 것을 알 수 있다. 지금 구글에서 agile korea로 검색하면 그래서 세번째로 나오긴 한다. 2017년 예약 페이지를 못이기고 있지만.. 네이버에서는 agile korea 2018 로 검색해야 나온다. 어느 페이지가 관심있나?크게 index, schedule, about, fag 네가지 페이지를 제공했다. 역시나 index, schedule 두페이지가 40% 정도의 비율로 접속한 것 같다.index에 접속하고 schedule로 이동한 건가?좀 더 정밀하게 이벤트를 수집해 볼 걸 그랬다.. 행사 당일행사 당일은 역시 모바일로 접속하는 비율이 높았지만, 역시나 노트북을 통해 접속하는 사람도 많았던 것 같다. 절반 정도가 스케쥴 화면에 접속을 했고, 한국 이외의 국가에서는 접속하지 않았다. 정리해 보면,우리가 세웠던 컨퍼런스 행사 페이지는 모바일로 접속하겠지? 라는 가정이 철저하게 깨진 것 같다. 데스크탑 접속 비율이 높아서 반응형 페이지로 부랴부랴 수정했던 것 같다. AMP를 써서 구글 캐시를 통해 더 빠르게 전달하고 싶었지만, 검색을 통해 접속하는 것이 어렵다보니 캐싱의 혜택을 보지 못하고 렌더링만 빠르게 구현된 것 같은 아쉬움이 있다. 사용자에게 더 가치있는 웹 페이지를 만들기 위해 디자이너와 함께 고민을 했었는데, 다 이루지는 못한 것 같아 아쉬움이 든다. 다음번 행사에는 이 경험을 바탕으로 더 나은 페이지를 만들 수 있기를 기대해 본다. 끝으로..참여하신 모든 분들 올해도 수고하셨습니다.","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"애자일코리아2018","slug":"애자일코리아2018","permalink":"https://kihoonkim.github.io/tags/%EC%95%A0%EC%9E%90%EC%9D%BC%EC%BD%94%EB%A6%AC%EC%95%842018/"},{"name":"agilekorea","slug":"agilekorea","permalink":"https://kihoonkim.github.io/tags/agilekorea/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"(책리뷰) 스프링5 레시피","slug":"boot_review/spring5recipes","date":"2018-10-05T07:06:00.000Z","updated":"2021-08-17T00:04:32.695Z","comments":true,"path":"2018/10/05/boot_review/spring5recipes/","link":"","permalink":"https://kihoonkim.github.io/2018/10/05/boot_review/spring5recipes/","excerpt":"","text":"제목 : 스프링5 레시피저자 : 마틴 데니엄, 다니엘 루비오, 조시 롱역자 : 이일웅출판사: 한빛미디어초판발행: 2018. 09 스프링 프레임워크는 다른 언어들의 비슷한 프레임워크들에 비해서 굉장히 많은 부분이 추상화되어있다. 덕분에 개발자들은 자세한 내용을 모르더라도 쉽고 빠르게 rest api를 만들어 낼 수 있다. 하지만 그만큼 숨겨져 있는 기능이 많기 때문에 제대로 알고자 한다면 끝이 없다. 게다가 스프링 소셜, 데이터, 시큐리티 등 관련 프레임워크 들이 너무나도 방대하다. 책으로 공부하자면 1000페이지 짜리 여러 권을 봐야 할 것이다. 스프링5 레시피는 스프링5 내용까지 담으면서 스프링으로 개발할때 필요한 주요 프레임워크를 다루고 있다.(mvc, 소셜, 시큐리티, 데이타, 배치, 인티그레이션 등..)하지만 이 책은 절대로 초보자를 위한 책이 아니다. A to Z 형식으로 주요 내용을 스토리 라인을 가지고 점차 나아가는 책이 아니다. 그렇기 때문에 이 책으로 스프링을 처음 공부하고자 하는 사람들에게는 좀 어려울 것 같다. 이 책으로 스프링 공부를 시작한다면 처음부터 개념이나 용어에서 막혀 혼란스러울 수 있다. 게다가 이책은 1000페이지가 넘는다. 스프링을 어느정도 사용해 봤고, 개념들을 알고 있지만 더 다양한 사용법을 알고 싶은 사람들에게 추천 할 책이다. 개인적으론 어떤 문제에 대해 한가지 방법만 알고 있었는데, 이책을 통해 여러 해결 방법을 알 게 되었다. 요리를 제대로 배우고 싶을때 레시피 책을 사서 보지는 않을 것이다. 어떤 음식을 당장 만들고 싶지만 잘 모를때 누군가 잘 정리해둔 레시피를 보고 그대로 따라하면 비슷한 맛을 낼 수 있다. 이게 레시피를 찾는 이유이다.이 책도 음식 레시피 책처럼 사용하면 좋을 것 같다. 챕터 단위로 카테고리가 잘 나눠져 있고, 각 레시피 제목이 적절한 키워드로 표현되어 있다. 책 전체를 빠르게 훑어보고 필요 할 때마다 빠르게 찾아서 보기 좋을 것 같다.각 레시피는 과제, 해결책, 풀이로 구성되어 어떤 내용인지 빠르게 알 수 있게 했고, 각 챕터가 끝 날때 마무리 부분에서 전체를 요약해 주는 점도 이 책의 장점인 것 같다. 스프링5 레시피는 스프링이 무엇이고 관련 프레임워크들은 어떤 것들이 있고 어떻게 사용하는지 한번에 보고 싶은 개발자를 위한 실무서이다. 책의 구성 스프링 개발 툴 스프링 코어 스프링 MVC 스프링 REST 스프링 MVC: 비동기 처리 스프링 소셜 스프링 시큐리티 스프링 모바일 데이터 액세스 스프링 트랜잭션 관리 스프링 배치 스프링 NoSQL 스프링 자바 엔터프라이즈 서비스와 원격 기술 스프링 메시징 스프링 인티그레이션 스프링 테스트 그레일즈","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) Node.js 교과서","slug":"boot_review/nodejstextbook","date":"2018-08-15T04:36:00.000Z","updated":"2021-08-17T00:04:32.694Z","comments":true,"path":"2018/08/15/boot_review/nodejstextbook/","link":"","permalink":"https://kihoonkim.github.io/2018/08/15/boot_review/nodejstextbook/","excerpt":"","text":"제목 : Node.js 교과서저자 : 조현영출판사: 길벗초판발행: 2018. 08 Node.js를 공부하다 보면 자주 참고하던 블로그가 하나 있는데, 바로 ZeroCho 이다. 이 책의 저자 블로그 이다. 블로그를 보면서도 참 꼼꼼하게 잘 정리해놨다는 생각이 들었는데, 책도 참 잘 쓴 것 같다. 이 책은 말그대로 교과서다. 당장 웹 어플리케이션을 만들어야 한다면 이 책 한권이면 될 것 같다. 실무에 바로 가져다 써도 될만한 예제 코드들이 가득하고, 사용하는 모듈 들도 참고할 만한 것들이 많다. 책의 구성은 다른 Node.js 책들과 크게 다르지 않다. Node.js 특징을 설명하고, 웹 서비스 개발을 위해 http, ws, express, passport 등의 모듈을 소개한다. database도 sequelize를 통해 mysql과 mongodb 를 함께 다루고 있다. 배포 환경을 위해 aws, gcp를 다루고 있다. step by step으로 되어있어 천천히 따라가면 정말 그럴싸한 웹개발을 할 수 있을 것이다. 이 책의 가장 큰 장점은 친절함 인 것 같다. 짧게 설명하고 길게 한번더 설명해주고 그래도 이해가 안될까봐 그림으로 한번 더 설명을 해 준다. 그리고 대부분의 책에서는 이정도는 알겠지 하고 넘어가는 부분도 꼭 집고 넘어간다. 이런 걸 보면 괜히 교과서라는 타이틀을 붙인 것이 아니다. 이 책의 대상 독자는 웹 서비스 개발을 하는 초, 중급 개발자인 것 같다. 서버와 데이터베이스를 모르는 초보도 볼 수 있게 책을 썼다고 한다. 더 깊이 들어간다면 아마도 1000 페이지가 넘어 갔을 것 같다. 그래서 인지 자세한 설명은 각 장의 마지막에 함께보면 좋은 자료에 링크를 넣어 둔 것 같다. 아쉬운 점은 process나 stream, connect 등에 대한 설명이 잘 나와 있지는 않다. 웹 서비스를 개발할 목적이 아니라면 이 책외의 다른 책의 도움을 받아야 할 것 같다. 또하나 개인적으로 아쉬운 점은 Rest API 개발 비중이 좀더 컸으면 좋았을 것 같다. 실무에 바로 쓸수 있는 내용들 인데, 대부분 예제 코드가 Pug 템플릿 엔진을 통해 서버 사이드 렌더링에 초점이 맞춰져 있다. 최근에는 react나 vue 같은 라이브러리를 이용해 프론트와 백엔드를 나눠서 개발을 많이 하는데, Rest Api는 짧게 소개하고 넘어가는 것같아 아쉬웠다. 최신 javascript, nodejs 스펙을 반영한 만큼 예제 소스도 이런 트렌드를 반영했으면 좀 더 실무에 바로 사용할 수 있지 않았을까 하는 아쉬움이 남는다. 하지만, 초급자가 아니라면 이책에서 설명하는 내용으로도 충분할 것이다. 한마디로 정리해보면, Node.js 교과서는 말그대로 교과서 같은 책이다. 웹 개발을 한다면 최선의 선택일 것 이다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"},{"name":"nodejs","slug":"nodejs","permalink":"https://kihoonkim.github.io/tags/nodejs/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) 모던 스타트업","slug":"boot_review/모던스타트업","date":"2018-08-15T04:36:00.000Z","updated":"2021-08-17T00:04:32.695Z","comments":true,"path":"2018/08/15/boot_review/모던스타트업/","link":"","permalink":"https://kihoonkim.github.io/2018/08/15/boot_review/%EB%AA%A8%EB%8D%98%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85/","excerpt":"","text":"제목 : 모던 스타트업 (팀 생산성을 높여주는 21가지 도구와 서비스)저자 : 이기곤출판사: 한빛미디어초판발행: 2018. 08 대기업에 다니는 개발자로서, 스타트업은 어떤 툴을 사용하는지 궁금해서 이 책을 보게되었다. 이 책에는 개발자, 디자이너, 기획, 마케팅등의 분야에서 사용 할 수 있는 21가지 도구를 소개하고 있다. 개인적으로는 11개 정도의 도구를 사용하거나 알고 있었는데, 매번 사용하는 기능만 쓰다보니 처음 보는 내용들도 꽤 있었다. 이 책에서 다루는 제품은 아래와 같다. 1부. 조직 관리비즈니스 플랫폼: G 스위트 / 파일 관리: 드롭박스 / 커뮤니케이션 서비스: 슬랙 2부. 프로젝트 관리이슈 관리: 지라 / 코드 관리: 깃허브 / 디자인 협업: 제플린RESTful API 개발 플랫폼: 포스트맨 / 지속적 통합 및 배포: 트래비스 CI / 시간 관리: 레스큐타임 3부. 인프라 관리IaaS: 아마존 웹 서비스 / 인스턴스 가상화: 도커 / 서비스 통합: 재피어 / 설정 자동화: 앤서블 4부. 서비스 운영로그 수집 시스템: 페이퍼트레일 / 충돌 감지 및 보고: 크래시리틱스 / 웹 서비스 성능 모니터링: 핑돔서버 애플리케이션 성능 분석: 뉴렐릭 APM / 자원 모니터링: 자빅스 5부. 그로스 해킹소셜 미디어 관리: 버퍼 / 마케팅 플랫폼: 위시폰드 / 데이터 분석: 구글 애널리틱스 각 제품의 getting started 문서를 잘 정리해 책 한권으로 정리해 놓은 것 같다. 여기에 저자의 사용 팁을 더한 느낌이다.각 제품별 10 페이지 내외의 공간에 꽤 다양하고 핵심적인 내용이 담겨져 있다. 책 한권으로 이렇게 많은 제품을 훑어 볼 수 있다는 건 정말 큰 장점이라고 생각된다. 이 책은 백과사전보다는 마치 여행가이드 같았다.새로 시작하는 스타트업이나 팀의 생산성에 대해서 고민하고는 있는 팀에게 좋은 가이드로서 볼만한 가치가 있는 책이라 생각된다.각 제품에 대해서 깊이 알지는 못하더라도 각 문제별 꿀 팁, 꿀 도구를 찾을 수 있는 시작점이 되어 줄 것 같다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) Java9 모듈 프로그래밍","slug":"boot_review/java9module","date":"2018-05-22T05:08:40.000Z","updated":"2021-08-17T00:04:32.694Z","comments":true,"path":"2018/05/22/boot_review/java9module/","link":"","permalink":"https://kihoonkim.github.io/2018/05/22/boot_review/java9module/","excerpt":"","text":"제목 : Java 9 모듈프로그래밍부제 : 자바 모듈 프로그래밍으로 재사용 가능하고 관리하기 쉬운 코드 작성하기저자 : 코시크 코타갈(Koushik Kothagal)역자 : 유동환 아직 많은 자바 프로젝트에서 jdk 1.8 로 넘어가지 못하고 있을 것 같다. 그만큼 1.8에 추가된 functional interface나 lamda의 개념은 기존의 프로그래밍 방식과 많이 달랐을 것이다. 이런 시점에 java 9 이 릴리즈 된지도 벌써 반년이 넘었다. 자바9에서 추가되거나 개선된 기능은 여러가지 가 있지만 가장 큰 변화는 모듈화(Modularity) 일 것이다. OOP에 익숙한 자바 개발자 입장에서 1.8의 함수형 프로그래밍 개념 보다는 모듈 프로그래밍이 그나마 더 친숙하게 다가올 수 있을 것 같다. 하지만 모듈을 어떻게 만들고 어떻게 다뤄야 하는지 익숙해 지기는 쉽지 않아 보인다. 오히려 1.8로 넘어가는 것 보다 9가 자리잡는데 더 오랜 시간이 걸릴 수 도 있을 것 같다는 생각이 든다. 그래도 “Java 9 모듈프로그래밍” 책이 매우 좋은 가이드가 되어 줄 것 같다. 일단 번역서임에도 불구하고 번역의 느낌이 별로 없다. 책 전체를 보면서 한 두문장을 제외하고는 딱히 애매한 부분이 없었다. 용어도 영어를 알파벳 그대로 옮길지, 한국어로 표현할지, 번역해서 표현할 지 매우 잘 선택한 것 같다. 개발자가 익숙한 단어를 다르게 표현되는 경우에 읽다가 흐름이 끊기는 경우가 많은데, 아마도 역자가 개발을 꽤 오래 한 것 같다. 오탈자도 거의 없는 느낌이다. 눈에 띄게 발견한 것도 한단어 정도? 이 책이 전달하고자 하는 목적은 명확하다. “모듈이란 무엇이고 왜 사용해야 하는가.”이 내용 말고는 다른 사족이 붙어있지 않다. 처음 부터 끝까지 모듈만 집중해서 전달한다. 예제 코드도 매우 단순하고 짧다. 단순한 예제가 step by step으로 점진적으로 나아간다.무엇보다 좋았던 점은 모듈이라는 개념이 왜 나올 수 밖에 없었는지 설명을 하며 책이 시작하는 것이다. 매우 간단한 예제와 Java API를 모듈화하는 Jigsaw 프로젝트를 통해 간결하고 명확하게 전달해 준다. 기존 코드에 어떤 문제가 있었는지, 그래서 모듈이 무엇이고 왜 필요한지, 모듈화를 위해 어떤 것들이 추가되었는지, 어떤 철학을 가지고 모듈화를 해야하는지, 기존 코드를 어떻게 마이그레이션 하는지 순으로 내용이 진행된다.앞의 내용을 이해한 상태에서 다음 장으로 넘어가야 한다.그래서 뒤로 갈 수록 조금씩 내용이 어려워 지는 느낌이다.각 장에서 다루는 세부내용은 출판사 리뷰를 보면 좋을 것 같다. 당장 java 9를 사용할 계획이 없더라도 6,7장 정도까지는 부담없이 볼 수 있고, java9를 사용하지 않더라도 보면 좋은 내용들이 많다. 캡슐화에 대해서 많은 부분에서 다루고 있다. 다 보고나면 뭔가 배운 것 같은 느낌을 주는 책이다. 그냥 추가된 API를 훑는 것이 아니라, 저자의 경험과 철학을 조금은 담은 느낌이다. 단, 모듈 프로그래밍의 다양하고 상세한 예제를 보고 싶거나, Java9 의 새로운 기능을 전반적으로 알고 싶은 사람에게는 조금은 지루 할 수도 있다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"java","slug":"java","permalink":"https://kihoonkim.github.io/tags/java/"},{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"},{"name":"module programming","slug":"module-programming","permalink":"https://kihoonkim.github.io/tags/module-programming/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"(책리뷰) 이것이자바다. 자바 기본서.","slug":"boot_review/이것이자바다","date":"2018-04-10T00:30:40.000Z","updated":"2021-08-17T00:04:32.696Z","comments":true,"path":"2018/04/10/boot_review/이것이자바다/","link":"","permalink":"https://kihoonkim.github.io/2018/04/10/boot_review/%EC%9D%B4%EA%B2%83%EC%9D%B4%EC%9E%90%EB%B0%94%EB%8B%A4/","excerpt":"","text":"보통 매년 자바(Java)책 한권정도는 보려고 하는데, 올해에는 “이것이 자바다”를 보게되었다. 2015년에 처음 나온 책이라 Java8 버전 내용까지는 추가되어 있었다. 자바관련 책을 보다보면 크게 두분류로 나뉘는 것 같다. 첫번째는 자바라는 언어에 대해 AtoZ 성격으로 모든 내용을 꼼꼼히 담아내는 기본서적이고, 두번째는 개발자가 본인의 경험을 담아 실무에서 많이 사용하는 내용에 대해 중점적으로 쓴 책이다. “이것이 자바다” 는 첫번째 분류에 속하는 책이다. 목차를 보면 알 수 있듯이 Java의 기본적인 내용부터 심화된 내용까지 다루고 있다. 그래서 책 두께도 상당하다. 1200 페이지에 달한다. 하지만 책이 술술 읽힌다. 저자가 글을 쓰는데 노력한 것이 느껴진다. 자바에 익숙해서 인지 모르겠지만 이틀정도면 쭉 훑어볼 수 있을 정도로 매끄럽게 글이 쓰여있다. “이것이 자바다” 책을 쭉 보다보니 좋은 점이 몇가지 있었다.첫번째는 내용의 구성이 꽤 좋다. 목차별로 특정 부분에 치우치지 않고 정말 밸런스 있게 짜여있다. 그래서 자바의 기본서로서 적합하다. 너무 쉽지도 어렵지도 않은 수준에서 자바의 대부분의 내용을 다룬다. 자바를 처음 시작하는 사람이라면 이책을 선택해도 좋을 것 같다. 두번째는 그림이 많다. 대부분의 사람들은 시각을 통해 정보를 가장 잘 받아 들인다. 글로만 설명하는 것 보다는 적절한 그림 한장이 더 도움이 된다. 이책은 그림을 적재적소에 잘 넣어 놓은 것 같다. 많은 내용을 보다가 눈이 피로하다가도 그림을보고 대강의 내용을 파악 할 수 있었다. 세번째는 예제 코드와 실행 결과, 설명이 한눈에 들어온다는 것이다. 많은 책들이 긴 예제 코드를 넣어 놓고 (1),(2).. 번호를 매겨놓고 길게 설명을 하고 마지막에 실행 결과를 보여준다. 페이지를 앞뒤로 왔다갔다 하면서 봐야하는 불편함이 있었는데, 이책은 코드와 함께 설명을 달아 놓고 실행 결과를 캡쳐해서 같이 배치해 두었다. 예제 코드를 좀더 집중해서 볼 수 있었다. 네번째는 예제 코드가 정말 꼼꼼하게 나와있다. 두꺼운 책과 무거운 노트북을 같이 가지고 다니면서 코드를 따라쳐 보는 것은 쉽지 않다. 그래서 책을 쭉 훑어보고 궁금한 내용에 대해서만 코드를 작성해 보는 편인데, 이책은 궁금할만한 내용 대부분을 예제 코드로 담은 것 같다. 강의를 오래한 사람이 쓴 책이라서 그런 것 같기도 하다. 이책의 단점은 각 자바 버전에서 추가된 내용이 무엇인지 구분하기 힘들다는 것이다. 1.6버전에서만 개발하던 사람이 1.7 혹은 1.8 버전을 사용해야 하는 경우 딱 그부분만 찾아서 보기가 쉽지 않다. 이책은 이게 몇 버전에 추가된 내용인지 알 수 없을 정도로 전체 내용에 잘 녹여 있다. 하지만 이런 구성 덕분에 자바를 처음 배우는 사람에게는 매우 좋은 책 일 수도 있다. 또하나 아쉬운 점은 대부분의 내용이 정말 기본적인 수준으로만 나와있다. JVM이나 메모리에 대한 내용이라 든가, 클래스 로더, 리플렉션 등에 대한 내용을 간단한 키워드를 언급하는 수준에서 끝난다. 1.7 이나 8버전에 대한 내용도 좀 더 담겼으면 좋았을 것같다.초보자에게는 매우 좋은 책이고, 중급자 이상에게는 또 다른 책들이 더 필요 할 것 같다. 리뷰를 마무리하면서 한 줄로 결론을 내보자면,좋은 구성 좋은 예제로 쉽게 쓰여진 자바의 기본서 이다.","categories":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}],"tags":[{"name":"java","slug":"java","permalink":"https://kihoonkim.github.io/tags/java/"},{"name":"book","slug":"book","permalink":"https://kihoonkim.github.io/tags/book/"}],"keywords":[{"name":"책리뷰","slug":"책리뷰","permalink":"https://kihoonkim.github.io/categories/%EC%B1%85%EB%A6%AC%EB%B7%B0/"}]},{"title":"마이크로서비스 아키텍처(MSA). 서비스 개발팀 이야기","slug":"Microservices Architecture/first-msa-retro","date":"2018-03-25T06:44:40.000Z","updated":"2021-08-17T00:04:32.693Z","comments":true,"path":"2018/03/25/Microservices Architecture/first-msa-retro/","link":"","permalink":"https://kihoonkim.github.io/2018/03/25/Microservices%20Architecture/first-msa-retro/","excerpt":"","text":"2015년 쯤 아키텍처 연구팀에 잠깐 있었는데, auto Scale in/out, 도커, 대용량 데이터베이스, 대용량 스토리지 등이 연구되고 있었다. 내가 있던 셀은 SaaS나 멀티테넌트 아키텍처가 주된 관심사 였다. 이런 주제들에 적합한 아키텍쳐가 무엇인지 알아보다 보니 자연스레 MSA로 초점이 맞춰졌다. 그때 조대협 님을 초청해서 세미나도 듣고, Chris Richardson 의 일주일짜리 강의도 듣을 수 있었다. 그 당시 MSA계의 국내외 최고의 거장이자 연예인이 아니었나 싶다. 지금와서 생각해봤을때 개인적으로 가장 반성할 점은 MSA를 대용량 처리에만 초점을 맞추고 사내에 전파를 시도했던 것이다. 사실 SDS같이 B2B를 주업으로 하는 곳은 몇몇 분야를 제외하고는 대부분 대용량 트래픽이나 동시성 이슈가 거의 없다. 10K 문제 조차도 개발자 레벨에서 접해볼 기회가 없을 정도인데, MSA 를 그런 이유로 사용하자고 했으니, 관심을 가질 이유가 없었을 것이다. 모놀로틱하게 waterfall 방법으로 개발하고 기존 경험을 기반으로 운영해도 큰 어려움 없이 대부분의 문제를 해결 할 수 있었다. 그러던 중 SI사업을 접고 대부분 솔루션 개발로 회사 비전이 바뀌면서 애자일에 대한 요구가 높아졌다. ‘우리가 이런 기능을 개발했으니 쓰세요’ 에서 ‘어떤 기능을 어떻게 쓰고 싶으세요?’ 로 변한 것이다. 개발하는 제품의 초점이 회사에서 사용자로 옮겨간 것이었다. 초기에 모든 요구사항을 수집하고 설계하고 개발하고 테스트하던 아주 긴 호흡의 개발 방법이 통하지 않는 시대가 온 것이었다. 실제 사용자의 목소리를 듣고 이를 반영해야 했다. 요구사항은 언제나 변할 수 있었다. 이런 방법을 적용하고자 Pivotal labs와 ThoughtWorks의 방식을 적절히 받아드린 ACT라는 곳이 회사에 생기게 되었다. 우리 팀은 개발 팀을 작게 구성하고, PM(product Manager), Dev, CX라는 역할자만 팀내에 두고 각자의 역할과 책임을 가지고 제품에 ownership을 가지고 빠르게 개발해 나가길 원했다. 하지만 SDS라는 대기업, 그안에 있는 사업부, 개발팀은 거대한 공룡과 같았다. 작게 개발하고 자주 배포할 수 있는 구조가 아니었다. 한 팀을 그렇게 만든다고 나머지 톱니바퀴가 같이 돌아갈 리가 없었다. 전체 팀이 Agile하게 일하고 독립적으로 빌드 배포가 가능해지길 원했다. 우리가 일하는 방식, 우리가 원하는 개발 문화를 가능하게 해줄 아키텍쳐가 필요해졌다. 그렇게 2년만에 우리는 다시 MSA를 꺼내 들게 되었다. eventuate blogThe microservice architecture enables teams to be agile and autonomous. Together, the team of teams and the microservice architecture enable continuous delivery/deployment.마이크로 서비스 아키텍처를 통해 팀은 민첩하고 자율적으로 업무를 수행 할 수 있습니다. 모든 팀들이 마이크로 서비스 아키텍처를 함께 사용하면 지속적으로 전달 / 배포 할 수 있습니다. 서론이 좀 길었다. 그다지 경험도 없는 마이크로서비스 아키텍처를 그 복잡도를 감수하면서까지 맨땅에 해딩하듯이 도입하게된 배경을 설명하고 싶었다. MSA를 적용하고자 할때는 가장 근본적인 목적이 있어야 한다. MSA는 서비스들이 잘 동작하게 만들기 위해서 별도의 수많은 컴포넌트가 있어야 하고, 그를 위해 많은 의사결정 포인트가 존재 한다. 이때 근본적인 목적이 그 선택의 기준이 되어 준다. 예를 들면, MSA에서 가장 이슈가 되는 서비스의 크기는 얼마 만해야 하는가 이다. 이론적으로 서비스를 Bounded Context 단위로 나누고, Bounded Context는 하나의 Aggregate를 갖는 것이 좋다고 말한다. 그렇게 되면 서비스가 굉장히 잘게 나눠져야 하고, 한 팀이 여러 서비스를 관리해야만 한다. 즉, 코드 repository가 많이 지고 각각의 빌드 파이프라인도 많이 진다. 여러 서비스를 개발하기위해 IDE도 자주 스위칭을 해야 할 것이다. 우리는 크게 4,5 개 정도의 도메인을 식별했고, 그안에서 더 나눠져야 하는 서비스가 있다면, 정말 큰 이유가 있지 않다면 동일한 서비스내에 놓고 Rest URI 수준에서 분리했다. 우리의 근본적인 목적은 여러팀이 Agile하게 일할 수 있도록 만드는 것이 었기 때문이다. 프로젝트의 기본적인 기술스택은 다음과 같다. 서비스 Java8 Spring-boot-web Spring-data-jpa, QueryDSL, MaridDB, flyway Spring-cloud-stream, rabbitmq Swagger (spring-fox-swagger-ui) Test: junit, mockito, wiremock, rest-assurd, spring-cloud-contract 공통 Spring-cloud : Zuul, Eureka, Config Server, Hystrix, OpenFeign(Ribbon), Sleuth Elasticsearch, Fluentd, Kibana Redis AWS 서비스 레벨는 각 서비스 개발팀 마다 조금씩 다르지만 거의 비슷하다. Database만 데이터의 목적에 맞게 다르게 가져간 정도이다.아키텍트 레벨에서 가져가는 공통 부분은 처음부터 다 들어온 것은 아니고, 진행 중에 필요에 의해서 하나씩 추가되었다. 테스트 전략은 백엔드 서비스에서는 크게 4단계로 진행했다. (각 테스트의 이름은 흔히 통용되는 것과 좀 다를 수 있다. 전체 팀이 모여서 각 테스트 단계의 목적과 의미에 대한 합의가 필요하다.)(참조: Testing Strategies in a Microservice Architecture) unit test: 클래스 레벨, 주로 의존관계에 있는 클래스는 mocking. functional test: 서비스 레벨, 다른 서비스의 API or Message queue는 stubbing. 자신의 서비스 내에서는 end-to-end (api호출 ~ database까지) contract test: 서비스간 api 사용하는 spec만 테스트 integration test: 실제 테스트 환경에서 실행. 전체 서비스와 database, rest api, message queue 등 모두 실제로 흐름 각 기술스택이나 테스트 단계에 대해서는 다음에 다시 정리하기로 하고, 이번 글의 본래 목적이었던 MSA로 진행하면서 겪었던 문제들에 대해서 되돌아 보고자 한다. 개발팀과 운영할 팀이 다르다.가장 안타까운 부분이다. 이 제품은 우리팀이 개발한 후에 다른 팀에 인수인계를 하는 것이 전제되어 있었다. 따라서 개발하는 팀의 이해관계자와 운영할 팀의 이해관계자가 다를 수 있고, 사용자도 다를 수 있다. 개발팀의 경험과 실력또한 다를 수 있다. 그렇기 때문에 Product Owner 입장에서는 모든 의사결정을 보수적으로 가져갈 수 밖에 없다. 아키텍트 역시 기술 스택은 java, spring을 기본으로 가져가기를 원했다. 심지어 controller-service-dao 패턴을 반드시 지키기를 원했다.진정한 Decentralized 된 MSA를 적용하고자 한다면 ‘You build, You run it’ 이 기본 전제가 되어야 할 것 같다. 모든 부분에서 Polyglot 하게 할 수는 없다.프로젝트 초반에 가장 큰 싸움이었던 것 같다. 파이썬을 좋아하는 개발자도 있고, nodejs를 좋아하는 개발자도 있다. 개인적으로는 Go로 개발하는 것에 재미를 들이고 있던 시기였다. 하지만 우리는 다뤄야할 도메인과 데이터에 관계없이 java, spring을 사용해야만 했다. msa는 목적에 맞게 폴리글랏 하게 개발 할 수있는 장점이 있다. 하지만, 일부 개발자가 좋아하는 언어로 개발해도 된다는 말은 아니다.개발 언어가 다양해지면, 전체 시스템은 관리가 복잡해 진다. 빌드환경, 배포환경도 달라져야 한다. 테스트나 모니터링을 위한 툴도 다양해야 하고, 튜닝할 포인트도 각기 다를 것이다. 즉, 언어가 많아질 수록 전문성이 낮아 질 수 밖에 없다. 이러한 이유로 netflix도 jvm 언어로 시작한 것 같다.(사실 java8 이후 부터는 java로 개발하는 것도 꽤 만족스럽긴 하다.) Local Test가 힘들다.모든 기능이 한 프로젝트에 담겨있고, 하나의 DB를 바라보고 있다면, local 환경에서 테스트하기가 쉽다. 특히 docker가 이를 더 쉽게 도와준다. db, rabbitmq 를 설치해서 실행하는데 몇 초면 끝난다. 하지만, MSA는 여러 서비스가 존재한다. 내가 호출해야하는 서비스가 다양한 경우 이를 모두 local 환경에 구축하긴 매우 어렵다. 다른 서비스의 내부 환경을 이해해야 한다는 뜻이기 때문이다.주로 내 데이터는 로컬 환경, 다른 서비스는 테스트 환경을 바라보게 하는데, 해당 서비스가 내려가있거나, 가끔 데이터가 꼬이는 일이 발생하기도 한다. 다같이 데이터 한번 지웁시다! 하는 말도 안되는 상황이 발생하곤 했다. Monolithic환경에서는 항상 살아있던 다른 서버스 들이 간혹 죽어있다.MSA에서 서비스는 다른 프로세스에서 실행되는 컴포넌트라는 의미다. 즉, 다른 서비스가 살아있음을 보장 할 수 없다. 다른 서비스를 호출했는데 503 (Service unavailable) 상태코드가 리턴된 경우, 내 서비스에서는 어떻게 반응을 해야 할까 고민을 해야 한다. monolithic 환경에서는 할 필요가 없는 고민이었다. lifecycle이 항상 같았으니까..MSA에서는 Circuit Breaker 패턴을 사용할 수 있다. 우리는 이를 위해 Hystrix를 적용했다. Hystrix는 죽어있는 서비스에 대해서 circuit을 open 해서 요청이 timeout 될 때까지 길게 기다리지 않게 하고, 비즈니스 요구사항에 맞게 fallback 정책을 가져갔다. 같이 503을 리턴하는 경우도 있고, 일시적으로 캐싱된 데이터를 리턴하는 경우도 있었다.하지만, 인증관련 서비스가 내려가있다면…휴… ACID가 보장이 안된다.MSA는 기본적으로 분산환경이다. 모든 서비스가 네트워크 상에 존재한다. 따라서 데이터의 일관성을 보장 하기 어렵다. 전체 서비스가 엮이면 @Transactional 어노테이션의 마법이 통하지 않는다. 2PC는 어렵고, 해본적도 없다. 포기하는 편이 마음이 편하다. http로 요청을 보냈는데, 서비스가 죽어있다면 다른 서비스에 데이터 반영하는 것을 포기하고 내꺼만 잘 반영하자는 의미가 아니다. 우리는 이런 문제를 위해 다른 서비스에 CUD를 발생시켜야 하는 경우에 Event Driven Architecture를 적용하고 Eventual Consistency를 달성하고자 노력했다. Rabbitmq를 통해 message를 전달했다. rabbitmq가 qos level 1을 지원하므로 최소 한번은 전달하는 것을 보장해 준다.하지만 message 전달이 실패하거나 서비스에서 처리 중 에 오류가 난 경우 보상작업을 해주거나 별도 비즈니스 흐름을 가져가야 하는 복잡함이 추가로 생겨났다. 다른 서비스의 모델이 변경되는 것에 영향을 받는다.내가 가진 데이터를 Rest API로 다른 서비스 혹은 UI에 제공한다는 의미는 API를 통해 다른 서비스들과 계약을 맺는 것으로 바라 볼 수 있다. 하지만 소프트웨어 개발이 언제나 그렇듯 요구사항은 변경된다. 즉 데이터가 변경되고 모델이 변경될 수 있다. 많이 하는 실수지만 데이터베이스의 모델이 그대로 Rest API의 response로 드러난다. 이 경우 서비스별로 독립적으로 빌드 배포가 가능하다는 이유로 계약을 어기고 변경 후 배포하게 된다. 해당 API를 호출하는 순간 내 서비스 기능과 상관없는 에러를 보게 될 것이다. 특히 개발 중에는 더 빈번히 발생한다. 이를 위해 우리는 Consumer driven contract test를 추가하게 되었다. 하지만 contract test는 정말 귀찮다. spring cloud contract의 경우 다른 서비스 소스에 내가 원하는 api의 response를 spec 으로 추가해야 하고, 그 서비스에서 spec을 기준으로 verify test를 진행하고, spec을 만족하는 stub server를 만들어 maven에 배포해야 하고, 내 서비스에서는 그 stub server를 maven에서 내려 받아서 contract test를 작성해야 한다. 말로 설명해도 굉장히 복잡하고 귀찮다. 서비스 팀간에 많은 의사소통이 필요하다. 이런 문제가 있을때 관련해서 많이 언급되는 것이 Tolerant Reader 패턴 인데, spring에서 서비스간 통신시 jackson을 사용하는 경우 할 수 있는 것이 별로 없다. (참고: Robustness principle) 하지만 중요한 것은, 내 서비스에서 API를 제공하면서 다른 서비스를 어떻게 바라보느냐 이다. DDD context map에서 말하는 customer-supplier 관계로 바라본다면 supplier가 주도하지만 결과적으로는 customer에서 원하는 결과를 제공해 줘야 한다. 하지만 다른 서비스를 단순히 준수자(Conformist)로 바라본다면 내가 변경하는 대로 알아서 반응하기를 기대하는 것이다.(예를 들면, naver open api 스팩이 변경되면 사용하는 쪽에서 알아서 변경 해야하는 준수자가 되는 것이다.) 사실 변경하는 입장에서 다른 서비스를 준수자로 바라보는 것이 편하긴 하다. 하지만 내 변경으로 인해 전체 시스템이 동작하지 않게 될 수도 있다. 우리 프로젝트에서는 모든 API에 대해서 복잡한 Contract Test를 작성해 나가기 보다는 꼭 필요한 것에 작성을 하고, 다른 것들이 변경되는 것에 대해서는 커뮤니케이션으로 빠르게 해결해 나가는 방향으로 정했었다. 서비스 팀이 많지 않고 가까이서 함께 일하기 때문에 가능한 일이었다. UI와 Service의 모델이 다르다.UX 디자이너 입장에서는 구현의 복잡함에 관계없이 사용자에게 가장 가치있고 편한 디자인을 해야했다. 서비스 개발자 입장에서는 의존관계를 잘 분리하고 최대한 단순한 모습으로 소스와 데이터를 관리 해야했다. 하지만 간혹 잘 나눠진 여러 서비스를 호출해서 하나의 응답으로 리턴해야 하는 경우가 있는데, 이 경우 두 가치가 대립하게 된다. 양쪽다 잘 지켜져야 하는 부분이기 때문에 PM이 중간에서 밸런스를 잘 맞춰가며 의사결정을 해야 할 것이다.개발팀에서 고민했던 것은 이런 서비스간 합성(aggregation)이 있을 경우, 혹은 모델을 변경(transformation)해야 하는 경우 중간 mediation layer를 가져가야 하는 가였다. 결론적으로는 서비스 합성은 필요한 서비스의 controller에서 처리했고, 모델 변경은 UI에서 컨버팅하는 로직을 넣는 것으로 개발되었다.많은 블로그에서 API Gateway의 기능 중 하나로 mediation기능(aggregation, transformation…)을 처리할 수 있는다고 나와 있다. 개인적으로는 게이트웨이에서는 단순히 인증이나 라우팅 정도만 처리하고 서비스에 특화된 기능 들은 서비스내부에서 처리하거나 mediation을 위한 서비스를 별도로 놓는 것이 좋다고 생각한다. 클라우드 비용이 많이 든다.서비스가 늘어가고, Database, Eureka, Config server 등 컴포넌트가 추가되고, 이 모든 것들이 이중화되고, 테스트 환경이 늘어가면서, AWS 비용이 수직상승하게 되었다. 대기업에서 한달에 몇 백만원 정도의 비용이 뭐 그리 대수냐 싶겠지만은 B2B 제품들은 사용자 수를 늘리고 동시접속 처리를 잘하는 것이 목적이 아니다. 따라서 인스턴스를 늘리는 것 처럼 개발을 위해 서버 운영비용에 크게 투자하는 것을 최소화 해야 한다. 쉽게 말해서 수지타산이 맞지 않는다.AWS를 쓰던 환경에서 Heroku로 옮기거나, 로컬 서버로 내리는 등의 변경이 자주 발생했다. 개발 환경은 처음부터 내부 서버를 이용하는 것이 마음 편할 것 같다. 이런 일이 자주 일어나다 보니 배포 환경 설정을 위해 Ansible을 적용하고 있다고 들었다. 빛은 생각보다 느리다.AWS는 서울 리전을 사용하고 비용 문제로 DB는 Heroku를 사용한 적이 있는데, Heroku는 한국 리전이 없다. 몇 ms 로 처리되던 것들이 몇 초가 걸리는 진귀한 경험을 하게된다. 네트워크가 빛으로 통신한다고 빠르다고 생각하면 정말 큰 오산이다. 만약 서비스간 통신이 바다를 넘나드는 일이 있다면 빠른 인터넷 속도를 경험하며 자라온 한국 사람들에게 있을 수 없는 경험이 될 것이다. 아키텍트팀의 설정변경으로 인해 서비스의 소스가 다시 빌드, 배포가 될 때가 있다.나는 우리 서비스의 소스가 개발팀의 변경에 의해서만 재 배포가 되기를 원했다. 아키텍트 팀의 환경설정 변경으로 인해 자주 재빌드 되고 그 과정에서 빌드가 실패하고 이로 인해 실제 기능이 잠시동안 배포되지 못한 일이 있었다. Spring cloud Config server가 도입된 이후 설정 변경으로 빌드가 깨지는 문제는 많이 해결되긴 했지만 알 수없는 설정이 생기기 시작했다. 또한 서비스의 로직과 상관없이 오류가 발생하기도 했다.Code ownership이 어디까지 가질 것이냐, Whole team을 어디까지 바라볼 것 인가의 문제였다. 기본적으로 코드의 변경은 서비스 개발 팀으로 한정 해야 한다고 생각한다. 빌드가 깨지고 버그가 생기면 조치해야 하는 팀은 서비스 팀이기 때문이다. 서비스팀 밖에서 적용하고자 하는 코드가 있다면 Merge request를 이용했으면 좋겠다. 좀 더 나아가서는 Service Mesh 패턴을 사용하는 것도 한가지 방법일 것 같다. 서비스 개발자는 아키텍처를 얼마나 이해해야 할까?서비스 팀 개발자에게 MSA로 개발하면 뭐가 다른 가요? 라고 물어봤을때 “똑같아요” 라는 대답을 하는 것을 많이 봤다. 그저 다른 팀 서비스를 클래스 참조하거나 DB Table join 하던 것에서 API로 호출 하는 것이 다를 뿐이다.서비스 팀 개발자가 Netflix oss나 Cloud native application, Twelve factor app 등을 모두 알아야 할까? 위 표와 같이 수많은 컴포넌트들을 알아야 할까? 당연히 알면 좋고 몰라도 크게 상관 없지만, 팀 내에 누군가는 알아야 하고 팀원들에게 설명해 줄 수 있어야 한다고 생각한다. 예를 들어 RestTemplete을 사용하다가 Ribon Client로 바꾸는 것으로 결정이 됐다면, 왜 그런 결정이 됐고, 실제 시스템이 어떻게 흘러가게 될지 예측을 할 수 있어야 할 것이다.Microservices Architecture는 말 그대로 아키텍처이다. 언급되는 대부분의 컴포넌트 들이 서비스 외부의 것들이고, 아키텍트 팀에서 관리가 될 것이다.서비스 개발팀은 이런 아키텍처에서 잘 돌아 갈 수 있도록 stateless, loosely coupling, high cohesion 한 서비스를 만드는 것이 가장 중요한 것 같다. MSA에서 DDD는 필수일까?MSA와 항상 같이 언급되는 것들이 있다. DDD, CQRS, Event-Driven, Event sourcing 등등..객체지향을 잘 이해하면 java로 더 아름답게 개발할 수 있는 것처럼, DDD를 이해하면 MSA를 더 잘 개발할 수는 있을 것이다. 하지만 필수는 아니라고 생각한다. 이런 용어들에 겁먹고 MSA를 시도조차 못하지는 않았으면 좋겠다.내 서비스에서 다루는 데이터를 API를 통해서 연결만 해 준다면, 내부 구현은 기존에 사용하던 방식 그대로 해도 된다. 다른 서비스와 의존관계를 더 잘 분리 할 수 있도록 도와주는 도구들일 뿐이고, 필요에 의해서만 도입하면 된다.개인적으로는 MSA에서 서비스 개발시 가장 중요한 것은 Metaphor 라고 생각한다. 본래의 의미에 가장 적절한 이름을 짓는 것, 같은 이름이라도 각 서비스에 맞는 의미를 부여하는 것, 이 것이 PM, Designer, Dev가 팀으로서 함께 고민해야 하는 가장 중요한 부분이다. 결론적으로..참 복잡하고 어렵다. 알아야 할 것도 많다. 우리는 이런 복잡도를 감수하면서 까지 MSA를 적용할 가치가 있는 것일까? 사실 지금도 매일 많은 문제에 부딪히고 있다. 하지만, 이 모든 과정이 좋은 개발 문화를 만들어 가는 밑거름이 되리라고 믿는다. 개발자로서는 정말 재미있는 경험이다. 내가 알고있는 모든 지식을 쏟아 부울수 있는 기회였다. 회사내 많은 제품들이 지속적으로 개선 가능한 구조로 개발될 수 있었으면 좋겠다. 고려되지 못한 것들..auto scaling, data partioning, design for failure….","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"agile","slug":"agile","permalink":"https://kihoonkim.github.io/tags/agile/"},{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"2017년 회고","slug":"retro/retro-2017","date":"2018-01-25T06:44:40.000Z","updated":"2021-08-17T00:04:32.705Z","comments":true,"path":"2018/01/25/retro/retro-2017/","link":"","permalink":"https://kihoonkim.github.io/2018/01/25/retro/retro-2017/","excerpt":"","text":"2018년 1월이 끝나가는 시점이지만, 작년의 일들이 기억속에서 사라지기 전에 회고를 해보려고 한다. GoodGo, Reactjs 등 새로운 기술을 사용해서 개발한 것나는 믿어주는 팀원들과 함께 한 것남의 지식을 정리만 하다가 나만의 경험과 생각을 정리해 발표한 것MSA를 실제 구현하고 있는 것페어 프로그래밍에 대해 더 깊게 고민해 본것 Bad개발을 일로서만 한 것더 다양한 사람들을 만나지 못한 것같이 일하는 팀원들이 유지되지 못하는 것평정심을 유지하지 못한 것 Try (Action Item)개인 프로젝트 진행영어.. 크게 보면 3가지 프로젝트에 투입되었고, 포기하지 않고 끝까지 읽은 책은 7권이고, 블로그는 크게 3가지 주제로 썼던 것 같다. 개발첫 번째 프로젝트는 2016년 ACT로 합류하면서 계속 진행해 왔던 프로젝트다. 안드로이드 개발이었고, 실제 제품이라기 보다는 프로토타입 성격이었다. 사용자 가치를 중심으로 불필요한 요소를 제거하고 빠르게 개발해 나가는, 우리 회사에서는 경험하기 쉽지 않은 일이 었다. 하지만.. 실제 계약이 되고, 프로토타입이 제품으로 변경되면서 엄청난 기술적 부채로 돌아 왔던 것 같다. 두 번째 프로젝트는 챗봇을 구성하기 위해 대화의 흐름을 설계하는 dialog designer를 개발하는 것 이었다. reactjs와 golang 을 이용해서 개발했다. 둘 다 처음 접한 기술이라 엄청 난 삽질을 경험 할 수 있었고, 덕분에 관련 내용을 블로그에 정리할 수 도 있었던 것 같다. 관련 내용으로 naver에 방문해서 발표도 할 수 있었다.(http://keen.devpools.kr/java2go/#dev)(챗봇 프로젝트를 진행하면서 알게 된 사실들 http://keen.devpools.kr/2017/05/30/20170530/) 세 번째 프로젝트는 제품을 만든 것은 아니고, 전자 SW센터에 애자일관련 개발 프렉티스를 코칭 해주는 일이 었다. 약 두달 정도 진행했고, 개발이 아닌 코칭이라는 일이 얼마나 어려운 일인지 알게 되었다. 사실 코칭보다는 컨설팅이라는 생각으로 참여했기 때문에 더 어렵지 않았나 싶다. 네 번째 프로젝트는 현재도 진행 중이지만, digital signage를 위한 플랫폼을 구축하는 것이다. 나는 컨텐츠를 스케쥴링해서 각 디바이스에 해당 스케쥴을 배포해 주는 서비스를 담당해서 개발하고 있다. 이 프로젝트에서 가장 재밌는 부분은 MSA이다. 2014년에 chris richardson의 강의를 1주일 정도 듣고, 관련 내용을 이론으로만 접했었는데, 실제로 하나씩 구현해 나가고 있다. 책가장 재밌게 봤고 인사이트를 받았던 책은 The LEAN mindset 이었다. 애자일 코리아 컨퍼런스 에 참여했다가 선물로 받았던 책인데, 일단 얇아서 읽기에 부담이 없었다. 가장 큰 주제는 성장마인드셋과 고정마인드 셋에 대한 내용이었다. 이와 관련해서 드라이퍼스 성장 모델에 관한 글을 읽게 되었는데, 개인적으로 페어를 함에 있어서 큰 인사이트를 얻을 수 있었다. project~ 2017.02 : PG가 사용할 APP 개발. front:Android. back:X~ 2017.07 : Chatbot을 위한 Dialog Designer 개발. front:reactjs, back:Go(gorilla)~ 현재 : digital signage를 위한 솔루션 개발. MSA 적용. front:reactjs, back:java(spring cloud) bookGo in actionJava8 in actionFunctional programming in java8The LEAN mindset테스트주도개발 TDD 실천법과 도구마이크로서비스아키텍처 구축그림으로 배우는 http&amp;network basic articleGo : http://kihoonkim.github.io/categories/ReactGo/golang/TDD : http://naver.me/xm55qEl7 http://kihoonkim.github.io/2017/03/11/Agile/TDD/Pair Programming : http://naver.me/GJbbXqky slideTDD: https://www.slideshare.net/koreakihoon/tdd-android-unit-testAgile: https://www.slideshare.net/koreakihoon/agile-fundamentals-73040911AWSome day 공유: https://www.slideshare.net/koreakihoon/act-continuos-learning-day 강의 및 발표SCSA8,9기: https://www.slideshare.net/koreakihoon/agile-fundamentals-73040911Naver d2: http://d2.naver.com/news/9972986SDS,전자: https://www.slideshare.net/koreakihoon/tdd-android-unit-test","categories":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}],"tags":[{"name":"retro","slug":"retro","permalink":"https://kihoonkim.github.io/tags/retro/"}],"keywords":[{"name":"Retro","slug":"Retro","permalink":"https://kihoonkim.github.io/categories/Retro/"}]},{"title":"페어 프로그래밍이란 무엇 일까?","slug":"Agile/pair-programming","date":"2018-01-01T07:16:39.000Z","updated":"2021-08-17T00:04:32.683Z","comments":true,"path":"2018/01/01/Agile/pair-programming/","link":"","permalink":"https://kihoonkim.github.io/2018/01/01/Agile/pair-programming/","excerpt":"","text":"대화를 통해 서로의 생각을 공유하는 방법 우리팀(ACT)에서는 개발자뿐만 아니라 PM, CX등 모든 역할자가 Pair로 일을 한다. 그래서 Pair Programming보다는 Pairing 이라는 용어로 사용하고 있기도 하다. 결국엔 두 명이 짝을 지어 일을 한다는 것인데, 페어 프로그래밍의 진행 방법과 장단점 등에 대해 경험을 공유해 볼까 한다. Pair programming is an agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently. - wikipedia - 페어 프로그래밍 진행 방법은 기본적으로 한 명이 타이핑을 하고 다른 한 명은 실시간 리뷰를 하는 것이다. 그리고 역할을 주기적으로 변경하며 진행하면 된다.장비는 모니터, 키보드, 마우스 하나만으로 진행 할 수 도 있고, 모니터, 키보드, 마우스를 두 개씩 연결하고 각자 사용 할 수 도 있다. 아래는 딱히 정확한 명칭 없지만 개인적으로 진행해 봤던 방식들이다. 드라이버 &amp; 네비게이터가장 일반적이고 전통적인 방법으로 한 명은 드라이버로 소스코드를 타이핑 하고, 다른 한 명은 네비게이터로서 작성되는 소스코드를 실시간으로 리뷰를 하고 큰 그림을 염두에 두고 가이드를 해 나가는 방법이다. 핑퐁(Ping-Pong)TDD로 개발을 하는 경우, 한 명은 실패하는 테스트 케이스를 작성하고, 다른 한 명은 테스트를 성공시키기 위한 구현코드를 작성하는 방법이다. 한 명이 계속 키보드를 잡고 코딩을 하는 것을 방지 할 수 있다. 키보드 &amp; 마우스한 명은 마우스만 사용하고, 다른 한 명은 키보드만 사용하는 방법이다. 잘 사용하지 않는 방법이긴 하지만, 새로운 툴이나 단축키 등을 배울 때 사용하면 유용할 수 있다. 몹(Mob) 프로그래밍일명 떼 코딩이라고 불리는 방법으로, 돌아가면서 한 명씩 드라이버가 되고 나머지는 네비게이터가 되어 개발을 진행한다. 가장 큰 장점은 커뮤니케이션 비용을 줄일 수 있다는 것이다. 프로젝트 초반에 코딩 스타일을 맞춰야 하거나, 주기적으로 코드리뷰를 하는 경우에도 사용하면 좋다. 하지만 단점은 네비게이터가 여러 명이다 보니 의견 통합이 어려울 수 있고, 간혹 자리를 비우거나 딴짓을 하는 사람이 생기기도 한다. 우리 팀의 경우는 모니터, 키보드, 마우스 모두 두 개씩 준비해서 각자 사용하고, 정해진 역할, 시간 없이 실시간으로 대화를 하면서 누구라도 타이핑을 할 수 있게 한다. 페어 프로그래밍을 하면 좋은 점지식 공유같이 페어 프로그래밍을 진행 했던 사람들에게 물어보면 가장 많이 장점으로 언급되는 부분이다. 웹 개발을 하더라도 누구는 JavaScript를 잘하고 누구는 CSS를 잘 할 수 있는데, 이런 경우 같이 페어를 하면 서로 몰랐던 부분을 많이 배울 수 있게 된다. 그리고 팀에 새로운 멤버가 들어온 경우, 팀의 개발환경이나 개발 스타일 등에 대해서 문서로 전달 하는 것이 아니라 페어 프로그래밍을 통해 같이 개발하면서 공유해 줄 수 있다. 또한 기술적인 스킬 뿐만 아니라 페어가 가지고 있는 좋은 습관들도 배울 수 있는 좋은 기회가 된다. 심리적 안정감개발을 할 때, 간혹 어려운 문제가 있더라도 ‘페어가 있으니 해결할 수 있겠지?’ ‘페어가 해결해 주겠지?’ 등의 심리적으로 기댈 수 있다. 실제로 페어가 해결 하기를 기다리는 것이 아니라 같이 고민을 하게되는 것이다.새로운 언어나 프레임워크 등을 사용해야하는 경우에도 혼자서는 중간에 포기하는 경우가 있는데, 페어와 함께 하다 보면 끝까지 도전을 해보게 되기도 한다. 높은 업무 집중도9시 출근해서 6시 퇴근 할 때까지 어느 정도로 집중해서 일을 할 수 있을까? 카카오 톡이나 라인 같은 메신저로 친구들과 대화도 나누고, 사내 메신저를 통해 동기들과 대화도 하고, 이메일도 주고 받게 되고, 티타임을 가지는 등 업무 외적으로 사용하는 시간이 많이 있을 것이다.덕분에 중간중간 일의 흐름이 많이 끊기게 된다. 하지만 페어와 함께 개발을 하다 보면 불필요하게 사용하던 개인적인 시간을 최소화 하고, 개발에 집중을 하게 된다. 실시간 코드 리뷰작은 타이핑 실수부터, 큰 설계 결함 등 페어 프로그래밍을 하다 보면 실시간으로 해당 로직에 대해서 코드리뷰를 할 수 있다. 내 소스코드에 대한 피드백을 가장 빠르게 받게되는 것이다.이를 통해 설계가 좋아지고, 결함도 줄어 들고, 일정한 수준의 코드 품질을 유지할 수 있었다는 의견이 많이 있다. 그리고 페어와 함께 개발을 하다 보면 코드 리뷰뿐만 아니라 같이 설계에 대한 고민을 끊임 없이 나눌 수 있는 사람이 있다는 것이 큰 장점 인것 같다. 집단적 코드소유Collective Ownership페어 프로그래밍을 하게 되면 자연스럽게 일의 담당자를 지정할 수 없게된다. 즉, 업무마다 담당자를 정하고 그 업무만 개발 하는 것이 아니라, 팀으로서 전체 제품에 대해서 함께 고민하고 개발을 해나가는 것이다. 모든 개발자들이 어떤 기능이든지 추가나 버그 수정, 리팩토링 등을 진행할 수 있다. 특정 업무에 대한 병목이 발생하는 것을 막을 수 있고, 코드 전체에 대해서 개발자들이 함께 아이디어를 내고 공유할 수도 있다. 피어 리뷰(Peer Review)우리 팀은 항상 같이 일한 팀원 들에게 피어 리뷰를 하고 있다. 하지만 사실 같은 팀에 속해서 일을 하더라도 업무적으로 엮이지 않는다면 그 사람에 대해서 제대로 알기 어렵고 대외적인 이미지만 가지고 평가를 하게 된다. 하지만 페어 프로그래밍을 진행하면서 모든 팀원들과 같이 일을 하고 많은 대화를 나누게 됨으로써 동료들의 장단점을 더 잘 알게 되고, 그 사람의 성장을 위한 진실된 피드백을 줄 수 있었다. 자연스럽게 팀워크도 더 좋아지게 됐던 것 같다. 페어 프로그래밍을 하면 안 좋은 점생산성저하많은 팀이 페어 프로그래밍을 하지않는 가장 큰 이유라고 생각된다. 관리자 입장에서는 한 명이 할 일을 두 명이 하고 있으니, 생산성이 반으로 줄어든다고 생각하기 때문일 것 이다.경험상 봤을 때, 1/2은 아니더라도 분명히 생산성이 두 명이 각자 개발하는 것에 비해서 많이 떨어진다는 느낌을 받기는 했다. 오래되긴 했지만 몇 몇 논문에서 15% 시간이 더 걸리고, 15% 결함이 줄었다는 연구 결과도 있다.앞서 장점으로 말했던 가치를 위해서 떨어지는 생산성은 미래를 위한 투자로 생각하는 것이 좋은 것 같다. [참고 논문]Pair programming productivityThe Costs and Benefits of Pair Programming 키보드 정복자실제 페어 프로그래밍을 하다보면, 시니어와 주니어 개발자가 같이 하는 경우가 많은데, 드라이버와 네비게이터의 역할 바꿔가면서 진행해야 하지만 시니어 개발자 혼자 개발을 하게 되는 것을 자주 볼수 있다. 생산성이 떨어지는 문제를 못 참는 문제도 있고, 주니어 개발자가 작성하고 있는 코드를 가만히 보고만 있을 수 없는 것이다. 처음에는 말로 이렇게 해 저렇게 해 지시를 하다가 결국 키보드를 점령해 버린다. 이런 일이 반복되면서 주니어 개발자는 의기소침하게 되고 키보드 타이핑 하는 것을 두려워하게 된다. 페어 프로그래밍을 했다고는 하지만 대화 없이 한 사람의 주도하에 개발이 끝나게 되는 것이다. 감정 노동항상 좋은 사람과 일을 하면 좋겠지만, 우리는 언제나 마음이 맞지 않은 팀원과 함께 하게 될 것이다. 혹은 마음은 잘 맞더라도 개발하는 스타일이 매우 다른 사람이 있을 수도 있다. 사람 마다 가지고 있는 성격이나 스타일이 쉽게 바뀌거나 개선 할수 있는 부분이 아니기 때문에 해결하기 어려운 문제라고 생각된다. 우리나라 정서 상 대놓고 말하기 어려운 부분이기도 하다.그 날 하루는 어쩔 수 심한 감정 노동에 시달리게 될 것이다. 피곤함페어와 함께 하루 종일 집중해서 개발을 하고, 끊임없이 대화를 한다는 것은 매우 많은 에너지를 소모하게 만든다. 중간 중간 쉬는 시간을 갖지 않으면 체력적으로 힘들어서 포기하게 될 것이다. 페어 프로그래밍을 잘하기 위한 방법들페어 프로그래밍은 매우 단순한 agile Practice이다. 그냥 두 사람이 같이 앉아서 같은 것을 함께 개발하는 것이다. 하지만, 실제로 해보면 매우 어렵게 느껴지고, 금새 ‘우리랑은 맞지 않는 방법이야‘ 라며 포기를 하게 된다. 어떻게 하면 좀 더 잘할수 있을까? 너무 상투적인 얘기이지만 가장 중요한 방법은 “많은 대화와 소통” 이다. 언제나 설계에 대해서 같이 고민하고 대화를 해야 한다. 화이트 보드를 이용해서 시각적으로 표현해 가면서 이야기 하는 것을 추천한다. 페어 프로그래밍을 한다고 모니터 앞에만 앉아 있어야 한다는고 생각하는 것은 옳지 않다. 그리고 꼭 페어끼리만 대화를 해야하는 것도 아니다. 그 순간 필요하다면 다른 팀원들도 불러서 의견을 듣는 것도 좋을 것이다. 그리고 코딩을 하는 순간에도 ‘이런 생각을 가지고 있는데, 이렇게 한번 개발해 볼게요.’ 라며 현재 머리 속에 있는 생각을 계속해서 공유를 해야 한다. 그렇지 않으면 한 사람이 드라이버가 되서 개발 하는 순간에 정적이 흐르게 되고, 네비게이터는 딴 짓을 하게 될 것이다. 항상 현재 머리 속에 있는 생각을 가감없이 공유하길 바란다. 무엇보다 생각하는 것을 멈추면 안된다. ‘페어가 알아서 하겠지’ 라는 안일한 생각보다는 항상 더 나은 코드를 작성하기위해 노력하고, 함께 일을하는 페어에게 하나라도 더 공유하기 위해 노력해야 한다. 생각이 멈추면 대화도 멈추게 된다. 항상 끊임없이 더 나은 방법을 위해 생각을 하고 이야기를 해야 할 것이다. 만약 시니어 개발자와 주니어 개발자가 같이 페어를 하는 상황이라면 다음 글을 한번 읽기를 추천한다. 아래와 같은 5가지 팁이 나와있다. ※ 주니어와 함께하는 페어링 방법(Pairing with Junior Developers) Don’t type.직접 개발을 하지 말고, 주니어에게 무엇을 입력해야 하는지 알려주세요. 토론하고 질문하세요. Let them make mistakes.직접 문제를 해결해 주면 일련의 규칙만 배우게 됩니다. 그냥 시도하게 하고 어떻게 되는지 지켜보세요. 문제가 발생하면 왜 안 되는지 이해할 수 있도록 도와주세요. Take Breaks주니어와 시니어의 경험의 차이로 인해 많은 추가 설명을 해야 될 것입니다. 정말 많이 피곤할 것입니다. 휴식을 취하세요. Be prepared to say “I don’t know”“나도 모른다. 그래도 좋은 질문이다. 같이 알아보자.”모르는 것에 대해 학습하는 방법을 알려줄 수 있는 좋은 기회입니다. Find what they can teach you.멋진 연주자 이거나 암벽 등반가 일수도 있습니다. 그들이 가르쳐 줄 수 있는 것을 찾고, 배우고 싶다고 하세요. 둘 사이의 관계가 뒤집어 지는 순간 사회적 평등을 느낄 것입니다. 위 아티클의 마지막에 다음과 같이 강조하고 있다. “Just Remember: Don’t Type” 시니어든 주니어든, 누구랑 같이 페어 프로그래밍을 하게 되든, 잊지 않았으면 한다. 타이핑을 하는 것 보다 대화를 하는 것이 더 중요하다. 대화를 통해 서로의 생각을 공유하자. 이것이 페어 프로그래밍을 잘 하는 가장 중요한 방법일 것이다. 당장의 속도 보다 팀의 성장을 원한다면 꼭 한번 페어 프로그래밍을 시도해 보길 바란다. “빨리 가고 싶으면 혼자 가고, 멀리 가고 싶으면 함께 가라”","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"agile","slug":"agile","permalink":"https://kihoonkim.github.io/tags/agile/"},{"name":"pair programming","slug":"pair-programming","permalink":"https://kihoonkim.github.io/tags/pair-programming/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"애자일 코리아 컨퍼런스 2017 참석 후기","slug":"Agile/agilekorea2017","date":"2017-09-30T05:30:30.000Z","updated":"2021-08-17T00:04:32.682Z","comments":true,"path":"2017/09/30/Agile/agilekorea2017/","link":"","permalink":"https://kihoonkim.github.io/2017/09/30/Agile/agilekorea2017/","excerpt":"","text":"주의 ! 사진이 많습니다. 사진은 AgileKoreaConf2017 행사사진 여기에서 가져왔습니다. 기억에 의존해서 썼기 때문에 발표자의 의도와 다를 수 있습니다. 애자일 코리아 컨퍼런스 가 5년만에 열렸다. 그래서 인지 메인 타이틀이 ‘리빌딩 애자일 커뮤니티’ 였다. 개발자이다 보니 보통 개발관련된 컨퍼런스만 참석을 하게되는데.. 애자일 컨퍼런스를 참석할지 말지 고민하다가 참석하게되었다. 개발자 중심의 행사도 아니고, 참가비도 컨퍼런스 치고 꽤 비싼 축에 들었다. 무엇보다 개발자들에게 매력적으로 다가올 많한 주제가 많지 않았다. 근데 참가자를 무려 400 명을 모집하려고 했다. 아무래도 같이 일하는 사람들이 주도적으로 준비하는 컨퍼런스다 보니 준비과정을 가까이서 지켜보았는데.. 사실 절반도 안모이면 어쩌지 걱정도 되었다.리빌딩 애자일 커뮤니티 인데… 다시 시작하는 길이 잘 되야 할텐데…처음에는 좀 무모해 보이기도 했지만, 결과적으로는 애자일 커뮤니티를 다시 살리고자 하는 분들의 열정이 좋은 결과를 만들어 낸 것 같다. 오랜만에 새로운 사람들을 만나보고도 싶기도 했고, 개발자가 아닌 다른 분야의 사람들은 어떤 생각을 할지 궁금하기도 해서 자원활동가로 참가를 하게되었다. 새로운 사람들과의 인연을 맺는데는 실패하기는 했지만.. 정말 좋은 컨퍼런스로 기억될 것 같다. 컨퍼런스 준비 덕분에 집에서 바라보는 새벽 모습을 처음으로 알게되었다. 잠실에 7시까지 가는 건.. 정말.. 휴.. 그래도 아침에 먹은 김밥은 정말 맛있었다. 8시 30분이 되자 등록대에 사람도 몰리기 시작했다. Lean Coffee첫번째 세션은 Lean Coffee 였는데, 시간표 타이틀만 보고는 그냥 커피마시는 시간인 줄 알았다. 커피는 페이크고, 원하는 주제로 토론을 하는 시간 이었다. 과연 많이 참여할까.. 싶었는데, 다양한 주제와 다양한 사람들이 열띤 토론을 하는 걸 볼 수있었다. 한국 컨퍼런스에서 사실 기대하기 어려운 모습인데 적극 적인 참가자들이 많아 보였다.A~H 까지 8개 테이블에 삼삼오오 사람들이 모여 들었다. 다른 트랙 준비를 위해서 참여하지 못해서 아쉽긴 하지만, 다른 분들의 후기를 기대해 본다. 이세션에 참여하신 분들끼리 또 다른 모임이 만들어 져도 좋을 것 같다는 생각이 든다. 세번째 트랙의 트랙매니저로 행사에 참여하다 보니 첫번째 키노트를 빼고는 다른 트랙의 내용을 듣지 못했다. 다른 트랙의 후기도 많이 올라왔으면 좋겠다. 부끄럼이 많은 개인적인 성향상 보통 직접 참여해야 하는 세선을 잘 듣진 않는데.. 트랙매니져다 보니 이번엔 거의 강제 참여를 당했다. 덕분에 정말 좋은 경험을 하게 되었다. 진짜 재미있었다. 각 세션별 리뷰 겸 개인적인 회고를 좀 해볼까한다. 키노트1 : The State of the Art in Agile키노트는 ThoughtWorks CTO 인 Mike Mason 이 The State of the art in Agile 을 주제로 발표해 주었다. 첫 장표에서 Agile has won! 이라는 자극적이면서 당당한 타이틀로 Agile의 State를 말해주는 것 같았다.애자일의 현재 생태와 Enterprise에서 애자일의 모습, Microservice 에 대한 내용이 었다. 사실 키노트 치고는 너무 일반적인 내용이란 생각이 들었다. 그만큼 지금 ACT 팀이 해당 주제에 대해서는 꽤 잘해내고 있다는 의미인 것 같기도 하다. 하지만 그래도 좀 더 깊은 울림을 주는 내용을 기대했는데… 그 전날 회사내에서 공유한 시간에서는 “본인의 20년 경력에서 애자일보다 나은 방법이 없었다”, “애자일은 단호해야 한다” 등의 얘기가 나왔다던데, 그런 내용에 대한 세션을 기대했지만 나오지 않았다.Q&amp;A 시간이 짧았던게 정말 아쉬웠다. Products, not Projects 애자일이나 MSA 관련 글에서 많이 나오는 주제이다. 프로젝트 처럼 모였다 흩어졌다 하는 것이 아니라, 한 제품을 꾸준히 발전시켜 나갈 수 있어야 한다는 것인데.. 우리 팀에서 역시 많이 강조하고 있다. 하지만, product를 만들고 있지만 인력 운영되는 건 왜 project를 하는 것 같은 느낌이 드는지.. 애자일 전파를 위한 혼자만의 싸움 전략트랙3의 첫번째 세션은 SKplanet에서 애자일 전파을 위해 홀로 외롭게 싸움을 시작해 지금은 21% 정도 온 것 같다는 신원 님의 발표였다.잠실 캠퍼스에서 행사를 진행하다 보면 보통 메인 트랙이 아니면 전체인원의 10%도 오지 않는데, 생각보다 많은 인원들이 참여해서 놀랬었다. 그만큼 각자의 회사에서 애자일 문화가 전파되는데 많이 힘들어 하고 있는 것 같았다. 그래서 인지 신원님의 소소한 팁들이 발표를 듣는 분들의 탄식을 자아냈다.회사내에서 애자일을 전파할때 부정적인 사람을 바꾸는 것보다는 긍정적이고 얼리어답터 기질의 사람들을 아군으로 만드는 것이 더 중요하는 것에 대한 내용이었다. 애자일 코치의 중요성도 강조해 주셨다. 애자일 코치 좀 채용해 달라고……마지막 질의응답을 받기 전에 물을 뿜으신 것을 빼고는 완벽한 세션이었다. ACT 팀 역시 본인들만 즐거운 팀이라는 외부 시선이 많다. 누군가에게 가치를 주고 싶은 순수한 마음도 지하철 역 앞에서 종교를 전도하는 사람들 마냥 귀찮고 의미없어 하는 시선이 많다. 우리에게 아군은 누가 있을까 고민하게 된다. 애자일 코치를 위한 코칭 리더쉽다목적홀 두번째 세션은 애자일 코치를 위한 코칭 리더십 이란 주제로 Odd-e의 박준표 님이 발표해 주셨다. 발표라기 보다는 워크샵을 진행해 주셨다. 참가자들이 들어오면서 각자의 퍼실리테이션, 컨설팅, 심리상담, 코칭, 멘토링 에 대해 정의와 키워드를 작성하였다. 세션이 끝날때까지 이 것들에 대한 언급이 없어서 아쉬웠는데, 지나고 나서 생각해보니 해당 내용들이 세션 전반에 걸쳐서 녹아져있던 것 같다. 8명씩 한조를 이뤄 워크샵이 진행되었다.스페이스팀 이란 게임을 먼저 진행했다. 게임에 대한 설명없이 다짜고짜 시작했다. 게임을 start하는 방법부터 팀내에서 해결하는 걸 기대했다고 하셨다.게임을 진행하는 모습은 아래 사진과 같다.8명 대부분이 처음 보는 사람들일 텐데, 금새 팀원들의 머리가 가까워지고, 엄청 시끄러워진다. 하지만 게임을 진행하는 20분 정도의 시간동안 팀내에 문제도 생기고 개인적인 심리 변화도 생긴다. 그에 따라 각자 행동을 변화하거나 다른 사람을 변화시키고자 한다.게임을 마치고 팀마다 시간에 따라 질서와 혼돈을 느낀 것을 그래프로 그리고 그에따라 본인이 취한 행동을 적고 토론하는 시간을 가졌다. 마치 이터레이션을 마치고 회고를 하는 것 같았다. 박준표님은 소프트웨어 개발하는 것이 게임과 닮아있다고 하셨다. 그 이유는 바로 학습 이었다. 학습이 이뤄지지 않으면 금새 흥미를 잃고 다음으로 나아가려 하지 않기 때문이다. 따라서 팀이 제대로 학습해 나가는 것이 중요하다. 애자일로 개발을 진행하다보면 각 단계마다 학습할 수있는 기회들이 있다. 그런데 그때 문제가 발생했을때 팀내에서 해결이 안되는 경우 애자일 코치의 역할이 중요하다.애자일 코치는 다양한 frame과 tool을 가지고 있어야 한다. 애자일의 여러 방법론 들은 frame 이고, 이를 하결하는데 도움을 주는 5가지 tool이 있다. 그리고 무엇보다 애자일 코치는 문제를 바라보고 해결하는 방법이 달라야 한다. 위 사진의 [문제/이슈] 처럼 왼쪽 방법이 아닌 오른쪽 처럼 문제를 이슈로 바라보고 그 이슈가 해결되었을 때의 모습을 팀원들이 그리게 해야한다. 스스로 변화할 열정과 의지를 가지게 함으로써 해결하게 만들 수 있어야 한다.예를 들면 아래 처럼.. 세션이 끝날 때쯤 Colored brain communication card 라는 것을 이용해서 회고를 진행하였다. 각자 오늘 느낀 점과 비슷한 카드를 골라 서로에게 설명하는 것이었다. 새로운 회고 방식이었다. 개인적으로 카드가 참 탐났다. ㅎㅎ 이세션을 통해 애자일 코치는 참 어려운 일이고 다른 영역의 일인데 너무 쉽게 보고 있는 건 아닌가 하는 걸 느꼈다. 개발자나 다른 팀원들은 제품의 문제를 풀지만 애자일 코치는 사람 간의 문제를 푸는 것 같았다. 박준표님은 계속해서 수련 을 한다고 말씀하셨다. 개발자들이 드래곤 워리어가 되기 위해 수련한다면, 애자일 코치는 우그웨이의 길을 걷는 듯한 느낌이었다. 박준표 님의 다른 세션을 더 들어보고 싶지만, 엄청 비싼 분인 것 같은 포스가…. 개발자를 위한 Improv (즉흥 연기)다목적홀의 마지막 세션은 IMFROG 팀의 즉흥연기 였다. 소통 이라는 큰 주제 아래 커뮤니케이션, 공감, 팀빌딩, 신뢰, 리더십, 에너지 를 주제로 즉흥 연기를 하는 것이었다. 처음에는 부끄러움 탓에 참여를 하지 않고 있었는데, 핑크티를 입었다는 이유로 강제 참여를 당했다… 인생 최고로 부끄러웠던 순간이었다. 난 앞으로 절대로 발연기하는 배우들을 욕하지 않기로 했다.정해진 대본도 없는데 말과 함께 행동을 하다 보니 말할 수 없는 부끄러움에 자세히 리뷰를 하지는 않겠다…..ㅠ내가 가진 나쁜 습관에 대해서 일깨워준 두가지만 언급해 보겠다.첫번째는 상대방의 말을 얼마나 경청하는 가에 대한 것이었다. 최근에 데일리 스탠덥을 하고 나서 상대방에 어떤 얘기를 했는지 전혀 기억이 나지 않은 일이 있었다. 다른 사람이 얘기할때 속으로 어제 뭐했지.. 무슨 얘기를 하나.. 등등.. 딴 생각만 하고 있던 것이었다. 즉흥 연기와 함께 부끄러움이 더 해졌다. 100% 경청을 힘들 더라도, 70%는 해야지..두번째는 Yes, and 였다. 난 개인적으로 불평 불만이 많고, 그게 무언가를 바꾼다는 생각을 가지고 있었다. 그래서 보통 화법이, Yes, but 이었다. 그러다 보니, 대화의 중심이 상대방이 아닌 내가 되었었다. “맞아, 그래, 그리고~~” 를 연습해야 겠다. 근데 잘안된다….. 우리팀은 항상 페어프로그래밍을 한다. 하루 종일 업무에 대한 대화, 잡담 등 끊임없이 얘기를 한다. 하지만 서로의 얼굴을 보고 하는 대화가 아닌, 모니터를 바라보고 한다. 참 오랜만에 사람의 얼굴을 표정을 가까이서 관찰해 본 것 같다. IMFOG 팀의 배우분들의 표정은 정말 다채로웠다. 얼굴 근육이 쉼 없이 움직이고 있었다. 이런 사람들은 일도 엄청 재미있게 하시려나.. 끝으로..그 동안 참 많은 컨퍼런스를 진행도 해보고 참여도 해봤는데, 가장 재미있던 행사였다. 그냥 앉아 세션을 들으면서 똑똑한 사람들 많네.. 하는 게 아니라, 개인적으로 느끼게 하는 것이 많았다. 그리고 놀라웠던 건 적극적인 사람들이 참 많다는 것이다.애자일이라는 문화가 더 널리 제대로 전파되고 자리잡았으면 좋겠다. 애자일 커뮤니티도 더 발전해 나가길 기원해 본다. 컨퍼런스에 참여하고 준비하신 모든 분들 수고하셨습니다.","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"애자일코리아2017","slug":"애자일코리아2017","permalink":"https://kihoonkim.github.io/tags/%EC%95%A0%EC%9E%90%EC%9D%BC%EC%BD%94%EB%A6%AC%EC%95%842017/"},{"name":"agilekorea207","slug":"agilekorea207","permalink":"https://kihoonkim.github.io/tags/agilekorea207/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"Java Exception Handle in Stream Operations","slug":"java/noexception-in-stream-operations","date":"2017-09-09T06:23:30.000Z","updated":"2021-08-17T00:04:32.698Z","comments":true,"path":"2017/09/09/java/noexception-in-stream-operations/","link":"","permalink":"https://kihoonkim.github.io/2017/09/09/java/noexception-in-stream-operations/","excerpt":"","text":"java8 스트림에서 Exception이 발생하는 경우 어떻게 처리해야 할까?우선 기본적인 내용부터 간단히 알아보고 넘어가 보자. Java ExceptionJava에서 Exception은 Checked Exception과 RuntimeException을 상속받아 구현된 Unchecked Exception으로 구분된다.RuntimeException은 자동으로 이전 스택으로 throw되기 때분에 별도의 처리가 없어도 된다. 하지만 Checked Exception 의 경우에는 throws를 명시하거나 try-catch로 처리해 주어야 한다.자세한 내용은 Java Tutorials 를 참고하기 바란다. Java Stream Operationsjava8에서 Collection의 내부반복을 위해 Stream API 를 지원하고 다양한 operation을 제공하고 있다.대부분의 operation 들은 Predicate, Supplier, Function등을 받아서 처리를 한다.하지만 java8에서 기본적으로 제공하고 있는 FunctionalInterface은 아래 메소드 시그니처와 같이 Exception을 throws 하지 않는다. 내부에서 Checked Exception이 발생한다면 처리할 방법이 없기 때문에 compile error를 내버린다. 123456789101112@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t)&#125;@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get()&#125;@FunctionalInterfacepublic interface Function&lt;T,R&gt; &#123; R apply(T t);&#125; 하지만, 대부분의 애플리케이션은 예외가 발생했을때 별도의 처리로직을 가져야 하는 경우가 있다.예를 들면, Exception이 발생한 경우 별도로 정의한 Custom Exception으로 감싸서 던진다. 12345try &#123; doSomeThing();&#125; catch(IllegalArgumentException e) &#123; throw new MyException(&quot;ERROR_CODE&quot;, &quot;ERROR_MESSAGE&quot;, e);&#125; Steam내에서 Exception 처리그렇다면 Stream operation에서 Exception이 발생한다면 어떻게 처리 할 수 있을까?DZone에 noException in Stream Operations에서 해답을 얻을 수 있었다.간단한 예제와 같이 알아보자. 아래와 같이 내부적으로 Chedcked Exception인 UnknownHostException 을 발생하는 메소드가 있고, 이를 Stream내에서 사용하는 경우를 생각해 보자. 123456public class InetAddress &#123; public static String getByName(String host) throws UnknownHostException &#123; if(1==1) throw new UnknownHostException(host); return &quot;localhost&quot;; &#125;&#125; Step 1아래와 같이 Stream map에서 위 메소드를 호출하려고 하면 Function&lt;T,R&gt; 은 Exception을 throw 하지 않기 때문에 compile error가 발생한다. 1234567public static void main(String[] args) &#123; String[] allowed = &#123;&quot;127.0.0.1&quot;, &quot;::1&quot;&#125;; Arrays.stream(allowed) .map(InetAddress::getByName) // &lt;--- compile error .collect(toSet()); // Unhandled exception: java.net.UnknownHostException&#125; Stream.map signature &lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T,? extends R&gt; mapper) Step 2이 문제를 제일 단순하게 해결하는 방법은 try-catch로 감싸서 RuntimeException으로 감싸서 throw 해주는 것일 것이다. 12345678910111213public static void main(String[] args) &#123; String[] allowed = &#123;&quot;127.0.0.1&quot;, &quot;::1&quot;&#125;; Arrays.stream(allowed) .map( host -&gt; &#123; try &#123; return InetAddress.getByName(host); &#125; catch(UnknownHostException e) &#123; throw new RuntimeException(e); &#125; &#125;) .collect(toSet());&#125; 하지만, 코드가 너무 복잡해 보이고 의도가 불명확해 지고, Stream API를 통해 코드를 서술적으로 작성하고자했던 목적에서 멀어지는 것 같다. Step 3우선 Function이 예외를 던져주지 않기 때문에 예외를 던져주는 Supplier를 정의해 준다. 123public interface ExceptionSupplier&lt;T&gt; &#123; T get() throws Exception;&#125; try-catch 블럭을 대신 처리해 줄 메소드를 다음과 같이 정의한다. 1234567public static &lt;T&gt; T wrap(ExceptionSupplier&lt;T&gt; z) &#123; try &#123; return z.get(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125;&#125; ExceptionSupplier의 descriptor는 () -&gt; T 이기 때문에wrap 함수에 ()-&gt;InetAddress.getByName(s) 로 넘겨 주면된다. 1234567public static void main(String[] args) &#123; String[] allowed = &#123;&quot;127.0.0.1&quot;, &quot;::1&quot;&#125;; Arrays.stream(allowed) .map(s -&gt; wrap(()-&gt;InetAddress.getByName(s))) .collect(toSet());&#125; 이 정도로도 충분히 예외처리 관련 로직을 분리해 내서 좋은 코드지만, 좀더 단순하게 작성하고 싶다. 메서드 레퍼런스도 그대로 사용될 수 있었으면 좋겠다. Step 4메서드 레퍼런스를 그대로 받아서 처리하기 위해서는 Supplier를 Function으로 변경해 주어야 한다.InetAddress.getByName(s) 는 String을 입력받아 String을 리턴해 주기 때문에 T -&gt; R 로 표현 할 수 있다. 123public interface ExceptionFunction&lt;T, R&gt; &#123; R apply(T r) throws Exception;&#125; ExceptionSupplier를 입력받아서 값을 리턴해주던 wrap 함수도 ExceptionFunction을 입력받아 try-catch를 처리한 Function을 리턴하도록 변경 할 수있다. 12345678910111213public static &lt;T, R&gt; Function&lt;T, R&gt; wrap(ExceptionFunction&lt;T, R&gt; f) &#123; // (r) -&gt; // wrap( // ()-&gt;InetAddress.getByName(r) // ) return (T r) -&gt; &#123; try &#123; return f.apply(r); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;;&#125; 최종적으로는 아래와 같이 exception 처리를 분리해내면서 함수형 스타일로 작성할 수 있다. 1234567public static void main(String[] args) &#123; String[] allowed = &#123;&quot;127.0.0.1&quot;, &quot;::1&quot;&#125;; Arrays.stream(allowed) .map(wrap(InetAddress::getByName)) .collect(toSet());&#125; Good!!","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}],"tags":[{"name":"java","slug":"java","permalink":"https://kihoonkim.github.io/tags/java/"},{"name":"java 8","slug":"java-8","permalink":"https://kihoonkim.github.io/tags/java-8/"},{"name":"exception","slug":"exception","permalink":"https://kihoonkim.github.io/tags/exception/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}]},{"title":"(Java Basic) Generics","slug":"java/java-generics","date":"2017-09-03T06:23:30.000Z","updated":"2021-08-17T00:04:32.697Z","comments":true,"path":"2017/09/03/java/java-generics/","link":"","permalink":"https://kihoonkim.github.io/2017/09/03/java/java-generics/","excerpt":"","text":"Java Generic Java Documentation 토비의 봄 TV Generics Generic을 왜 사용하는가? Stronger type checks at compile time. Elimination of casts. Generic Class Type parameter &amp; argument123456public class Generics&lt;T&gt; &#123; // type parameter void print(T t) &#123; ... &#125; public static void main(String[] args) &#123; new Generics&lt;String&gt;().print(&quot;&quot;); // type argument &#125;&#125; static method에 type parameter 사용 불가123public class Generics&lt;T&gt; &#123; static void hello(T t) &#123;&#125; // compile error&#125; Type parameter convention123456T - TypeE - ElementK - KeyV - ValueN - NumberS, U... - 2nd, 3rd, 4th types Generic Method Method 안에서만 사용할 타입 지정1234567public class Generics&lt;E&gt; &#123; &lt;T&gt; Generics(T t) &#123;&#125; &lt;T&gt; void method1(T t) &#123; ... &#125; &lt;S, E&gt; E method2(S t) &#123; ... &#125; &lt;S, T&gt; S method3(T t) &#123; ... &#125; static &lt;T&gt; void method4(T t) &#123; ... &#125;&#125; Type Eraserhttps://docs.oracle.com/javase/tutorial/java/generics/erasure.html If type parameter T is unbounded, the Java compiler replaces it with Object 12345678public class Node&lt;T&gt; &#123; private T data; public T getData() &#123; return data; &#125;&#125;public class Node &#123; private Object data; public Object getData() &#123; return data; &#125;&#125; The Java compiler replaces the bounded type parameter T with the first bound class12345678public class Node&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T data; public T getData() &#123; return data; &#125;&#125;public class Node &#123; private Comparable data; public Comparable getData() &#123; return data; &#125;&#125; Raw typeGeneric이 없는 기본 타입 123456789public static void main(Sting[] args) &#123; List rawTypeList = new ArrayList&lt;String&gt;(); List&lt;Integer&gt; list1 = Arrays.asList(1,2,3); List rawInt = list; // not compile error List&lt;Integer&gt; list2 = rawInt; // warning : unchecked or unsafe operation (하위 호환을 위해서) List&lt;String&gt; strs = rawInt; // not compile error String str = strs.get(0) ; // ClassCastException&#125; Generic과 타입의 상속 관계1234567891011121314public class Generics &#123; public static void main(String[] args) &#123; // Number is Integer&#x27;s super type. Integer i = 10; Number n = i; List&lt;Integer&gt; intList = new ArrayList&lt;&gt;(); List&lt;Number&gt; numberList = intList; // compile error : Incompatible types. // List is ArrayList&#x27;s super type. ArrayList&lt;Integer&gt; intList = new ArrayList&lt;&gt;(); List&lt;Integer&gt; numberList = intList; // OK &#125;&#125; Bounded Type parameter upper bound : extends12345678// T는 List의 sub type 만 가능// T에 상관없이 List에 있는 기능만 사용하겠음을 의미public class Generics&lt;T extends List&gt; &#123; &lt;S extends List&gt; void hello(S s) &#123;&#125; &lt;S extends Comparable&lt;S&gt;&gt; long count(S[] list, S elem) &#123; return Arrays.stream(list)(s -&gt; s.compareTo(elem) &gt; 0).count(); &#125;&#125; lower bound : super123// T는 List의 super type 만 가능public class Generics&lt;T super Integer&gt; &#123;&#125;new Generics&lt;Number&gt;(); 주로..1234567// upper bound : method 내부에서 사용되는 경우// lower bound : method 외부에서 사용되는 경우public class Generics &#123; private static &lt;T extends Comparable&lt;? super T&gt;&gt; max(List&lt;? extends T&gt; list) &#123; return list.stream().reduce((a,b)-&gt; a.compareTo(b)&gt;0 ? a:b).get(); &#125;&#125; Type 추론compiler가 타입을 추론 12345678910public class Generics &#123; static &lt;T&gt; void method(T t) &#123;&#125; public static void main(String[] args) &#123; Generics.method(1); Generics.&lt;Integer&gt;method(1); // hint List&lt;String&gt; strs = new ArrayList&lt;&gt;(); List&lt;String&gt; strs2 = Collections.emptyList(); List&lt;String&gt; strs3 = Collections.&lt;String&gt;emptyList(); &#125;&#125; Wild card : ? ? : 타입 모름. 내부 구현에서 타입을 알필요 없음. 타입이 정해지면 그 이후 사용하겠음12345678910111213141516171819public class Generics &#123; static void printList(List&lt;Object&gt; list) &#123; list.forEach(System.out::println); &#125; static void printList2(List&lt;? extends Object&gt; list) &#123; list.forEach(System.out::println); &#125; public static void main(String[] args) &#123; List&lt;?&gt; list; // List인거 이외에는 관심없음 List&lt;? extends Object&gt; objs; // Object에 있는 기능만 사용 printList(Arrays.asList(1,2,3)); printList2(Arrays.asList(1,2,3)); List&lt;Integer&gt; intList = Arrays.asList(1,2,3); printList(list); // compile error printList2(list); // ok &#125;&#125; 12345678910111213141516public class Generics &#123; static class A &#123;&#125; static class B extends A &#123;&#125; public static void main(String[] args) &#123; List&lt;B&gt; listB = new ArrayList&lt;&gt;(); listB.add(new B()); // ok List&lt;A&gt; listA = listB; // complie error List&lt;? extends A&gt; lA = listB; // ok lA.add(new A()); // complie error lA.add(new B()); // complie error lA.add(null); // only ok List&lt;? super B&gt; l2 = listB; // ok &#125;&#125; Type parameter vs Wild card 무엇을 사용해야 할까 Type Parameter를 사용한다는 것은 내부에서 T이 무엇인지 관심있음 wild card를 사용하는 경우는 Type이 무엇인지 관심없음 API 설계 의도에 따라 선택해서 사용해야 함1234567891011121314public class Generics &#123; static &lt;T&gt; void method1(List&lt;T&gt; list, T t)&#123; &#125; static void method2(List&lt;?&gt; list) &#123; list.add(1); //불가능 list.add(null); // 가능 list.clear(); // 원소와 상관없는 기능만 사용 가능 &#125; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5); method1(list); method2(list); &#125;&#125; 12345678910111213public class Generics &#123; static &lt;T&gt; boolean isEmpty1(List&lt;T&gt; list) &#123; return list.size() == 0; &#125; static boolean isEmpty2(List&lt;?&gt; list) &#123; return list.size() == 0; &#125; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5); System.out.println(isEmpty1(list)); System.out.println(isEmpty2(list)); // API 설계의도에 더 맞음 &#125;&#125; wild card capture type을 추론해야 되는 경우 capture를 실행하게 됨 추론할 수 없는 경우 에러12345678910111213141516171819202122232425262728293031323334353637383940public class Generics &#123; // API 구현에 오해를 부름. 내부에서 원소 타입이 중요한가??? // static &lt;T&gt; void reverse(List&lt;T&gt; list) &#123; // List&lt;T&gt; temp = new ArrayList&lt;&gt;(list); // for(int=0; i&lt;list.size(); i++) &#123; // list.set(i, temp.get(list.size()-i-1)); // &#125; // &#125; // wild card를 사용하려고 하니 capture 불가.. // static void reverse(List&lt;?&gt; list) &#123; // List&lt;?&gt; temp = new ArrayList&lt;&gt;(list); // for(int=0; i&lt;list.size(); i++) &#123; // list.set(i, temp.get(list.size()-i-1)); // compile error : capture&lt;?&gt; // &#125; // &#125; static void reverse(List&lt;?&gt; list) &#123; reverseHelper(list); &#125; private static &lt;T&gt; void reverseHelper(List&lt;T&gt; list) &#123; List&lt;T&gt; temp = new ArrayList&lt;&gt;(list); for(int=0; i&lt;list.size(); i++) &#123; list.set(i, temp.get(list.size()-i-1)); &#125; &#125; // Raw Type 이용 // private void reverse(List&lt;?&gt; list) &#123; // List temp = new ArrayList&lt;&gt;(list); // List list2 = list; // for(int=0; i&lt;list.size(); i++) &#123; // list2.set(i, temp.get(list2.size()-i-1)); // &#125; // &#125; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5); reverse(list); System.out.println(list); &#125;&#125; Intersection Type과 람다를 이용한 동적 기능확장 interface &amp; 로 연결 class 는 한번만 사용 가능123public class Generics &#123; &lt;S extends Serializable &amp; Comparable&gt; hello(S s) &#123;&#125;&#125; with Lambda : 정의해햐할 메소드 개수가 1개면 됨123456789public class IntersectionType &#123; public static void main(String[] args) &#123; // markable interface : Serializable hello( (Function &amp; Serializable) s-&gt;s); &#125; private static void hello(Function o) &#123;&#125; private static void hello(Serializable o) &#123;&#125; private static &lt;T extends Function &amp; Serializable&gt; void hello(T o) &#123;&#125;&#125; default method를 이용하여 기능 확장가능1234567891011121314151617181920212223242526272829public class IntersectionType &#123; interface Hello &#123; default void hello()&#123;&#125; &#125; interface Hi &#123; default void hi()&#123;&#125; &#125; interface Printer &#123; default void print(String str)&#123;&#125; &#125; public static void main(String[] args) &#123; // markable interface : Serializable hello( (Function &amp; Hello &amp; Hi) s-&gt;s); run( (Function &amp; Hello &amp; Hi &amp; Printer) s-&gt;s, o -&gt; &#123; o.hello(); o.hi(); o.print(); &#125;); &#125; // 함수마다 계속 수정해야 하나?? private static &lt;T extends Function &amp; Hello &amp; Hi&gt; void hello(T t) &#123; t.hello(); t.hi(); &#125; // callback을 이용하여 해결 가능 private static &lt;T extends Function&gt; void run(T t, Cunsumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125;&#125; delegate를 통해 기능 조합12345678910111213141516171819public class IntersectionType &#123; interface DelegateTo&lt;T&gt;&#123; T delegate(); &#125; interface Hello extends DelegateTo&lt;String&gt; &#123; default void hello() &#123; System.out.println(&quot;Hello&quot; + delegate()) &#125; &#125; public static void main(String[] args) &#123; run((DelegateTo&lt;String&gt; &amp; Hello)()-&gt;&quot;Kihoon&quot;, o-&gt;&#123; o.hello(); &#125;); &#125; private static &lt;T extends DelegateTo&lt;S&gt;, S&gt; void run(T t, Consumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125;&#125; Library 수정 없이 기능 확장하기12345678910111213141516171819202122232425262728293031323334353637public class IntersectionType &#123; interface Pair&lt;T&gt; &#123; T getFirst(); T getSecond(); void setFirtst(T first); void setSecond(T second); &#125; static class Name implements Pair&lt;String&gt; &#123;...&#125; interface ForwardingPair&lt;T&gt; extends DelegateTo&lt;Pair&lt;T&gt;&gt;, &lt;Pair&lt;T&gt; &#123; default T getFirst()&#123; return delegate().getFirst();&#125; default T getSecond()&#123; return delegate().getSecond();&#125; default void setFirtst(T first)&#123; return delegate().setFirst(first);&#125; default void setSecond(T second)&#123; return delegate().setSecond(second);&#125; &#125; interface DelegateTo&lt;T&gt;&#123; T delegate(); &#125; private static &lt;T extends DelegateTo&lt;S&gt;, S&gt; void run(T t, Consumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125; interface Convertable&lt;T&gt; extends DelegateTo&lt;T&gt;&gt; &#123; default void convert(Function&lt;t,T&gt; mapper) &#123; Pair&lt;T&gt; pair = delegate(); pair.setFirst(mapper.apply(pair.getFirst()); pair.setSecond(mapper.apply(pair.getSecond()); &#125; &#125; public static void main(String[] args) &#123; Pair&lt;String&gt; name = new Name(&quot;Ki&quot;, &quot;Kim&quot;); run((ForwardingPair&lt;String&gt; &amp; Convertable&lt;String&gt;)()-&gt;name, o-&gt;&#123; o.convert(s-&gt;s.toUpperCase()); &#125;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Basic","slug":"Java/Basic","permalink":"https://kihoonkim.github.io/categories/Java/Basic/"}],"tags":[{"name":"java","slug":"java","permalink":"https://kihoonkim.github.io/tags/java/"},{"name":"generic","slug":"generic","permalink":"https://kihoonkim.github.io/tags/generic/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Basic","slug":"Java/Basic","permalink":"https://kihoonkim.github.io/categories/Java/Basic/"}]},{"title":"create & run & test React App","slug":"reactgo/reactgo-7-create-react-app","date":"2017-04-29T05:12:00.000Z","updated":"2021-08-17T00:04:32.703Z","comments":true,"path":"2017/04/29/reactgo/reactgo-7-create-react-app/","link":"","permalink":"https://kihoonkim.github.io/2017/04/29/reactgo/reactgo-7-create-react-app/","excerpt":"","text":"처음 React.js 개발환경을 설정 할때를 떠올려보면 Babel, Webpack이나 test를 위한 라이브러리(Jest)를 설정하기 위해 수 많은 삽질과 시간을 들였던 것 같다. 특히 나와 같이 Front-End 기술에 익숙하지 않은 사람들은 이런 기술들이 어렵게 다가 올 수 있다. 하지만, create-react-app을 사용하여 React 프로젝트 생성하면 쉽게 만들고 설정할 수 있다. Create React apps with no build configuration. create-react-app 설치 및 프로젝트 생성123456789101112$ npm install -g create-react-app$ create-react-app my-first-reactCreating a new React app in C:\\Users\\kihoonkim\\workspace\\my-first-react.Installing packages. This might take a couple minutes.Installing react, react-dom, and react-scripts...It looks like you are using npm 2.We suggest using npm 3 or Yarn for faster install times and less disk space usage.npm WARN optional dep failed, continuing fsevents@1.0.17 create-react-app으로 프로젝트를 생성하면 아래와 같은 구조를 만들어 준다. 매우 단순한 package.json을 볼 수 있다. 설치 하고 나면 아래와 같은 메시지를 볼 수 있다. 하나씩 실행해 보자. npm start단순히 local dev server를 통해 실행한다.http://localhost:3000 을 통해 접속해 볼 수 있고, 소스 파일 수정시 자동으로 hot deploy 된다. 1234567891011121314151617$ cd my-first-react$ npm start---&gt; my-first-react@0.1.0 start C:\\Users\\kihoonkim\\workspace\\my-first-react&gt; react-scripts start---Starting the development server...---Compiled successfully!The app is running at: http://localhost:3000/Note that the development build is not optimized.To create a production build, use npm run build. npm run buildwebpack 을 통해서 컴파일, 압축 등을 한 후 static asset을 생성한다.build 디렉토리 하위에 파일이 생성된다. 123456789101112131415161718192021222324$ npm run build&gt; my-first-react@0.1.0 build C:\\Users\\kihoonkim\\workspace\\my-first-react&gt; react-scripts buildCreating an optimized production build...Compiled successfully.File sizes after gzip: 46.63 KB build\\static\\js\\main.00c83e70.js 289 B build\\static\\css\\main.9a0fe4f1.cssThe project was built assuming it is hosted at the server root.To override this, specify the homepage in your package.json.For example, add this to build it for GitHub Pages: &quot;homepage&quot;: &quot;http://myname.github.io/myapp&quot;,The build folder is ready to be deployed.You may serve it with a static server: npm install -g serve serve -s build npm test테스트 파일을 실행 시켜준다. 기본적으로 jest를 사용한다. 1234567891011121314151617181920$ npm test---&gt; my-first-react@0.1.0 test C:\\Users\\kihoonkim\\workspace\\my-first-react&gt; react-scripts test --env=jsdom---RUN src\\App.test.js---PASS src\\App.test.js √ renders without crashing (16ms)Test Suites: 1 passed, 1 totalTests: 1 passed, 1 totalSnapshots: 0 totalTime: 0.385s, estimated 7sRan all test suites.Watch Usage› Press p to filter by a filename regex pattern.› Press q to quit watch mode.› Press Enter to trigger a test run. npm run ejectreact-scripts 를 통해 사용하던 dependencies나 설정 파일들을 현재 앱 디렉토리로 복사해 준다.react-scripts는 삭제되고, 절대로 다시 이전으로 되돌릴수 없다. 12345678910111213141516171819202122232425262728293031$ npm run eject&gt; my-first-react@0.1.0 eject C:\\Users\\kihoonkim\\workspace\\my-first-react&gt; react-scripts ejectAre you sure you want to eject? This action is permanent. [y/N]yEjecting...Copying files into C:\\Users\\kihoonkim\\workspace\\my-first-react Adding config\\env.js to the project Adding config\\paths.js to the project .....Updating the dependencies Removing react-scripts from devDependencies Adding autoprefixer to devDependencies Adding babel-core to devDependencies .....Updating the scripts Replacing &quot;react-scripts start&quot; with &quot;node scripts/start.js&quot; Replacing &quot;react-scripts build&quot; with &quot;node scripts/build.js&quot; Replacing &quot;react-scripts test&quot; with &quot;node scripts/test.js&quot;Configuring package.json Adding Jest configuration Adding Babel preset Adding ESLint configurationRunning npm install... 초기 상태 그대로 실행하면 아래와 같다. 초기 세팅을 했으므로 이제 개발이랑 테스트 삽질기를 작성해야겠다..","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"reactjs","slug":"ReactGo/reactjs","permalink":"https://kihoonkim.github.io/categories/ReactGo/reactjs/"}],"tags":[{"name":"reactjs","slug":"reactjs","permalink":"https://kihoonkim.github.io/tags/reactjs/"},{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"reactjs","slug":"ReactGo/reactjs","permalink":"https://kihoonkim.github.io/categories/ReactGo/reactjs/"}]},{"title":"golang interface. mockingl. dependency-injection. Test 하기 좋은 코드","slug":"reactgo/reactgo-6-golang-ducktyping-di-test","date":"2017-04-09T14:38:00.000Z","updated":"2021-08-17T00:04:32.703Z","comments":true,"path":"2017/04/09/reactgo/reactgo-6-golang-ducktyping-di-test/","link":"","permalink":"https://kihoonkim.github.io/2017/04/09/reactgo/reactgo-6-golang-ducktyping-di-test/","excerpt":"","text":"golang의 interface와 duck typingJava 개발자로서 Golang을 처음 접했을때, 가장 당황스러웠던 것 중 하나가, 바로 interface 였다.java로 인터페이스와 구현 클래스를 작성한다면 다음과 같을 것이다. 12345678910111213public interface Duck &#123; void Quack();&#125;public class DonaldDuck implements Duck &#123; @override public void Quack() &#123; System.out.Println(&quot;I&#x27;m Donald Duck&quot;); &#125;&#125;....public static void main(String[] agrs) &#123; Duck duck = new DonaldDuck();&#125; java 는 implements 키워드를 통해 DonaldDuck class는 Duck interface의 구현체 임을 명시적으로 선언한다.하지만, Go 에서는 어느곳에도 명시적으로 선언하지 않는다. 암묵적으로 만족만 시킨다면 interface의 구현체라고 생각할 수 있다. 12345678910111213141516type Duck interface &#123; Quack()&#125;type DonaldDuck struct &#123;&#125;func (d DonaldDuck) Quack() &#123; fmt.Println(&quot;Hello I&#x27;m Docal Duck. Quack Quack&quot;)&#125;func (d DonaldDuck) Walk() &#123; fmt.Println(&quot;I can walk&quot;)&#125;func main() &#123; var donald Duck = new(DonaldDuck) donald.Quack()&#125; 프로그래밍 언어에서 이런 방식을 흔히 Duck Typing 이라고 부른다. 만약 어떤 새가 오리처럼 걷고, 헤엄치고, 꽥꽥거리는 소리를 낸다면 나는 그 새를 오리라고 부를 것이다. 내 마음대로 해석해 보자면, 부르는 사람의 입장에서는 실제로 어떤 새인지가 중요한게 아니라 어떻게 행동하느냐 에 따라 어떤 새인지 구분하겠다는 것이다. 자바 개발자 입장에서 객체지향 적으로 바라보자면…한 객체가 다른 객체와 협력을 할때 그 객체가 내부적으로 실제로 어떻게 동작하는 가보다는 어떤 행동을 할 수 있는가 가 중요한 것이다.즉, 객체간 어떤 메시지로 협력을 구성할 수 있는지, 객체가 어떤 행위를 할 수 있는지가 중요한 것이다. 객체가 어떤 행위를 수행 할 수 있는 지를 정의하는 것으로 그 객체를 추상화 할 수 있다면, 그 객체와 협력하는 객체간 의존성을 낮출 수 있다. java에서 한 객체가 어떻게 행동하는지를 public하게 드러내는 방법이 바로 interface()를 사용하는 것이다.golang에서도 interface를 동일한 방식으로 사용함으로써 의존성을 낮추고 테스트하기 쉬운 코드를 만들 수 있다. interface를 사용하여 개발예를 들어, User 정보를 조회할 수 있는 UserService가 있고, UserService에서 Mysql에서 조회하는 UserMysqlRepository를 사용한다면, UserService는 UserMysqlRepository에 의존성을 갖게 될 것이다.만약 Mysql이 다른 DB로 변경되거나 UserMysqlRepository의 메소드가 변경된다면 UserService도 수정이 필요해 진다. 1234567type UserMysqlRepository struct &#123;&#125;func (r UserMysqlRepository) FindByName(name string) User &#123; ... &#125;type UserService struct &#123;&#125;func (u UserService) SearchBy(name string) (user User) &#123; user := UserMysqlRepository&#123;&#125;.FindByName(name) return&#125; java에서는 이런경우를 위해 interface로 타입을 지정하고 DI(Dependency Injection)을 통해 의존성을 주입해 줌으로써 결합도를 낮춘다. 일단 위의 예시에서 UserRepository라는 interface를 만들어 보자. 123type UserRepository interface &#123; FindByName(name string) User&#125; 의존성 주입의 가장 쉬운 방법은 실행시 파라메터로 넘겨주는 것이다. 12345678type UserService struct &#123;&#125;func (u UserService) SearchBy(name string, repo UserRepository) (user User) &#123; user = repo.FindByName(name) return&#125;func main() &#123; UserService&#123;&#125;.SearchBy(&quot;test&quot;, UserMysqlRepository&#123;&#125;)&#125; 또는 12345678910type UserService struct &#123; repo *UserRepository&#125;func (u *UserService) SearchBy(name string, repo UserRepository) (user User) &#123; user := u.repo.FindByName(name) return&#125;func main() &#123; UserService&#123;repo:UserMysqlRepository&#123;&#125;&#125;.SearchBy(&quot;test&quot;)&#125; 이와 비슷한 내용으로 더 잘 정리된 글(Dependency Injection in Golang)도 참조해 보면 좋을 것 같다. 하지만, golang의 DI를 다루는 대부분의 예제는 위 블로그 수준에서 끝난다.java를 개발할때 spring을 사용하는 경우 framework레벨에서 의존성을 주입해 준다.덕분에 controller, service, infra(DB, Network..) 레이어를 분리할 수 있다. 하지만 golang에서 앞의 예제처럼 작성한다면.. main 함수에서, 혹은 UserService보다 상위 레이어에서 UserMysqlRepository라는 infra 레벨의 레이어에 접근을 해야하는 문제가 있다. 123456// User Rest API Request Handlerfunc UserHandler(w http.ResponseWriter, r *http.Request) &#123; // HTTP handler에서 Mysql 까지 알아야 하나??? UserService&#123;repo:UserMysqlRepository&#123;&#125;&#125;.SearchBy(&quot;test&quot;) ...&#125; 이 처럼 레이어간 경계를 위해서 외부에서 Dependency Injection을 해줄 수 있는 방법이 필요해졌다.golang의 Injection library로는 facebookgo inject가 가장 많이 사용되는 것 같다. 간단히 설치해보고 테스트해 보자. inject library 사용glide 를 통해 간단히 설치 할 수 있다. 1~gogo &gt; glide get github.com/facebookgo/inject `inject:””` 을 통해 의존성 주입을 할 곳을 정해주면 된다.그리고 inject.Graph를 통해 주입할 대상을 매핑해 주면된다. 12345678910111213141516171819202122232425262728type User struct &#123; name string&#125;type UserService struct &#123; repository UserRepository `inject:&quot;&quot;` // &lt;&lt;--- Injection&#125;func (s *UserService) FindAll() (users []User) &#123; s.repository.FindAll() return&#125;type UserRepository interface &#123; FindAll() []User&#125;type UserMysqlRepository struct &#123;&#125;func (repo *UserMysqlRepository) FindAll() []User &#123; var users = []User &#123; User&#123;&quot;ki&quot;&#125; &#125; fmt.Println(&quot;This is Mysql Repository&quot;) return users&#125;func main() &#123; var userService user.UserService inject.Populate(&amp;user.UserGormRepository&#123;&#125;, &amp;userService) fmt.Println(userService.FindAll())&#125; UserService에 대한 단위 테스트를 작성하는 경우 실제 UserMysqlRepository를 통해 실행 될 필요는 없기 때문에, Mock 객체를 사용하여 테스트하는 것이 좋다.golang에서 지원하는 gomock을 설치해서 사용하면 된다. 12go get github.com/golang/mock/gomockgo get github.com/golang/mock/mockgen 아래와 같이 mockgen을 통해서 mock 객체를 generate하면 된다. 1gogo&gt;mockgen --source ./user/user_repository.go --destination ./user/user_repository_mock.go 생성된 mock 객체를 보면 아래와 같이 만들어졌다.수정하지 말라고 나와있지만, package 명은 user로 변경해줘야 한다. 123456789101112131415// Automatically generated by MockGen. DO NOT EDIT!// Source: ./user/user_repository.gopackage mock_user // ==&gt; userimport ( gomock &quot;github.com/golang/mock/gomock&quot;)// Mock of UserRepository interfacetype MockUserRepository struct &#123; ctrl *gomock.Controller recorder *_MockUserRepositoryRecorder&#125;...... facebookgo/inject와 golang/gomock을 사용한 전체 테스트 코드는 아래와 같다.NewMockUserRepository에서 리턴되는 값이 *MockUserRepository 포인터이기 때문에, inject.Graph의 Value로 넘겨줄때 &amp; 를 붙이면 안된다. 12345678910111213141516171819202122232425262728package userimport ( &quot;testing&quot; &quot;github.com/facebookgo/inject&quot; &quot;github.com/golang/mock/gomock&quot; &quot;strings&quot;)func TestFindAll(t *testing.T) &#123; // mock ctrl := gomock.NewController(t) mockUserRepository := NewMockUserRepository(ctrl) // stub var users = []User &#123; User&#123;&quot;test user&quot;&#125; &#125; mockUserRepository.EXPECT().FindAll().Return(users) // inject var userService UserService inject.Populate(mockUserRepository, &amp;userService) // test results := userService.FindAll() if strings.Compare(&quot;test user&quot;, results[0].name) != 0 &#123; t.Errorf(&quot;expected %s, actual %s&quot;, &quot;test user&quot;, results[0].name) &#125;&#125; UserService와 UserGormRepository간에 interface를 통해 메시지를 정의하고 사용함으로써 실제 구현체로부터 의존성을 분리할 수 있었다. Test 코드를 작성할때도 UserService에서 UserGormRepository를 사용하는 것이 아니라 MockUserRepository라는 Mock 객체를 inject 받아 사용함으로써 각 객체의 경계를 명확히 분리하여 테스트 할 수 있었다. 사실 이번 삽질기를 작성하면서 golang을 너무 java 개발하듯이 하는 것은 아닌가 하는 고민이 들었다.실제 프로젝트에서도 이와 매우 유사하게 작성해 나가고 있긴 하다. go 언어의 패러다임이 무엇인지 아직도 잘 모르겠다….좀 더 삽질해봐야 겠다.","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"},{"name":"Duck Typing","slug":"Duck-Typing","permalink":"https://kihoonkim.github.io/tags/Duck-Typing/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"golang configuration file 삽질기","slug":"reactgo/reactgo-5-configuration","date":"2017-04-05T14:38:00.000Z","updated":"2021-08-17T00:04:32.703Z","comments":true,"path":"2017/04/05/reactgo/reactgo-5-configuration/","link":"","permalink":"https://kihoonkim.github.io/2017/04/05/reactgo/reactgo-5-configuration/","excerpt":"","text":"개발을 하다보면 local, development, production 등의 환경이 다르다. 예를 들면 데이터베이스 접속 정보가 있을 것 이다.소스코드에 하드코딩 되어 있다면, 데이터베이스 인스턴스의 IP, Port등이 변경되는 경우 소스를 재 빌드, 배포, 실행을 해줘야 할 것이다.보통 이런경우에 환경설정 파일을 배포환경 별로 관리를 하게된다. 1234config |------ config.local.json |------ config.dev.json |------ config.prod.json 하지만 Twelve Factor App에 의하면 config 설정은 특정 언어나 OS에 의존하지 않도록 환경변수 를 사용하라고 나와있다. Go 언어를 위한 Configuration library가 다양하게 존재한다.이 라이브러리들도 크게 환경설정 파일을 이용하거나 환경변수를 이용하는 것들로 나뉘는 것 같다. 대부분의 사용법이나 컨셉은 비슷한 것 같다. 환경설정을 위해서 구글 검색을 하다가 설정파일 기반의 Gonfig 를 발견하고 적용해 보았다. config-sample에 나와있는 대로 설정하고 실행해 보면 잘 되는 것을 확인 할 수 있다.아래 구성한 것은 gonfig 관련된 소스를 config 패키지로 뺀것만 다르다. 1~gogo&gt; glide get github.com/tkanos/gonfig 123~gogo&gt; go run main.go8081local 테스트도 정상적으로 동작하는 것을 확인 할 수 있다. 1234~gogo\\config&gt; go testfilePath C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo\\config/config.local.jsonPASSok github.com/kihoonkim/gogo/config 0.036s 하지만 문제는 test coverage 를 측정할 때 오류 가 난다._test\\_obj_test가 경로에 추가되면서 제대로된 경로에서 찾지를 못하면서 오류가 난다. 1234~gogo\\config&gt; go test -coverfilePath github.com\\kihoonkim\\gogo\\config\\_test\\_obj_test/config.local.jsonexit status 500FAIL github.com/kihoonkim/gogo/config 0.033s run, test 때와 cover 옵션을 붙였을 때 runtime.Caller(0)가 리턴해주는 경로가 다른 것이다. 해당 문제를 제대로 해결하지는 못했다. config 패키지의 전체 경로를 하드코딩하든가, _test\\_obj_test 가 경로에 있는 경우 삭제하는 방식으로 해결 할 수 있었다. 하지만, 두 방법 다 좋아 보이지 않는다. 결국엔 환경변수 를 사용하는 방식으로 가기로 결정했다.env library 를 사용해서 구현하였다.라이브러리는 github star를 많이 받은 녀석 중 가장 간단해 보이는 것으로 선택했다. 1~gogo&gt; glide get github.com/caarlos0/env 설치 후 configuration.go, configuration_test.go 를 아래와 같이 변경 후 실행하였다. 1234567891011121314151617181920// gogo/config/configuration.gopackage configimport ( &quot;fmt&quot; &quot;github.com/caarlos0/env&quot;)type Configuration struct &#123; Port int `env:&quot;PORT&quot; envDefault:&quot;3000&quot;` // env library&#125;func GetConfiguration() Configuration &#123; configuration := Configuration&#123;&#125; err := env.Parse(&amp;configuration) // env library if err != nil &#123; fmt.Printf(&quot;%+v\\n&quot;, err) &#125; return configuration&#125; 12345678910111213141516171819// gogo/config/configuration_test.gopackage configimport ( &quot;testing&quot; &quot;os&quot; &quot;fmt&quot;)func TestGetConfiguration(t *testing.T) &#123; // mock env variable os.Setenv(&quot;PORT&quot;, &quot;1234&quot;) configuration := GetConfiguration() if configuration.Port != 1234 &#123; fmt.Errorf(&quot;Expected %d, but Actual %d&quot;, 1234, configuration.Port) &#125;&#125; 1234~gogo\\config&gt; go test -coverPASScoverage: 80.0% of statementsok github.com/kihoonkim/gogo/config 0.040s 테스트 및 커버리지 측정도 정상적으로 동작하는 것을 확인 할 수 있었다. 환경변수는 각 OS 별로 설정하면 될 것이다. windows: 시스템속성 &gt; 환경변수 Linux/Mac: export PORT=4321 linux/mac 이라면 아래와 같이 실행시 넘겨줘도 된다. 12$ PORT=1111 go run main.go1111 docker 를 사용해서 실행한다면 -e 옵션으로 넘겨주면 된다. 1$ docker run ... -e PORT=&quot;1111&quot; ... 환경설정파일을 사용하는 라이브러리와 환경변수를 사용하는 라이브러리에 대해서 테스트 해 보았다. 라이브러리를 떠나서 두 경우다 장단점이 있을 것이다.각자의 환경에 맞게 구성하면 될 것 같다.","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"golang test code.. vendor 이녀석!!","slug":"reactgo/reactgo-4-test-vendor","date":"2017-04-03T06:13:00.000Z","updated":"2021-08-17T00:04:32.702Z","comments":true,"path":"2017/04/03/reactgo/reactgo-4-test-vendor/","link":"","permalink":"https://kihoonkim.github.io/2017/04/03/reactgo/reactgo-4-test-vendor/","excerpt":"","text":"현재 있는 개발 팀의 핵심 프랙티스 중의 하나가 TDD 이다.Test first를 하는 것은 아니지만, Test Code 작성을 매우 강조하고 있다.이와 관련해서는 TDD(android unit test) 에서 설명하고 있으니 참고하면 될 것 같다.TDD를 해야 하기 때문에, 새로운 언어나 프레임워크를 사용할 때 제일 먼저 스파이킹 하는 것이 “Test Code를 어떻게 작성하면 되는 가..” 이다. Java로 작성할 때는 기본적으로 junit을 사용하여 유닛테스트를 작성했다.Golang은 별도의 라이브러리나 프레임워크 도움없이 go test 만으로도 충분히 테스트 할 수 있는 것 같다.심지어 Test Coverage 까지 측정해 준다. 간단한 코드로 테스트를 시작해 보았다.테스트 코드는 테스트하고자하는 파일명 + _test.go 로 작성하면 된다.테스트 파일은 테스트 대상파일과 같은 패키지 에 넣으면 된다. Package testing &gt; Overview To write a new test suite, create a file whose name ends _test.go that contains the TestXxx functions as described here. Put the file in the same package as the one being tested. The file will be excluded from regular package builds but will be included when the “go test” command is run. 테스트는 기본적으로 파일단위가 아니라 패키지단위로 실행 되는 것 같다. 123456// ../gogo/calc/calculator.gopackage calcfunc Sum(a int, b int) int &#123; return a + b&#125; 1234567891011// ../gogo/calc/calculator_test.gopackage calcimport &quot;testing&quot;func TestSum(t *testing.T) &#123; result := Sum(1, 2) if result != 3 &#123; t.Errorf(&quot;expected:%s actual:%s&quot;, 3, result) &#125;&#125; 내가 만든 calc 패키지를 테스트 하기위해서 go test calc라고 입력 하고 실행 했더니 아래와 같이 오류가 났다. 1234C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; go test -v calccan&#x27;t load package: package calc: cannot find package &quot;calc&quot; in any of: C:\\Go\\src\\calc (from $GOROOT) C:\\Users\\kihoonkim\\goworkspace\\src\\calc (from $GOPATH) 패키지 이름만 입력된 경우 $GOROOT 와 $GOPATH 에서 해당 패키지를 찾는 것 같다.따라서 아래와 같이 상대 경로(./xxx) 를 통해서 해당 패키지를 실행 해야 한다. 12345~gogo&gt; go test -v ./calc=== RUN TestSum--- PASS: TestSum (0.00s)PASSok github.com/kihoonkim/gogo/calc 0.033s 패키지명 없이 go test 만 실행하는 경우 현재 디렉토리에 있는 패키지를 찾아 테스트를 실행한다. 12345~gogo\\calc&gt; go test -v=== RUN TestSum--- PASS: TestSum (0.00s)PASSok github.com/kihoonkim/gogo/calc 0.035s 여러 패키지를 한번에 실행시키고 싶으면 일일히 열거해 주거나 ... 을 사용하면 된다.... 은 하위의 모든 패키지를 의미한다. 1~gogo&gt; go test -v ./calc ./utils 1~gogo&gt; go test -v ./... 그런데, ... 을 이용해서 테스트 하는 경우 문제가 있다.package manager를 통해 생성된 vendor 하위에 있는 패키지들까지 인식되면서 오류가 난다. 123~gogo&gt; go test -v ./...vendor\\github.com\\jinzhu\\gorm\\model_struct.go:12:2: cannot find package &quot;github.com/jinzhu/inflection&quot; in......... 안타깝게도 특정 패키지만 exclude 시키는 옵션은 없는 것 같다.linux나 Mac 이라면 아래와 같이 실행 시킬 수 는 있다. 1~gogo $ go list ./... | grep -v vendor | xargs -n1 go test -v package manager로 glide를 사용하고 있다면 더 쉬운 방법이 있다. 1~gogo $ go test -cover $(glide novendor) winodw는 아래 처럼 하면 되긴 하지만, 더 좋은 방법을 찾지는 못했다..ㅠ 12~gogo&gt; go list ./... | findstr /V &quot;vendor&quot; &gt; pkgs.txt~gogo&gt; for /F %p in (pkgs.txt) DO go test %p java 개발시 테스트 코드는 별도의 test 디렉토리를 만들고 그 안에 동일한 패키지 구조로 코드를 만든다.golang 도 처음에는 습관적으로 이런 구조로 디렉토리 구조를 생성했었다.이 경우에 test 디렉토리 아래에 있는 패키지만 실행 시키면 되기 때문에 OS에 종속적인 커맨드 없이 go test 만으로 실행 시킬 수 있는 장점이 있기는 하다. 12345678910~gogo&gt; go test -v ./test/...testing: warning: no tests to run PASSok github.com/kihoonkim/gogo/test 0.034s [no tests to run] === RUN TestSum--- PASS: TestSum (0.00s)PASSok github.com/kihoonkim/gogo/test/calc 0.037s=== RUN TestUtils--- PASS: TestUtils (0.00s)PASSok github.com/kihoonkim/gogo/test/utils 0.043s 하지만!!!Coverage 측정을 해야하는 경우, 반드시 같은 디렉토리에 넣어야 한다. test 디렉토리에 넣은 경우 커버리지 측정 안됨 123456789101112131415~gogo&gt; go test -v -cover ./test/...testing: warning: no tests to runPASScoverage: 0.0% of statementsok github.com/kihoonkim/gogo/test 0.033s coverage: 0.0% of statements [no tests to run]=== RUN TestSum--- PASS: TestSum (0.00s)PASScoverage: 0.0% of statementsok github.com/kihoonkim/gogo/test/calc 0.042s coverage: 0.0% of statements=== RUN TestUtils--- PASS: TestUtils (0.00s)PASScoverage: 0.0% of statementsok github.com/kihoonkim/gogo/test/utils 0.039s coverage: 0.0% of statements 같은 디렉토리에 넣은 경우 커버리지 측정 됨 1234567891011~gogo&gt; go test -v -cover ./calc ./utils=== RUN TestSum--- PASS: TestSum (0.00s)PASScoverage: 100.0% of statementsok github.com/kihoonkim/gogo/calc 0.039s coverage: 100.0% of statements=== RUN TestUtils--- PASS: TestUtils (0.00s)PASScoverage: 100.0% of statementsok github.com/kihoonkim/gogo/utils 0.032s coverage: 100.0% of statements 서두에 언급한 것같이 같은 디렉토리에 테스트파일을 함께 넣는 것을 표준처럼 가이드를 하고 있는데, 이런경우 대상파일의 private 한 func 까지 접근이 가능해 진다.TDD 를 하는 경우 black box 테스트를 하듯이 테스트 대상의 API를 정의해 나가야 한다. 즉, public 한 녀석들만 접근하고 테스트 하는 것이 좋다고 생각한다.하지만 항상 정답은 없는 것 같다. 각자 좋다고 생각하는 방식으로 구조를 잡으면 될 것 같다. 암튼 우리는 Test Coverage를 측정해야 하기 때문에 같은 디렉토리 내에 테스트코드를 넣기로 했다. Test Coverage &amp; Reportgolang 에서 테스트 커버리지를 측정하고 html로 리포트를 보는 방법은 간단하다. 12~gogo&gt; go test -coverprofile=coverage.out~gogo&gt; go tool cover -html=coverage.out 하지만.. vendor 라는 녀석이 항상 문제다… 12~gogo&gt; go test -coverprofile=coverage.out ./calc ./utilscannot use test profile flag with multiple packages shell script로 처리하려면 여기를 참조해 보자. 어려우면 gocov 를 받아서 실행해보자. 12&gt; go get github.com/axw/gocov/gocov&gt; go get -u gopkg.in/matm/v1/gocov-html 12345# windows~gogo&gt; gocov test ./calc .utils | gocov-html &gt; coverage.html# linux$ gocov test $(glide novendor) | gocov-html &gt; coverage.html","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"golang Package Manager로 dependency 관리하기","slug":"reactgo/reactgo-3-packagemanager","date":"2017-04-02T04:18:00.000Z","updated":"2021-08-17T00:04:32.702Z","comments":true,"path":"2017/04/02/reactgo/reactgo-3-packagemanager/","link":"","permalink":"https://kihoonkim.github.io/2017/04/02/reactgo/reactgo-3-packagemanager/","excerpt":"","text":"프로젝트를 할때 혼자 개발하는 것이 아니라면, dependency를 명확하게 관리 하는 것이 중요하다.개발 환경을 세팅할 때 절대로 특정 모듈이나 라이브러리가 설치되어 있다고 가정해서는 안된다.버전관리도 힘들고 서로 다른 환경에서 개발하게 될 수도 있다.또한 이는 CI/CD를 위해서도 매우 중요하다. 회사에서 프로젝트 할때는 glide를 사용하는데..dep이 golang의 공식 PM으로 될 것 같아 이번에는 dep을 설치 및 삽질을 해 보았다.현재 기준(17.04.02)으로 아직 오피셜 하지는 않은 것 같다. 깃헙에 아래와 같이 나와 있다.dep is NOT an official tool. Yet.Note that the manifest and lock file formats are not finalized DEP 설치 및 실행go get 명령어를 통해 간단히 설치 할 수 있다.GOPATH에 따라서 자동으로 설치되는 위치가 정해지기 때문에 어디에서 명령어를 실행하든 상관없었다. 1&gt; go get -u github.com/golang/dep/... dep init 명령어를 통해 dep을 설정 할 수 있다.아무 곳에서나 하면 안되고, 내 repository 로 이동해서 실행해야 한다. 123C:\\Users\\kihoonkim\\goworkspace&gt; cd src\\github.com\\kihoonkim\\gogoC:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; dep init 아래와 같이 vendor 디렉토리와 lock.json, manifest.json 파일이 생성되는 것을 볼 수 있다. dep ensure 를 통해 새로운 패키지를 설치, 업데이트를 할 수 있다.glide는 버전을 명시 하지 않으면 최신 버전을 자동으로 받아 오는 것 같았는데..dep는 @^1.0 처럼 버전을 정확히 명시해 줘야 했다. 1gogo &gt; dep ensure github.com/jinzhu/gorm@^1.0 manifest.json 에 아래 처럼 등록 된 것을 확인 할 수 있다. 1234567&#123; &quot;dependencies&quot;: &#123; &quot;github.com/jinzhu/gorm&quot;: &#123; &quot;version&quot;: &quot;1.0&quot; &#125; &#125;&#125; 하지만.. vendor 디렉토리에 해당 패키지가 설치되지 않았다… dep ensure -update 를 해도 반응이 없다……;;;;; 정식 릴리즈 되면… 써야겠다……ㅠ일단 glide를 설치해서 사용하자. Glide 설치 및 실행glide 설치는 몇 가지 방법이 있지만, linux/mac 에서는 아래 쉘을 실행시키는 것이 제일 쉽다. 1&gt; curl https://glide.sh/get | sh 윈도우에서는 쉘스크립트 실행이 안되서 go get으로 받아왔다. 123C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; go get -u github.com/Masterminds/glideC:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; glide init glide init 을 실행하면 dependency 명시를 위한 glide.yaml 파일이 생성된 것을 볼 수 있다. GORM 패키지를 glide를 통해 다시 받아보자 1gogo&gt; glide get -u github.com/jinzhu/gorm glide.yaml 파일에도 잘 들어가있고, vendor디렉토리에 패키지가 잘 받아져 온 것을 확인 할 수 있다. vendor 디렉토리에 받은 패키지를 모두 삭제하고 glide install 명령을 통해 다시 받아보았다. 123C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; cd vendorC:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo\\vendor&gt; rmdir /s github.com 12345678C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; glide install[INFO] Downloading dependencies. Please wait...[INFO] --&gt; Found desired version locally github.com/jinzhu/gorm 5174cc5c242a728b435ea2be8a2f7f998e15429b![INFO] Setting references.[INFO] --&gt; Setting version for github.com/jinzhu/gorm to 5174cc5c242a728b435ea2be8a2f7f998e15429b.[INFO] Exporting resolved dependencies...[INFO] --&gt; Exporting github.com/jinzhu/gorm[INFO] Replacing existing vendor dependencies Glide 명령어 정리 get glidecurl https://glide.sh/get | sh initializationglide init configurationvi glide.yaml resolve the dependencyglide update reporoducible installationsglide install add more dependencies glide get github.com/foo/bar glide get github.com/foo/bar#^1.2.3 Glide 관련 파일, 디렉토리 vendor glide.lock glide.yaml gitingorevendor 디렉토리나 glide.lock 파일은 glide update/install 시 생성되기 때문에 형상관리 될 필요가 없다..gitingore 에 추가해 놓자. 결론, dep가 공식 릴리즈 되기전까지 glide를 쓰자..사용이 편하고, go get &lt;–&gt; glide get 처럼 명령어도 비슷해서 더 직관적이고 쉬운 것 같다.","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"Golang 설치부터 테스트까지 가보자","slug":"reactgo/reactgo-2-go-setting-run-test","date":"2017-04-01T06:03:00.000Z","updated":"2021-08-17T00:04:32.702Z","comments":true,"path":"2017/04/01/reactgo/reactgo-2-go-setting-run-test/","link":"","permalink":"https://kihoonkim.github.io/2017/04/01/reactgo/reactgo-2-go-setting-run-test/","excerpt":"","text":"설치관련해서는 정리가 잘된 곳이 많아서 넘어가려다가..개인 노트북(Windows10)에 다시 설치하면서 정리도 할겸.. 남겨 본다. golang을 설치해 보자.https://golang.org/dl/ 에서 다운로드 받고 각 OS에 맞게 설치하면 된다.윈도우에서 설치할때는 C:\\Go 에 설치되고, MAC에 설치할때는 /usr/local/go 에 기본으로 설치된다. 개발할 작업디렉토리를 만들자https://golang.org/doc/code.html#Workspacesworkspace를 원하는 곳에 원하는 이름으로 생성하자.java를 개발시 eclipse에서 workspace를 만들고 하위에 여러 프로젝트를 하는 개념으로 생각하면 안된다.한 프로젝트를 개발하기 위한 작업공간을 만든다고 생각해야 한다. 12mkdir %USERPROFILE%\\goworkspacecd %USERPROFILE%\\goworkspace 다음으로 workspace 아래에 세 디렉토리를 만들어 줘야 한다.src contains Go source files,pkg contains package objects, andbin contains executable commands. 1mkdir src pkg bin 123456C:\\Users\\kihoonkim\\goworkspace&gt;dir2017-04-01 오후 03:22 &lt;DIR&gt; .2017-04-01 오후 03:22 &lt;DIR&gt; ..2017-04-01 오후 03:01 &lt;DIR&gt; bin2017-04-01 오후 03:01 &lt;DIR&gt; pkg2017-04-01 오후 03:01 &lt;DIR&gt; src 환경변수 세팅GOROOT, GOPATH를 환경변수에 등록해 주고, GOROOT/bin 을 PATH에 추가해 준다. 12345678910111213141516171819202122C:\\Users\\kihoonkim&gt; go envset GOARCH=amd64set GOBIN=C:\\Go\\binset GOEXE=.exeset GOHOSTARCH=amd64set GOHOSTOS=windowsset GOOS=windowsset GOPATH=C:\\Users\\kihoonkim\\goworkspaceset GORACE=set GOROOT=C:\\Goset GOTOOLDIR=C:\\Go\\pkg\\tool\\windows_amd64set GCCGO=gccgoset CC=gccset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0set CXX=g++set CGO_ENABLED=1set PKG_CONFIG=pkg-configset CGO_CFLAGS=-g -O2set CGO_CPPFLAGS=set CGO_CXXFLAGS=-g -O2set CGO_FFLAGS=-g -O2set CGO_LDFLAGS=-g -O2 gogland IDE를 사용한다면 GOROOT, GOPATH가 제대로 설정되었는지 확인하고, 세팅이 안되어 있다면 다시 지정해 준다. github에 만들어 놓은 repository를 연결 해보자src\\github.com\\kihoonkim 까지 디렉토리를 만들고 git clone을 할 수도 있지만,실수를 줄이기 위해서 go get 을 통해 받아오고 git 설정을 하기로 했다.뭐든 정답은 없으니 편한 방법으로 하면 될것 같다.src, pkg, bin 이나 src 밑에 go get을 통해 다운받아지는 패키지들은 형상관리가 필요 없기 때문에..내 repository에 맞게 git init을 해줘야 한다.git 주소 : https://github.com/kihoonkim/gogo.git 123C:\\Users\\kihoonkim\\goworkspace&gt; go get github.com/kihoonkim/gogoC:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt; git init Hello World 출력해 보기go application을 실행 하기 위해서는 main 패키지 내에 main 함수 가 존재해야 한다.다음은 main.go 파일을 만들고 실행까지 시킨 화면이다. 테스트 코드 작성해 보기https://golang.org/pkg/testing/테스트 코드 작성하는 것에 대해서는 다음에 자세하게 정리해 볼 예정이기 떄문에,일단 테스트 코드 생성 정도만 하고 넘어가보자.실제 실행되는 테스트는 없다.go test 를 통해 테스트 코드를 실행 시킬 수 있다. Commit &amp;&amp; Pushjetbrains 에서 만든 IDE 들을 즐겨 사용하는 이유중 하나가git 연동하는 툴이 좋다는 것이다.커밋 전에 변경된 소스코드를 비교 해서 볼 수도 있고..패어프로그래밍을 할때 커밋전에 리뷰를 할 수도 있다.git commitgit push 12345678C:\\Users\\kihoonkim\\goworkspace\\src\\github.com\\kihoonkim\\gogo&gt;git pushCounting objects: 5, done.Delta compression using up to 4 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (5/5), 510 bytes | 0 bytes/s, done.Total 5 (delta 0), reused 0 (delta 0)To https://github.com/kihoonkim/gogo * [new branch] master -&gt; master","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"Golang 뭐로 개발하지?","slug":"reactgo/reactgo-1-development-env","date":"2017-03-27T14:13:00.000Z","updated":"2021-08-17T00:04:32.701Z","comments":true,"path":"2017/03/27/reactgo/reactgo-1-development-env/","link":"","permalink":"https://kihoonkim.github.io/2017/03/27/reactgo/reactgo-1-development-env/","excerpt":"","text":"개발을 시작 할 때 언제나 선택의 순간이 온다.언어, IDE, framework, Package Manager 등등..백엔드 언어는 Go 를 사용하기로 했기때문에 그에 맞는 녀석들을 선택해야 한다. 이제 막 시작하는 단계이기 때문에 Go와 주변 생태계를 깊이 알지 못한다.어차피 모르는데.. 좋고 나쁘다는 판단 기준도 없었기 때문에대부분 단순히 끌리는 대로 선택하거나 그냥 제일 유명한 것들을 선택했다.당연히 잘못된 선택이 있을 수도 있지만, 그 또한 배움의 과정이라 생각했다.(사실 이름에 go 가 들어가는 녀석들 위주로 선택했다……..) Go 언어 문법 은 예제로 배우는 GO 프로그래밍을 참조해서 공부했다.반나절 정도면 볼 수있고 설치 방법도 정리가 잘되어 있는 것 같다.C언어랑 javascript랑 짬뽕된 문법인 것 처럼 느껴진다.문법 자체는 심플하고 재밌는 요소들이 있는 것 같지만,아직 Go 언어가 가진 패러다임이 무엇인지 이해하지는 못했다.. IDE 는 Android Studio나 intellij를 주로 사용해 왔기 때문에 고민없이 Gogland 를 선택했다.Gogland를 사용하면 좋은 점은 이 곳을 보면 될 것 같다. Package Manager 는 Dep 이 golang의 공식 매니져인 것 같지만, 아직 official tool 이 아니라고 나와있어서, glide 를 선택했다.(안드로이드 개발할 때 이미지 처리하느라 사용한 glide 랑 이름이 같아 친근한 나머지….) Web framework 은 정말 많이 존재하는 것 같다.Revel이 제일 유명하고 많이 사용되는 것 같지만,우리는 Rest, websocket 정도만 지원되면 될 것 같아서 좀 더 가벼워 보이는 gorilla 를 선택했다.web framework 이라기 보다는 몇 개의 library를 모아놓은 toolkit 같아 보인다.mux, websocket 정도만 사용하지 않을까… ORM 은 GORM을 사용하기로 했다.모델이나 DB처리가 많거나 복잡할 것 같진 않지만..특정 DB에 종속되거나 SQL 레벨로 작성하는 것을 좋아하지 않아서ORM기술을 자주 사용하는 편이다.GORM 정말 직관적인 이름인 것 같다. 발음은 고~옴 일까 고름일까..;;현재 dialect로는 mysql, postgresql, sqlite, mssql만 지원하는 것 같다.spring-data-jpa 처럼 정말 편한 정도는 아니지만.. 단순 CRUD는 간단하게 사용할 수 있을 것 같다.안타깝게 로고는 없네…. TEST/Mock 은 아직 고민 중이다.assertion을 위해서 Gomega를 사용하고mocking을 위해서 gomock을 사용할까… 제대로 비교해서 선택하려면 awesome-go 를 참조하면 될 것 같다. Golang 설치 부터 여러 패키지 설치 및 환경설정하며 겪은 삽질은 다음에 공유하기로…..","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}],"tags":[{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"golang","slug":"ReactGo/golang","permalink":"https://kihoonkim.github.io/categories/ReactGo/golang/"}]},{"title":"새 프로젝트의 시작 React! Go!","slug":"reactgo/new_project_reactgo","date":"2017-03-26T05:56:00.000Z","updated":"2021-08-17T00:04:32.701Z","comments":true,"path":"2017/03/26/reactgo/new_project_reactgo/","link":"","permalink":"https://kihoonkim.github.io/2017/03/26/reactgo/new_project_reactgo/","excerpt":"","text":"오랜만에 웹 개발을 하게되었다. 2..3 년 만인가?내 웹 개발 경험의 대부분은 jQuery + Spring 였던 것 같다.최근에는 Angularjs는 ionic을 튜토리얼 수준으로 돌려보느라 사용해 봤고..(Ionic-Firebase)실제 프로젝트에서는 Reactjs를 하루정도 사용해 본 것 같다. 이제 안드로이드 개발 좀 할 만해졌는데.. 웹 개발이라니..몇 년 전만 해도 jQuery가 뭐든걸 다 해줄 것 같던 시대였는데.. 이제는 주변에서 아무도 jQuery 얘기를 하지 않는다.어찌됐든, 난 2017년이 되서야 이 기분을 느끼게 되었다. 우리가 개발할 제품의 대부분의 기능은 화면에서 사용자와 인터렉션 하는 것이고백엔드와 통신보다는 View Component를 재활용 해서 구성하는 것이 많아 보였다.백엔드는 약간의 Rest API와 단순한 DB 처리 수준으로 예상 되었다.Angular2로 프로토타입 수준으로 개발이 되어 있긴했지만,팀원들 대부분 웹개발이 JSP나 jQuery 수준에 머물러 있었고,Angular2 뿐만 아니라 Typescript에 대한 런닝커브가 꽤 클 것 같았고,MVC framework보다는 단순히 View library만 있으면 될 것 같아 과감히 버리기로 결정했다. 결국 ReactJS + SpringBoot 로 결정하고, 바로 기본적인 Test Code와 함께 CI를 구성했다.React를 열심히 굴려보고 있는데.. 우리의 진취적인 PM인 Keen의 한마디가 던져졌다. 회사에서 개발하면서 이렇게 작은 크기의 백엔드를 할 일이 거의 없는데.. Golang 으로 해보는게 어때요? react-redux에서 맨붕 중이었는데.. Golang 이라니..시스템프로그래밍 할 일도 없고.. 동시성 처리할 일도 없을 것 같은데… Golang 이라니..하지만, 우리는 새로운 것에 목마른 순종자들이기 때문에.. SpringBoot 는 과감히 버렸다. Golang지농업.. 나시Golang 등의 아재 개그가 난무하며..이렇게 우리 개발팀 6명은 모든 익숙한 것을 버리고 새로운 환경에 던져졌다. 개발 완료는 4월 말!!우리 개발팀의 Reactjs + Golang 삽질기를 4월 말까지 공유해 보고자 한다.. 잘… 되겠지??","categories":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"intro","slug":"ReactGo/intro","permalink":"https://kihoonkim.github.io/categories/ReactGo/intro/"}],"tags":[{"name":"reactjs","slug":"reactjs","permalink":"https://kihoonkim.github.io/tags/reactjs/"},{"name":"개발일지","slug":"개발일지","permalink":"https://kihoonkim.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%BC%EC%A7%80/"},{"name":"golang","slug":"golang","permalink":"https://kihoonkim.github.io/tags/golang/"}],"keywords":[{"name":"ReactGo","slug":"ReactGo","permalink":"https://kihoonkim.github.io/categories/ReactGo/"},{"name":"intro","slug":"ReactGo/intro","permalink":"https://kihoonkim.github.io/categories/ReactGo/intro/"}]},{"title":"TDD (Android Unit Test) + QnA","slug":"Agile/TDD","date":"2017-03-11T05:24:39.000Z","updated":"2021-08-17T00:04:32.682Z","comments":true,"path":"2017/03/11/Agile/TDD/","link":"","permalink":"https://kihoonkim.github.io/2017/03/11/Agile/TDD/","excerpt":"","text":"현재 속해있는 팀은 사용자중심, Pairing, TDD 를 핵심 프랙티스로 사용하고 있고,PM, CX, DEV 세 역할자가 한공간에서 일을 한다.PM은 비지니스 및 도메인을 분석하고 사용자에게 가치가 있을 기능 들을 찾는다.CX는 이 기능들에 대해서 사용자가 어떻게 사용하면 좋을 지에대해 분석하고 UI를 디자인한다.DEV는 유저스토리와 UI를 받아 실제 제품을 만들어 나간다.제품은 반복, 지속적으로 고객 또는 사용자의 피드백을 반영해 나간다.사용자 피드백에 의해서 요구사항은 언제든 변경됐다. 심지어 이터레이션 중간에도 변경된다.이런 개발환경에서 개발팀은 계속되는 요구사항 변경을 빠르게 반영하면서, 언제든 배포가 가능하도록 준비해야 된다. 빠르게 요구사항을 반영하고, 언제든 배포하고 시연할 수 있으려면 어떻게 해야 할 까?내가 수정한 소스 코드가 다른 소스에 영향을 주지 않았다는 것을 어떻게 알 수 있을까?빠르게 요구사항을 반영해 나가면서 어떻게 리팩토링도 하고 일정한 수준의 설계 품질을 유지 할 수 있을까? 난 이 팀에 합류 했을땐 TDD도 처음이었고, Android 개발도 처음이었다.그저 자바 개발자로서 unit test와 OOP에 대한 지식 정도만 갖고 있을 뿐이었다.약 8개월간 안드로이드 개발을 하면서 위 문제들에 대해 대응하면서 얻은 경험을 공유하고 싶어서 슬라이드를 만들었다.다른 팀에 공유하고 느낀 것은.. 테스트 코드를 작성하는 팀이 거의 없다는 것이다.더 많은 사람들에게 경험을 공유 할 수 있었으면 좋겠다. 현재 속한 회사나 팀의 모든 개발자가 이렇게 일한다거나 일해야 한다는 것은 아니다.같은 개발팀 개발자들과 여러 상황을 대처하며 끊임없이 토론하고 개선해가며 얻은 경험일 뿐이다. 슬라이드에는 없지만, Q&amp;A 를 받았던 질문에 대해서도 공유하고자 한다.질문을 받을 때만다 지속적으로 업데이트 할 예정이다. QnATest Coverage는 어느정도 나오나?커버리지가 높다고 좋은 코드 품질을 가졌다거나, 오류가 없는 제품이라고 보기 힘들기 때문에개발팀원들은 테스트 커버리지를 중요하게 생각하지는 않는다.하지만 jacoco를 통해 CI환경에서 매번 빌드 시 측정이 되고 있다.프로젝트 초반에는 자주 모니터링 했지만, Test code 작성하는 것이 습관이된 이후에는 신경을 쓰진 않았다.보통 Line Coverage 기준으로 89~90% 를 유지했다. 브랜치 전략은 어떻게 하나?git을 사용하고 remote에 master와 development 브랜치가 있다.우리 팀은 개발자의 개발리듬을 매우 짧고 반복적으로 가져가기를 원한다.또한 요구사항 변경에 대해 빠르게 반영하기를 원한다.그렇기 때문에 commit/push 단위가 매우 짧다.로컬에 브랜치를 만들거나 Feature 단위로 브랜치를 만들고 merge 하는 것이 불필요하다고 생각했다.development 브랜치에 바로 commit/push 한다. TDD를 하면 정말 설계가 좋아지나?TDD는 프로그래밍 목적을 명확하게 해준다는 것 뿐이다.좋은 개발자가 좋은 설계를 만든다. 개발자가 누구냐에 따라 설계가 좋아지는 것이다.테스트 코드는 좋은 설계를 만들수 있게 도와주는 도구일 뿐이다.그렇기 때문에 계속 객체지향 설계에 대해 함께 강조하는 것이다. 주석도 잘 안다는 것으로 알고 있는데, 문서화는 어떻게 하나?주석은 메소드 이름으로 대신하길 원한다. 왜 이렇게 짤 수 밖에 없었는지에 대해서 주석을 단다.개발팀의 문서화가 UML에 대한 질문이라면 작성하지 않는다.싱크를 유지하는 것이 매우 큰 병목이라고 생각한다.복잡한 경우 페어와 함께 화이트 보드에 다이어그램을 그리면서 설계를 하고다른 개발팀원들을 모아서 그 자리에서 바로 리뷰를 한다.일정 시간이 지나고 공유가 됐다고 생각하면 사진으로 남긴 후 지워버린다. mocking 할 객체가 너무 많다. 정말 테스트 대상객체 이외에 전부 mocking 해야하나?한 method를 테스트하려는데 mocking 할 객체가 많다면,거대한 객체를 만들고 있는 것이 아닌지 의심해 봐야한다.생성자나 onCreate() 에서 너무 많은 일을 하고 있는지도 확인해 봐야 한다.객체가 가지고 있는 책임이 명확하게 나눠져 있고, 협력관계가 잘 형성되어 있다면mocking 할 객체가 많지 않을 것이다. 객체를 만들기 보다는 Activity 하나에 기능을 다 넣어 두는 것이 변경할 대상이 하나여서 더 좋은 것 아닌가?무질서 속에 질서가 있듯이, 내 방이 아무리 어질러져 있더라도 나는 어떤 물건이든 쉽게 찾을 수 있다.하지만, 다른 사람도 쉽게 찾을 수 있을까? 물건을 찾기 위해 더 어지르고 나름의 질서마져도 깨트릴 것이다. Activity에 모든 기능을 다 넣고, 주석도 잘 달고 메소드도 잘 식별해 놨다고 하더라도,개발자가 바뀌는 순간 모든 것이 무질서하게 된다고 생각한다.그 개발자가 몇 주 뒤의 본인이 될 수도 있는 것이다. 개발자들은 변경될 것 같은 부분을 경험적으로 혹은 본능적으로 파악할 수 있다.interface를 적절하게 사용하면 변경을 지역화 할 수 있다. 객체망을 만들 듯 설계하면서 TDD를 한다고 했는데, 레거시 코드 리팩토링을 위해 테스트 코드는 어떻게 만드나?TDD는 method 하나에 대해서 단위 테스트를 짠다는 느낌보다는객체망을 형성해가며 실행 흐름을 테스트 한다는 느낌이 크다.하지만 이미 존재하는 레거시 코드에 대해서 그렇게 하는 것은 쉽지 않다고 생각한다.우선 외부 라이브러리에 대해서 통합테스트 하는 느낌으로method 레벨로 테스트 코드를 작성하고 리팩토링 해나가는 것이 좋지 않을까.. 좋은 설계를 하려면 어떻게 해야 하나?우리 팀 또한 최고 좋은 설계가 어떤 모습인지 모르고 그렇게 하려고 하지 않는다.처음 부터 디자인 패턴을 생각하고 그렇게 만들려고 하지 않는다.객체 지향 원칙을 따라 개발하다 보면 어느순간 그 패턴이 되어 있는 경우가 많다.한가지 팁은 extract method 를 하는 것이 중요한 것 같다.일단 메소드로 추출되어 있다면 언제든지 다른 객체에게 책임을 넘겨 줄 수 있다. 계속 QnA를 추가 할 수 있기를…","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"TDD","slug":"TDD","permalink":"https://kihoonkim.github.io/tags/TDD/"},{"name":"Android","slug":"Android","permalink":"https://kihoonkim.github.io/tags/Android/"},{"name":"Robolectric","slug":"Robolectric","permalink":"https://kihoonkim.github.io/tags/Robolectric/"},{"name":"Mockito","slug":"Mockito","permalink":"https://kihoonkim.github.io/tags/Mockito/"},{"name":"OOP","slug":"OOP","permalink":"https://kihoonkim.github.io/tags/OOP/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"linux 정리","slug":"linux","date":"2017-02-24T08:56:32.000Z","updated":"2021-08-17T00:04:32.699Z","comments":true,"path":"2017/02/24/linux/","link":"","permalink":"https://kihoonkim.github.io/2017/02/24/linux/","excerpt":"","text":"Linux System Administration실습 환경 CentOS 5.4 kernel 2.6.18 vmware player *.100 : FTP, DNS *.200 : Web VMWare deault Network host PC : 192.168.xxx.1 Router : 192.168.xxx.2 DNS : 192.168.xxx.2 DHCP : 192.168.xxx.254 Remote Login server : Telnet#23, SSH#22 Client : Secure-CRT, Tera-Term, Netterm, Putty…. client 설정 : /etc/ssh/ssh_config server 설정 : /etc/ssh/sshd_config ssh / sshd SSH의 보안강화 자동로그인 Server 12# ll .ssh/-rw-r--r-- 1 root root 397 2월 23 17:15 known_hosts Client 12345678910111213# ssh-keygen -t dsa &lt;-- key pair 생성# ll .ssh -rw-------. 1 root root 736 2017-02-23 17:12 id_dsa &lt;-- private key -rw-r--r--. 1 root root 616 2017-02-23 17:12 id_dsa.pub &lt;-- public key# scp ~/.ssh/id_dsa.pub &#123;server_ip&#125;:~/.ssh/authorized_keys# eval $(ssh-agent)# ssh-add# vi .bash_profile eval $(ssh-agent) ssh-add# vi .bash_logout kill $SSH_AGENT_PID kernel 확인1234# ls /bootvmlinuz-2.6.18-164.el5# uname -r2.6.18-164.el5xen Shell 확인123456# ps PID TTY TIME CMD 3953 pts/2 00:00:00 bash# cat /etc/passwdroot:x:0:0:root:/root:/bin/bash Shell variable 지역변수 : name=KIM 환경변수 : export name[=KIM] : 자식 프로세스에게 복사되어 전달 됨 variable substitution : $ex) echo $PATH command substitution $() day=`date +%d` &lt;— bourne sh month=$(date +%m) &lt;— ksh 연산 substitution (( 연산 ))12345# x=100# y=200# (( sum=x+y ))# echo $sum300 Shell의 File Generation 특수 문자 * : zero를 포함한 more character ? : any single character […] : […]에 나열된 single character PWD cd - &lt;– 이전 디렉토리로 이동 set | grep PWD12OLDPWD=/rootPWD=/etc/sysconfig/network-scripts Prompt1234# set | grep ^PSPS1=&#x27;[\\u@\\h \\W]\\$ &#x27;PS2=&#x27;&gt; &#x27;PS4=&#x27;+ &#x27; Shell 이 로그인시 실행하는 일련의 스크립트1234/etc/profile~/.bash_profile : User specific environment and startup programs~/.bashrc : User specific aliases and functions/etc/bashrc Shell의 숨은 파일 /etc/skel 에서 계성 생성시 복사 됨 (bash_history 는 로그아웃 될때 생성) .bash_history : exit 할 때 메모리에 가지고 있는 history 정보 저장 .bash_profile .bashrc .bash_logout : logout 시 실행하는 스크립트 Shell script 구동 원리 확장자는 의미 없음 : myjob.sh $? : 이전명령 성공 여부 자식 shell 이 구동되며 실행 12# bash myjob.shbash --&gt; bash --&gt; 명령들.. 실행 권한을 허용하려면 12345# mysum.sh -bash: mysum.sh: command not found# ./mysum.sh -bash: ./mysum.sh: 허가 거부됨# chmod 755 myjob.sh 명령으로 실행 할때 어떤 쉘인지 알려주려면 12# vi myjob.sh#! /bin/bash &lt;-- 제일 앞에 쉘 정보 알려줌 현재 쉘에서 실행하려면 12# . .bashrc# source .bashrc 리눅스의 종료와 재시작 종료 halt sutdown -h +10[0,now,hh:mm] init 0 재시작 reboot sutdown -r +10[0,now,hh:mm] init 6 Run Level1234567# /etc/inittab 0 - halt (Do NOT set initdefault to this) 1 - Single user mode &lt;-- network 안됨 2 - Multiuser, without NFS (The same as 3, if you do not have networking) 3 - Full multiuser mode 4 - unused 5 - X11 &lt;-- GUI 12- 런레벨별 실행, 중지되는 서비스 확인 K / S# ls /etc/rc?.d POST : power on self test MBR(부트로더) GRUB Kernel load init process GRUB /etc/grub.conf –&gt; /boot/grub/grub.conf hiddenmenu timeout=5 title splashimage=(hd0,0)/grub/splash.xpm.gz (hd0,0) : 첫번째 하드디스크의 첫번째 파티션 == /boot grub passwd 설정 1234567# grubgrub&gt; md5cryptPassword: ***Encrypted: $1$fOVnB/$Ke.EE9GeW/TuEKQeXYq1V.# vi /etc/grub.confpassword --md5 $1$fOVnB/$Ke.EE9GeW/TuEKQeXYq1V. 리눅스 시간 시스템 시간 : data H/W 시간 (CMOS 시간) : clock 두시간 동기화 : clock -s(시스템시간 바꾸기) / -w(하드웨어시간 바꾸기) 시스템 시간 맞추기12# rdate -s time.bora.net (-p print, -s setting)# date mmddHHMM[yy] VI editor 비정상 종료시 복구방법 12vi -r myfilerm .myfile.swp VI 환경 설정 .exrc(Unix 호환) / .vimrc Tips 입력모드 : i, r, a, o 단어변경 : cw set number / set nonumber set showmode # 리눅스는 기본, – INSERT – set showmatch # 괄호 매치 set ts=4 MAN page 분류번호 : ex) LS(1) man 5 passwd man -a passwd Section 1 : 일반사용자 명령 ( /bin, /usr/bin ) Section 8 : 관리자 명령 ( /sbin, /usr/sbin ) Section 2 : System Call (Kernel 함수) Section 3 : Library Call ( /lib, /usr/lib ) Section 5 : File Format ( /etc ) Linux Directory Tree 모양의 계층적 구조 / : 최상위 디렉토리 /boot : 커널 관련 /dev : 장치파일 /bin : 명령어 /sbin : 관리 명령어 /lib : Library /usr : 추가적인.. /root : root 계정 홈 /home : user들의 홈 /etc : 시스템 설정 파일 /mnt : 새로 마운트 할 곳 /media : 이동식 저장 장치를 시스템에서 auto mount /proc : process 관련된 정보 memory fs, ls /proc/$$ /sys : 하드웨어관련된 정보 memory fs /misc: NFS 관련 /net : NFS 관련 … Mount scsi : /dev/sda[a, b, c, d] IDE : /dev/hda[a, b, c, d] partition 1234567891011121314151617[DISK]-----|sda1 &lt;-- FS : mounted /boot-----|sda2 &lt;-- SWAP-----|sda3 &lt;-- FS : mounted /-----# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda3 11165404 4003200 6585876 38% //dev/sda1 101086 18507 77360 20% /boot/dev/hdc 3754570 3754570 0 100% /media/CentOS_6.8_Final# swapon -sFilename Type Size Used Priority/dev/sda2 partition 4096564 964 -1 # umount /boot or [/dev/sda1] # mount /dev/sda1 /boot /etc/fstab /mnt : 새로 마운트 할 곳 fdisk -&gt; mkfs -&gt; mount 리눅스에 따라서 CD/DVD 장치 명이 다를 수 있음 : ls /dev/cdrom 사용자와 그룹 useradd -u(ID) -g(group) -d(home) -s(shell) : /etc/default/useradd usermod userdel groupadd groupmod groupdel Primary Group : -g ,로그인 했을 때 기본 속한 그룹 / Secondary Group : -G newgrp (group) : 그룹 변경 &lt;-&gt; exit passwd -l username : lock passwd -u username : unlock passwd -d username : delete password pwconv / pwunconv : shadow file 생성 삭제 /etc/passwd : 계정 정보, Primary Group 정보 12계정:패스워드:UID:GID:GECOS:디렉토리:쉘user:x:500:500::/home/user:/bin/bash /etc/shadow : 비밀번호 정보 12계정:암호화된패스워드:암호변경일:암호사용최소일자:암호사용최대일자:user:$1$R0qq4D8J$HM2Eq9PQwP.d/kL2ZhRRz/:17213:0:99999:7::: /etc/group : 그룹 정보, 유저의 Secondary Group 정보 1user:x:500: 사용자별 공간 할당 - quota 파일시스템마다 사용자나 그룹이 생성할 수 있는 파일의 용량과 개수를 제한하는 것 123456789101112131415161718192021222324252627281) # rpm -qa|grep quota2) # mkdir /userHome3) # vi /etc/fstab /dev/sdb1 /userHome ... defaults,usrquota ... # mount /userHome 혹은 # mount -o usrquota /dev/sdb1 /userHome # mount /dev/sdb1 on /userHome type ext3 (rw,usrquota)4) 테스트 user 생성 # useradd -d /userHome/john john # useradd -d /userHome/bann bann # passwd john # passwd bann5) # cd /userHome # quotacheck -aum (all, user, mount) &lt;-- quota check 를 위한 db 생성6) # edquota -u john &lt;--- Block 크기 or Inode(파일) 개수 제한 Disk quotas for user john (uid 507): Filesystem blocks soft hard inodes soft hard /dev/sdb1 40 0 0 10 0 07) # quotaon /userHome &lt;=&gt; # quotaoff /userHome8) # edquota -p john bann # repquota /userHome # quota bann File 유형 - : file d : directory b: block device c : character device l : link s : socket p : pipe Socket 양방향 인터넷 소켓 : 네트워크 통신용 ==&gt; netstat 명령으로 확인 유닉스 소켓 : IPC용 Pipe 단방향 Anonymous pipe : ps -e | grep init Named Pipe : mkfifo 명령으로 생성 File Permission user group other rwx rwx rwx chmod 777 file chmod 7777 file chown username[.groupname] file chgrp groupname file directory : rwx : ls / 파일 생성,삭제 / cd umask : 0022 -&gt; 000 010 010 허용하고 싶지 않은 비트 설정 (rw-r–r–) 12345678910111213141516171819type u g o[0000][000][000][000][000] set user id bit : rws : owner uid 권한으로 실행 가능 set group id bit : rws : owner gid 권한으로 실행 가능 sticky bit : rwt : swap 공간에 남아 있음. root 만 설정 가능 $ ll /usr/bin/chsh-rws--x--x 1 root root 19096 9월 4 2009 /usr/bin/chsh$ chsh -&gt; /etc/passwd 수정해야 됨[ps table]* set user id bit == 1real user id : 일반 유저 : uideffective user id : 권한 체크 유저 : owner uid* set group id bit == 1real group id : 일반 그룹 : uideffective group id : 권한 체크 그룹 : owner gid$ ll -d /tmpdrwxrwxrwt 12 root root 4096 2월 21 15:38 /tmp Switch User su : root는 생략되어 실행 su username : 계정만 바꿈, bash 나 PATH 등은 유지 su - username : username 으로 로그인 한 것과 동일 su -l username : 위와 동일 sudo : root의 제한된 명령을 일반 user에게 허용하기 위해.. (/etc/sudoers) 링크 ls -i : inode 번호 까지 ls -l : inode 에 있는 정보까지 같이 보여 줌 123[Filesystem]| SB | INode Block | Data Block | |-&gt; 1000 | fileA Hard Link : ln 12345678910$ vi fileA$ ln fileA fileA.ln$ ls -il229923 -rw-r----- 2 root root 12 2월 21 17:05 fileA229923 -rw-r----- 2 root root 12 2월 21 17:05 fileA.ln==&gt; inode#, file type, link count, file size 가 동일 함==&gt; INode block을 공유==&gt; data를 변경하더라도 둘이 동일. Data block은 동일하게 사용하기 때문에==&gt; inode, data block 둘다 동일 Symbolic Link : ln -s 123456789# ln -s fileA fileA.sym# ll -i 229923 -rw-r----- 2 root root 14 2월 21 17:08 fileA 229561 lrwxrwxrwx 1 root root 5 2월 22 09:46 fileA.sym -&gt; fileA ==&gt; INode block이 다름 ==&gt; Data block에 링크하고 있는 파일의 패스 정보가 들어있음 ==&gt; inode, data block 둘다 다름 ==&gt; 링크파일을 삭제하고 다시 만들어도 링크관계가 유지됨 Hard link 제한 점 inode 번호를 참조 하기 때문에 다른 파일시스템에 있는 파일은 링크 불가 12# ln /boot/grub/grub.conf mygrub.confln: creating hard link &#x27;mygrub.conf&#x27; to &#x27;/boot/grub/grub.conf&#x27;: 부적절한 장치간 연결 다렉토리는 링크 불가 12# ln mydir testdirln: &#x27;mydir&#x27;: 디렉토리는 하드링크할 수 없습니다 프로그램 설치 명령 RPM (Redhat Package Manager) : 의존성 문제 해결 X 123설치 : # rpm -Uvh package_name.rpm삭제 : # rpm -e package_name조회 : # rpm -qa | grep telnet (-qf -ql -qi) YUM (Yellowdog Update Modified) : 의존성 문제 해결 O 123456# yum install package_name# yum localinstall package_name.rpm# yum check-update# yum update package_name# yum remove package_name# yum info package_name Telnet Telent 요청시 프로세스 생성 과정 (pstree 로 확인 가능)init -&gt; xinetd (/etc/xinetd.d) -&gt; in.telnetd -&gt; login -&gt; bash telnet-server 설치 방법 123456789101112131) # rpm -qa|grep telnet-server 2) # yum [-y] install telnet-server 3) # vi /etc/xinetd.d/telnet disable=no 혹은 # chkconfig telnet on 4) # service xinetd restart[start, stop, status] 5) Listen Socket 확인 # netstat -a|grep telnet 6) 연결시도후 실패할 경우 방화벽 확인 # system-config-securitylevel 7) root로 로그인할려면 # mv /etc/securetty /etc/securetty.bak 파일 묶기 : tar절대경로 사용시 주의! 경로의 맨앞에 / 가 없음. 생성 : # tar -cvf 파일명 대상목록 목록 : # tar -tvf 파일명 풀기 : # tar -xvf 파일명 압축 해제 및 tar 풀기 1234# tar -xzvf 파일명 J : tar + xz z : tar + gzip j : tar + bzip2 파일 압축 zip unzip : 원본 파일 놔두고 압축 12# zip etc.tar.zip etc.tar# unzip etc.tar.zip gzip gunzip : 하드링크 관계, 원본 파일 삭제 후 압축 12# gzip etc.tar# gzip -d etc.tar.gz # gunzip etc.tar.gz bzip2 bunzip2 : Symbolic link, 원본 파일 삭제 후 압축 12# bzip2 etc.tar# bzip2 -d etc.tar.bz2 xz : 원본 파일 삭제 후 압축 12# xz etc.tar# xz -d etc.tar.xz 압축률 12345# ll etc*-rw-r--r-- 1 root root 13763954 2월 22 13:23 etc.tar.zip-rw-r--r-- 1 root root 13763834 2월 22 12:01 etc.tar.gz-rw-r--r-- 1 root root 9214644 2월 22 12:01 etc.tar.bz2-rw-r--r-- 1 root root 8282932 2월 22 12:01 etc.tar.xz dump &amp; restore dump 123456789* Full Backup# dump -0uf /tmp/boot.dump /boot # /dev/sda1 * Incremental Backup# dump -2uf /tmp/boot.dump /boot # /dev/sda1# cat /etc/dumpdates/dev/sda1 0 Wed Feb 22 13:40:22 2017 +0900/dev/sda1 2 Wed Feb 22 13:43:42 2017 +0900 restore 12# restore -rf /tmp/boot.dump# restore -rf /tmp/boot.dump2 파일 위치 검색 find 123456789101112 find 찾는경로 찾는조건 동작# find /home -name Filename [-print] -size +10k -exec 리눅스명령 &#123;&#125; \\; -user KIM -type f[d] -inum 1000 -perm 777 -newer# find . -name fileA# find /bin -inum 1015859# find . -name fileA -exec ls -l &#123;&#125; \\;# find . -name fileA -exec rm &#123;&#125; \\; which : $PATH 에 설정된 디렉터리만 검색 1# which ifconfig whereis : 실행 파일 및 소스, man 페이지 검색 1# whereis ifconfig Time-Schedule 작업 일회성 작업 : at 123456789# at now + 3minutesat&gt; date &gt; /root/at.outat&gt; cal &gt;&gt; /root/at.outat&gt; &lt;EOT&gt;job 2 at 2017-02-22 14:35# at -l &lt;==&gt; atq1 2017-02-22 15:29 a root# at -d 1 [작업번호] &lt;==&gt; atrm 1 12/etc/at.deny : 사용 제한/etc/at.allow : 사용 허용 반복적인 작업 : crontab 123crond 실행되면서 /etc/crontab 참조분 시 일 월 요일 사용자 실행명령01 * * * * root run-parts /etc/cron.hourly 123456789* /var/spool/cron/user_name 으로 크론테이블 생성됨 but root만 접근 가능$ ll /usr/bin/crontab &lt;-- set user id bit-rwsr-sr-x 1 root root 315416 2월 27 2009 /usr/bin/crontab# crontab -l : 리스트# crontab -e : 크론 테이블 수정 45,46,47 14 * * 3 date &gt;&gt; /root/cron.out 45-47 14 * * 3 date &gt;&gt; /root/cron.out# crontab -r : 삭제 파이프 ls | more 2개의 프로그램을 연결해주는 연결 통로 필터 stdin 으로 받아 stdout으로 내보냄 cat wc -[lwc] filename grep (global regx print) : grep ^root /etc/group awk sed 리다이렉션 입출력 방향 변경 stdin 변경 1$ 명령 &lt; 파일 stdout 변경 12$ 명령 &gt; 파일 overwrite $ 명령 &gt;&gt; 파일 append stderr 변경 12$ 명령 2&gt;파일 $ 명령 2&gt; /dev/null 프로세스 실행중인 프로그램 $$ : 내 PID $? : 마지막 실행된 자식 프로세스의 종료 상태 포그라운드 프로세스 : $ sleep 100 백그라운드 프로세스 : $ sleep 100 &amp; 좀비 프로세스 : $ ps -e | grep defunct 고아 프로세스 : 백그라운드 프로세스 종료전에 부모 프로세스가 종료된 경우 1234# ps -ef | grep sleeproot 7926 1 0 16:12 ? 00:00:00 sleep 1000root 7948 1 0 16:17 ? 00:00:00 sleep 2000PPID : 1, TTY : ? 로 변경 됨 작업 : 쉘에서 실행시킨 프로세스 12345678910111213141516# sleep 1000 &amp;[1] 8018# jobs[1]- Running sleep 1000 &amp;[2]+ Running sleep 1000 &amp;# fgsleep 1000[2]+ Stopped sleep 1000# jobs[1]- Running sleep 1000 &amp;[2]+ Stopped sleep 1000# bg 2[2]+ sleep 1000 &amp;# jobs[1]- Running sleep 1000 &amp;[2]+ Running sleep 1000 &amp; 종료 12345# kill 8018 &lt;- pid# kill %2 &lt;- job number# kill -l# kill $$ &lt;- default -15. bash 가 무시함9) SIGKILL 19)SIGSTOP 무시할 수 없음. 커널이 무조건 전달 함 Service service network restart # status, start, stop 데몬, 서버프로세스 시스템과 독자적으로 구동되어 제공되는 프로세스 하드디스크 추가하기 fdisk : 파티션 나누기 123456789# fdisk /dev/sdb n -&gt; p -&gt; 1 -&gt; enter -&gt; enter -&gt; p -&gt; w# fdisk -l /dev/sdb Disk /dev/sdb: 1073 MB, 1073741824 bytes 255 heads, 63 sectors/track, 130 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Device Boot Start End Blocks Id System /dev/sdb1 1 130 1044193+ 83 Linux mkfs : 파일시스템 생성 12345678910111213141516171819202122# mkfs -t ext3 /dev/sdb1 mke2fs 1.39 (29-May-2006) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) 130560 inodes, 261048 blocks 13052 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=268435456 8 block groups 32768 blocks per group, 32768 fragments per group 16320 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Writing inode tables: done Creating journal (4096 blocks): done Writing superblocks and filesystem accounting information: done This filesystem will be automatically checked every 24 mounts or 180 days, whichever comes first. Use tune2fs -c or -i to override mount 123456# mkdir /mydata# mount /dev/sdb1 /mydata# ls /mydata lost+found# mount /dev/sdb1 on /mydata type ext3 (rw) /etc/fstab : 시스템 시작시 자동으로 마운트 되도록 설정 123456# blkid /dev/sda3 /dev/sda3: LABEL=&quot;/&quot; UUID=&quot;22bf335b-fc20-4c8b-8694-760499058928&quot; TYPE=&quot;ext3&quot; SEC_TYPE=&quot;ext2&quot;# e2label /dev/sdb1 /mydata# vi /etc/fstab 장치명[LABEL, UUID] 마운트될디렉토리 FS타입 속성 덤프사용여부 파일시스템체크여부 /dev/sdb1 /mydata ext3 defaults 1 1 RAID123* 실습 환경scsi |------[sda]--[sdb]--[sdc]--[sdd]--[sde]--[sdf]--[sdg]boot |--raid 0--| |--raid 1--|&lt;--복구 Linear RAID : 1번 하드디스크가 모두 채워진 뒤 2번째 하드디스크를 사용 RAID 0(Stripping) : 여러 하드디스크에 동시에 저장. 저장성능 효츌적. 데이터 안전성 보장 못함 1234567891011121314151617181920212223242526272829301) # fdisk /dev/sdc n -&gt; p -&gt; 1 -&gt; enter -&gt; enter -&gt; t -&gt; L -&gt; fd -&gt; p -&gt; w2) # fdisk /dev/sdd 위와 동일3) # ll /dev/md* 장치명 타입 메이져 마이너 # mknod /dev/md0 b 9 0 - 매이져: /proc/devices 확인 가능 - 마이너: 하드웨어의 위치정보 ll /dev/sd*4) # mdadm --create /dev/md0 \\ --level=0 \\ --raid-devices=2 /dev/sdc1 /dev/sdd1 # mdadm --detail --scan 혹은 # mdadm -D -s5) # mkfs.ext3 /dev/md06) # mkdir /raid0 # mount /dev/md0 /raid07) # df =&gt; 용량확인 # cp /bin/c* /raid08) # vi /etc/fstab /dev/md0 /raid0 ext3 defaults 1 1 # umount /raid0 # mount /raid09) # halt============&gt; disk 제거후 재시작 1) # vi /etc/fstab 에서 해당정보 제거 &lt;-- 복구모드에서는 readonly mode 로 마운트 됨2) # mount -o remount / &lt;-- rw 모드로 다시 마운트 되도록 설정 # vi /etc/fstab3) # reboot RAID 1(미러링) : 여러 하드디스크에 중복 저장, 데이터 안전성 보장됨 12345678910111213141516171819202122232425262728293031323334353637381) # fdisk /dev/sdd n -&gt; p -&gt; 1 -&gt; enter -&gt; enter -&gt; t -&gt; L -&gt; fd -&gt; p -&gt; w2) # fdisk /dev/sde 위와 동일3) # mdadm --create /dev/md1 \\ --level=1 \\ --raid-devices=2 /dev/sdd1 /dev/sde1 # mdadm -D /dev/md14) # mkfs.ext3 /dev/md15) # mkdir /raid1 # mount /dev/md1 /raid16) # df =&gt; 용량이 1/2 # cp /bin/d* /raid17) # vi /etc/fstab /dev/md1 /raid1 ext3 defaults 1 1 # umount /raid1 # mount /raid18) # halt============&gt; disk 제거후 재시작1) 확인 # ll /dev/sd* # df # ll /raid1 # mdadm -D /dev/md1 Number Major Minor RaidDevice State 0 8 49 0 active sync /dev/sdd1 1 0 0 1 removed2) # fdisk /dev/sde n -&gt; p -&gt; 1 -&gt; enter -&gt; enter -&gt; t -&gt; fd -&gt; p -&gt; w3) # mdadm /dev/md1 --add /dev/sde1 ; mdadm -D /dev/md1 Number Major Minor RaidDevice State 0 8 49 0 active sync /dev/sdd1 2 8 65 1 spare rebuilding /dev/sde1 # mdadm -D /dev/md1 Number Major Minor RaidDevice State 0 8 49 0 active sync /dev/sdd1 1 8 65 1 active sync /dev/sde1 # fdisk -l RAID 5 : 하드디스크 최소 3개 이상 필요. 패리트비트 사용. (0+0+0+pairity= 짝수). 공간효율 결함 허용. N-1 만큼 공간 사용 LVM (Logical Volume Manager) 여러개의 하드디스크를 합쳐서 한개의 파티션으로 구성 후 필요에 따라 여러 파티션으로 구성 가능 PV: Physical Volume VG: Volume Group LV: Logical Volume PE: Physical Extent LE: Logical Extent 1234 PV VG LV[ 20G ] [ 30G ] =&gt; [ 40G ] =&gt;[ 20G ] [ 10G ] pvcreate PV vgcreate [-s size] VGName PVPath lvcreate [-L size] [-n lvname] VGName pvdisplay / vgdisplay / lvdisplay -m lvextend &lt;–&gt; lvreduce vgextend &lt;–&gt; vgreduce 실습 12345678910111213141516171819201) # fdisk /dev/sdc # fdisk /dev/sdd n -&gt; p -&gt; 1 -&gt; enter -&gt; enter -&gt; t -&gt; L -&gt; 8e -&gt; p -&gt; w2) # pvcreate [-f] /dev/sdc1 /dev/sdd1 # pvdisplay3) # vgcreate myVG /dev/sdc1 /dev/sdd1 # vgdisplay -v myVG4) # lvcreate --size 500m --name myLG1 myVG # lvcreate --size 800m --name myLG2 myVG5) # mkfs -t ext3 /dev/myVG/myLG1 # mkfs -t ext3 /dev/myVG/myLG26) # mkdir /lvm1 # mkdir /lvm2 # mount /dev/myVG/myLG1 /lvm1 # mount /dev/myVG/myLG2 /lvm2 네트워크 장치 정보 : ifconfig eth0 ifup eth0 / ifdown eth0 root 만 접근가능 하도록 설정 1# touch /etc/nologin IP 고정하기 123456# cat /etc/sysconfig/network-scripts/ifcfg-eth0# Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]DEVICE=eth0BOOTPROTO=dhcpONBOOT=yesHWADDR=00:0c:29:7c:ca:a6 12# system-config-network# service network restart nslookup : DNS test 12345678910111213141516# nslookup&gt; serverDefault server: 192.168.214.2Address: 192.168.214.2#53&gt; www.naver.comServer: 192.168.214.2Address: 192.168.214.2#53Non-authoritative answer:www.naver.com canonical name = www.naver.com.nheos.com.Name: www.naver.com.nheos.comAddress: 125.209.222.141Name: www.naver.com.nheos.comAddress: 125.209.222.142&gt; exit /etc/sysconfig/network : hostname 설정 /etc/sysconfig/network-scripts/ifcfg-eth0 : 네트워크 정보 /etc/nsswitch.conf : 정책 &gt; hosts: files dns /etc/hosts : /etc/resolv.con : DNS 서버 정보 DNS(Domain Name System) 서버 : #53 캐싱 전용 네임 서버 : URL의 IP 주소를 알려주는 네임 서버 123456789101112131415161718# yum install caching-nameserver# vi /etc/named.caching-nameserver.conf &lt;-- 상위 버전에서는 /etc/named.conf 127.0.0.1 -&gt; any localhost -&gt; any# named-checkconf /etc/named.caching-nameserver.conf# service named start# nslookup &lt;-- nameserver 테스트&gt; server 192.168.214.100 Default server: 192.168.214.100Address: 192.168.214.100#53&gt; www.naver.com...# vi /etc/resolv.confnameserver 192.168.214.100# chkconfig --list named# chkconfig --level 235 named on 마스터 네임 서버 : 도메인에 속한 컴퓨터들의 이름을 관리하고, 외부에서 해당 컴퓨터 IP주소를 알기 원할 때 알려주는 네임 서버 1234567891011121314151617181920212223# vi /etc/named.rfc1912.zones &lt;-- 상위 버전에서는 /etc/named.conf 에 같이 관리 zone &quot;test.com&quot; IN &#123; type master; file &quot;test.com.db&quot;; allow-update &#123; none; &#125;; &#125;;# vi /var/named/chroot/var/named/test.com.db $TTL 3H @ SOA @ root. ( 2 1D 1H 1W 1H ) IN NS @ IN A 192.168.214.100 www IN A 192.168.214.200 ftp IN A 192.168.214.100 blog IN A 192.168.214.150 ==&gt; TTL : time to live @ : zone name # named-checkzone test.com /var/named/chroot/var/named/test.com.db zone test.com/IN: loaded serial 2 OK# service named restart FTP 서버구축 : vsftpd 설치 여부 확인 1# rpm -qa|grep vsftpd 설치 123# yum install vsftpd`# service vsftpd start [ stop, start, restart, status ]# netstat -a|grep ftp 부팅시 자동으로 실행되도록 설정 12345678# chkconfig --list vsftpd vsftpd 0:해제 1:해제 2:해제 3:해제 4:해제 5:해제 6:해제 &lt;-- run level# chkconfig --level 235 vsftpd on # ll /etc/rc2.d/S*vsftp* lrwxrwxrwx 1 root root 16 2월 24 10:23 /etc/rc2.d/S60vsftpd -&gt; ../init.d/vsftpd# chkconfig --level 2 vsftpd off &lt;-- 링크 삭제# ll /etc/rc2.d/K*vsftp* lrwxrwxrwx 1 root root 16 2월 24 10:26 /etc/rc2.d/K50vsftpd -&gt; ../init.d/vsftpd 연결시도후 실패할 경우 방화벽 확인 12# system-config-securitylevel or system-config-firewall# iptables -F root로도 연결하려면 123* root 주석처리/etc/vsftpd/ftpusers &lt;-- not allowed to login/etc/vsftpd/user_list &lt;-- denied user Anonymous User 연결 123456789# grep ^ftp /etc/passwd ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin# cd /var/ftp &lt;-- ftp의 home directory# ls -l drwxr-xr-x 2 root root 4096 9월 4 2009 pub# vi /etc/vsftpd/vsftpd.conf anon_upload_enable=YES &lt;-- upload 허용# chmod 777 /var/ftp/pub or chown ftp.ftp /var/ftp/pub xinetd 형태로 설치 12345678# service vsftpd stop# vi /etc/vsftpd/vsftpd.conf listen=NO# cp /usr/share/doc/vsftpd2.x.x/vsftpd.xinetd /etc/xinetd.d/vsftpd# vi /etc/xinetd.d/vsftpd disable=no# service xinetd restart SELinux network의 application level의 보안 정책 123456789101112131415161718192021# getenforce Enforcing# getsebool -a | grep ftp allow_ftpd_anon_write --&gt; off allow_ftpd_full_access --&gt; off allow_ftpd_use_cifs --&gt; off allow_ftpd_use_nfs --&gt; off ftp_home_dir --&gt; off ftpd_connect_db --&gt; off ftpd_use_fusefs --&gt; off ftpd_use_passive_mode --&gt; off httpd_enable_ftp_server --&gt; off tftp_anon_write --&gt; off tftp_use_cifs --&gt; off tftp_use_nfs --&gt; off# setsebool -P allow_ftpd_full_access 1# vi /etc/sysconfig/seLinux# setenforce 0# getenforce Permissive NFS (Network File System) 서버 NFS server : 최소 runlevel 3 12345678# rpm -qa | grep nfs-utils# vi /etc/exports /share 192.168.214.*(rw,sync) # (rw,sync,no_root_squash)# mkdir /share# chmod 707 /share# service nfs start# exportfs -v /share 192.168.214.*(rw,wdelay,root_squash,no_subtree_check,anonuid=65534,anongid=65534) nfs는 rpc를 사용하는데.. rpc는 고정된 port가 아니기 때문에, 중재자(111 포트)가 필요 1234# ps -e|grep port or rpcbind # rpcinfo -p 프로그램 버전 원형 포트 100000 2 tcp 111 portmapper client 1234567891011# showmount -e 192.168.214.100 Export list for 192.168.214.100: /share 192.168.214.*# mkdir /myShare# mount -t nfs 192.168.214.100:/share /myShare# df192.168.214.100:/share 11165408 4216736 6372352 40% /myShare- root 계정으로 파일을 생성시 NFS 서버 설정에 따라 계정이 다르게 보임-rw-r--r--. 1 nfsnobody nfsnobody 0 2017-02-24 15:04 rootfile &lt;-- root_squash-rw-r--r--. 1 root root 0 2017-02-24 15:06 rootfile2 &lt;-- no_root_squash NTP (Network Time Protocol) Stratum 1~15 계층 구조로 시간을 맞출 수 있음 설치 12# rpm -qa|grep ntp# yum install ntp 서버 (CentOS5) 123456789# vi /etc/ntp.conf server 127.127.1.0 # local clock fudge 127.127.1.0 stratum 10# service ntpd start# chkconfig --level 35 ntpd on# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*LOCAL(0) .LOCL. 10 l 27 64 377 0.000 0.000 0.001 클라이언트 (CentOS6) 123456789101112# vi /etc/ntp.conf server 192.168.214.100# service ntpd start# chkconfig --level 35 ntpd on# ntpq -p &lt;== stratum 16 으로 아직 맞춰지지 않았음 remote refid st t when poll reach delay offset jitter==============================================================================192.168.214.100 .INIT. 16 u 37 64 0 0.000 0.000 0.000# ntpq -p &lt;== stratum 11 (server st == 10) remote refid st t when poll reach delay offset jitter==============================================================================*192.168.214.100 LOCAL(0) 11 u 1 64 1 0.646 0.025 0.000 autofs NFS client service 1234567891011121314# rpm -qa | grep autofs# ps -e | grep auto 1745 ? 00:00:00 automount# lsmod | grep auto autofs4 21076 3# vi /etc/auto.master /net -hosts : /net 아래에서 호스트명으로 접속(cd)시 자동 마운트 /misc /etc/auto.misc : auto.misc 에 설정된 정보로 자동 마운트# vi /etc/auto.misc data -fstype=nfs 192.168.214.100:/share# cd /net/192.168.214.100/share # cd /misc/data Samba Unix 계열, Windows 계열 모두 가능 윈도우 : 공유 폴더 12345678910111213141516# rpm -qa|grep samba# smbclient -L 192.168.214.1/smbShare -U linuxuser Domain=[M13054] OS=[Windows 7 Enterprise 7601 Service Pack 1] Server=[Windows 7 Enterprise 6.1] Sharename Type Comment --------- ---- ------- ADMIN$ Disk 원격 관리 C$ Disk 기본 공유 IPC$ IPC 원격 IPC samShare Disk session request to 192.168.214.1 failed (Called name not present) session request to 192 failed (Called name not present) session request to *SMBSERVER failed (Called name not present) NetBIOS over TCP disabled -- no workgroup available# mount -t cifs //192.168.214.1/smbShare /sambaMount -o username=linuxuser Command1234567- 일반명령 : /bin/ or /usr/bin- 관리명령 : /sbin/ or /usr/sbin- $PATH 에서 명령을 찾아서 실행$ shutdown -h +10-bash: shutdown: command not found$ /sbin/shutdown -h +10shutdown: you must be root to do that! id : 내 정보 passwd : 패스워드 변경 ipcs : ipc status whereis : 어디에 있나? pwd : 현재 디렉토리 date : 시간 확인 cal : 현재 달 chsh : change shell touch : 0byte file 생성 cat / head / tail / more / less : 파일 보기 file : 어떤 종류의 파일인지 보기 history: !number !character alias c=clear echo $hello &lt;– variable ps -f (현재 터미널에서 사용중인 프로세스) export : 지역변수 -&gt; 환경변수 env : 환경변수 보기 set : 지역변수 + 환경변수 보기 who : 누가 접속해 있나 who -r : run level 확인 tty : 접속한 가상 터미널 확인 date : 시스템 시간 확인 clock : hardware 시간 확인 rdate : 시간 재 설정 df : 파일시스템 확인 swapon : swap 공간 확인 free : 메모리 공간 확인 mount : 마운트, 장치를 특정 디렉토리에 연결 umount : 언마운트 eject : 언마운트 + 장치 제거 pstree : 프로세스 부모 자식 관계 보기 stty -a : 터미널 시그널 확인 blkid /dev/sda3 : 블럭 ID scp src dest : 리모트 복사 lsmod : 커널 모듈 확인","categories":[{"name":"linux","slug":"linux","permalink":"https://kihoonkim.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://kihoonkim.github.io/tags/linux/"}],"keywords":[{"name":"linux","slug":"linux","permalink":"https://kihoonkim.github.io/categories/linux/"}]},{"title":"Definition of Done","slug":"Agile/Definition-of-Done-in-Agile","date":"2017-01-27T07:16:39.000Z","updated":"2021-08-17T00:04:32.681Z","comments":true,"path":"2017/01/27/Agile/Definition-of-Done-in-Agile/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Agile/Definition-of-Done-in-Agile/","excerpt":"","text":"Avoid Chaos in Agile Development by Defining “Done”애자일 프로젝트는 유저스토리의 완료 처리를 통해 진행상황이 관리된다. 따라서, 유저스토리의 **완료(Done)**의 기준에 대해 정확하고 일관성있게 이해하는 것이 중요하다. Key Challenges 소프트웨어 개발 프로젝트는 정확하고 투명한 진행상황 관리가 필요하다 애자일 프로젝트에서는 완전히 완료된 일만 트래킹한다 유저스토리에만 집중하다보면, 비기능 요구사항을 방치하게 될 수도 있다 Recommendation 유저스토리의 완료의 의미가 무엇인지 정의해라 유저스토리가 완전히 완료된 것만 트래킹해라 완료의 정의를 가능한 가볍게 유지해라 Introduction애자일 프로젝트는 프로젝트의 현재 상태를 정확히 알지 못해 실패하는 경우가 있다. 누가 하고 있는지, 얼마나 많은 일이 남았는지 등이 명확하게 보여야 한다. 간혹 요구사항이 누락되거나 stakeholder의 관심사항이 프로젝트 끝까지 남아있는 경우가 있다. 이런 문제를 해결하려면, 완전히 완료된 유저스토리란 무엇인지, 그 정의를 모든 프로젝트 구성원이 이해하고 있어야한다. Is It Done Yet??개발자가 **유저스토리를 완료(Done)**했다고 말했는데, Unit Test 코드가 없거나, VCS에 커밋하지 않았다면? QA가 해당 스토리는 테스트가 더 필요하다고 말한다면? 나중에 개발자가 소스코드를 다시 수정했다면?? 성능테스트를 해야되는 상황이라면?? 스크럼마스터는 개발자에게 다음 스토리를 진행하도록 해야 할까?? 각 개발자마다 다른 기준을 가지고 있거나, 전반적인 기준이 존재하지 않는 다면, 그 프로젝트는 관리되지 않고, 혼돈 상태가 될 것이다. Define What It Means for a Story to be “Done”Why Define the Completion of a “Story”스토리 레벨에서 Done을 정의하는 것은 프로젝트 진행상황을 정확하고 일관성있게 추적할 수 있게 한다. 애자일 프로젝트에서는 단순히 해당 이터레이션에서 계획된 스토리 대비 완료된 스토리의 수 를 추적하면 된다.(번다운차트 활용) 스토리가 완료되는 기준이 명확하지 않으면, 얼마나 일이 진행되고 있는지, 프로젝트의 현재상태는 어떤지 알 수가 없다. Define Completion of an “Iteration”이터레이션 별로 테스트나 문서의 레벨이 다르다면, 이터레이션의 진행상황을 추적하기 어렵다. 이터레이션이 지연되지 않게 하려면, 워크아이템을 제한하고 리스크를 낮출 필요가 있다. 워크아이템을 이터레이션에서 개별 스토리로 이동시키고, 지속적으로 개선을 해라. 리스크가 있거나 먼저 완료되야 하는 것이 있다면 우선순위를 조정하라. Define Completion of a “Project”프로젝트의 진행상황을 어떻게 추적할 것인가? 애자일 프로젝트 전체가 완료(Done)되는 것을 조직에서 어떻게 알 수 있는가? 애자일 프로젝트는 프로젝트 기간동안 발견되는 새로운 정보(요구사항)를 받아들인다. 이는 프로젝트 스코프가 계속 커지는 문제가 생길 수 있다. 그렇기 때문에 애자일 프로젝트는 기간과 자원등을 고정할 필요가 있고, 중요한 기능을 우선순위화 해서 먼저 완료될 수 있게 해야된다. 그 기간이 완료됐다면, 제품은 납품(Delivered)되어야 한다. How to Define Done“It Compiled, so I’m Done.” ??? Define of Done 스토리가 완료되기 전에 해야될 일이나 만들어야 하는 것들이 무엇이 있는지 모두의 동의하에 명확히 해야된다. 프로젝트에 영향을 주지 않는 범위에서 다양한 이해관계자의 요구를 반영하여 최대한 상세히 해야된다. 이는 프로젝트 전체에서 잘 이해하고 있어야한다. Do Not Track Partially Complete WorkI am 82% done with that task. 이 말은 스토리가 거의 완료(almost done)되었다는 의미로 사용했을 것이다. 하지만, 아직 진행중인 스토리의 진행상황을 추적하지 마라. 애자일 프로젝트에서 스토리는 작다(small). 그러므로 단순하게 Done / Not Done 으로만 관리해라. 거의 완료된 스토리를 완료된 것이라고 간주하다보면 배포하거나 데모할 수 있는 스토리가 없어질 수도 있다. 스토리가 고객에게 보여줄 준비가 되지 않았다면, 그건 Not Done 이다. Apply Done at the Story Level하나의 스토리의 모든 작업이 완료된 경우에 다음 스토리를 진행하라. 일부 작업이 이터레이션이 끝날때 까지 남아있더라도, 완료로 간주해서는 안된다. Make Sure the Definition of Done Is Comprehensive애자일은 문제의 가장 단순한 해결책을 찾는 것에 집중하기 때문에, 설계나 사용자, 기능 등에 관련된 문서를 없애려는 경향이 있다. 완료(Done)의 의미를 정의할때, Architect, DA, UX, 보안담당자등의 의견이 반영되어야 한다. Coding: 코딩 표준, 코드리뷰, 패어링 등의 수준이 모든 개발팀이 동의해야된다. Nonfunctional requirements: 소프트웨어는 기능이 잘 동작하는 것만으로 충분하지 않다. 다음과 같은 고려사항이 있다. Security Performance Scalability Production Readiness Documentation Unit Tests: 코드 커버리지의 수준이 명확해야 한다. Functional, Integration and Acceptance Tests: 스토리 마다 이슈나 문제등이 진짜 해결됐는지 보장할 수 있어야 한다. Demo: 언제든지 새기능이 사용자에게 보여줄 수 있어야 된다. Application Life Cycle Management and Source Control: 스토리가 완료됐다면 VCS, ALM에도 정확히 반영해야 된다. Refactoring and Technical Debt reduction: 대부분의 코드들이 지속적으로 리팩토링되고 기술적 부채를 해결해 나가기 때문에 Done이 다시평가 되어야 한다. Keep the Definition of Done as Light as Possible12- Agile Manifesto 중..&quot;maximize the amount of work not done.&quot; 하지 않아도 되는 일을 최대로 찾아라. 즉, 일을 단순화해라. 광범위해게 완료(Done)을 정의하다보면, 정의가 너무 커지고 무거워지는 위험이 있다. 미처 생각지 못했던 완료의 의미가 있다면 추가해나가고, 더이상 의미없는 항목은 빼려는 노력을 지속적으로 해야된다. Done의 정의가 너무 광범위하고 크면 애자일 개발팀은 느려지고 많은 장점을 잃는다. 여러 산출물(Artifacts)에 대해서 효율성과 필요성에 대해서 지속적으로 평가를 해라. Continuously Streamline애자일 초기단계에는 Done의 정의에 새로운 항목이 추가되기 때문에 많은 시간이 필요하다. 하지만, 이터레이션별 산출물을 간소화하고 최적화하다보면 시간이 줄어들 것이다. Simplify by Changing Artifacts문서를 관리하는 이유는 크게 두 가지이다. 기존 개발팀이 아무도 존재하지 않은 상황에서 소프트웨어를 잘 유지보수 해야되는 경우 새로운 맴버가 들어온 경우 트레이닝 목적으로 사용하는 경우 애자일에서 문서는 프로세스로 대체할 수 있다. 첫번째 경우는 코드를 명확하게 작성하고, 자동화 테스트를 함으로서 해결한다. 두번째 경우를 위해서 패어 프로그래밍 기법을 사용하여 트레이닝할 수 있다. 사용가능한 기술을 통해서 문서를 가볍고 효율적으로 바꿀수도 있다. 문서를 Wiki로 바꾼다든가, Javadoc과 같은 툴을 사용할 수 도 있다. Simplify by Removing Artifacts문서가 비즈니스 요구사항을 더이상 해결할 수 없거나, 이를 생성하거나 유지보수하는 비용 대비해서 그다지 가치를 주지 못하는 것이라면 그 문서를 없애라. Defining Done is Foundational to Agile Project Success제대로 관리될때, 애자일 프로젝트는 폭포수 방식 보다 더 빠르게 가치있는 소프트웨어를 만들 수 있다. 애자일 팀은 완료된 유저스토리를 통해서 진행상황을 추적하고 관리한다. 그렇기 때문에 일관성있고 완벽한 완료(Done)의 의미가 중요하다. 진행상황을 정확하게 측정할 수 있어야, 제한된 시간과 자원내에서 최대의 가치를 고객에게 전달 할 수 있다.","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"agile","slug":"agile","permalink":"https://kihoonkim.github.io/tags/agile/"},{"name":"dod","slug":"dod","permalink":"https://kihoonkim.github.io/tags/dod/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"Agile Fundamentals (1day course)","slug":"Agile/AgileFundamentals","date":"2017-01-27T07:16:39.000Z","updated":"2021-08-17T00:04:32.681Z","comments":true,"path":"2017/01/27/Agile/AgileFundamentals/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Agile/AgileFundamentals/","excerpt":"","text":"Agile fundamentals Slide Agile 강의 SCSA 6기 SCSA 7기","categories":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}],"tags":[{"name":"agile course","slug":"agile-course","permalink":"https://kihoonkim.github.io/tags/agile-course/"}],"keywords":[{"name":"Agile","slug":"Agile","permalink":"https://kihoonkim.github.io/categories/Agile/"}]},{"title":"Microservices Reading List","slug":"Microservices Architecture/MSA Reading List","date":"2017-01-27T06:44:40.000Z","updated":"2021-08-17T00:04:32.692Z","comments":true,"path":"2017/01/27/Microservices Architecture/MSA Reading List/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/MSA%20Reading%20List/","excerpt":"","text":"Microservice ArchitectureJames Lewis Micro Services: Java, the Unix Way Martin Fowler Microservices Resource Guide What are Microservices? When Should I Use Them? Test Cris Richardson microservices.io Introduction to microservices Building microservices using an API gateway Building Microservices: Inter-Process Communication in a Microservices Architecture Building microservices with Spring Boot – part 1 Building microservices with Spring Boot – part 2 Deploying Spring Boot-based microservices with Docker – part 3 Building and deploying microservices with event sourcing, CQRS and Docker NodeJS: the good parts? Matt Stine Microservices Reading List Microservices Are SOLID Benjamin Wootton Microservices - Not A Free Lunch!Weronika Łabaj Goodbye Microservices, Hello Right-sized Services 조대협 대용량 웹서비스를 위한 마이크로 서비스 아키텍쳐의 이해 마이크로서비스 아키텍쳐(MSA)는 선택이 아니라 필수다 MSA 아키텍쳐 구현을 위한 API 게이트웨이의 이해 #1 MSA 아키텍쳐 구현을 위한 API 게이트웨이의 이해 #2 - API 게이트웨이 기반의 디자인 패턴 Micro Service Architecture의 이해_slide 정도현(MORE AGILE) 마이크로서비스가 가져올 미래의 개발 패러다임 윤석찬 마이크로서비스 인 액션 Gregor Hohpe Starbucks Does Not Use Two-Phase Commit 스타벅스는 2단계 커밋을 사용하지 않는다. Cloud Native Application What being cloud-native really means ‘Cloud Native’: What It Means, Why It Matters The Twelve-Factor App (영어) The Twelve-Factor App (한국어) 12-Factor Apps in Plain English Why 12 Factor Application Patterns, Microservices and CloudFoundry Matter","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"(SDS 사내 기고) Microservices Architecture 란?","slug":"Microservices Architecture/[SDS사내 기고] Microservice Architecture란","date":"2017-01-27T06:44:39.000Z","updated":"2021-08-17T00:04:32.692Z","comments":true,"path":"2017/01/27/Microservices Architecture/[SDS사내 기고] Microservice Architecture란/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/[SDS%EC%82%AC%EB%82%B4%20%EA%B8%B0%EA%B3%A0]%20Microservice%20Architecture%EB%9E%80/","excerpt":"","text":"Microservices Architecture모놀리틱 아키텍쳐(Monolithic Architecture)우리가 전통적으로 SI나 솔루션을 개발하던 모습은 모든 기능을 패키지 단위로만 구분해서하나의 프로젝트에 넣어서 관리하는 것이었습니다. 심지어 모든 개발팀이 공유해서 말이죠.그리고 이 프로젝트 구성을 보면 뛰어난 SA들이 전체 구조를 잡고, 모든 기술 스택을 정하고, 개발 표준을 잡아둡니다.개발자들은 이 틀 안에서 개발가이드대로 업무 로직만 작성하면 되는 것이죠. 원하는 기술을 마음대로 적용할 수 없는 것이죠.. 다른 팀의 서비스나 데이터가 필요하면 어떻게 했나요?아마도 바로 클래스 참조를 하거나 DB Table을 Join 해서 처리 했을 겁니다.이 방식으로 개발하면 모든 서비스마다 같은 기술, 같은 환경을 사용하기 때문에유지보수도 쉽고 테스트하기도 쉽고 배포도 쉬운 장점이 있습니다. 모놀리틱 아키텍쳐의 문제점하지만, 소프트웨어는 시간이 지날수록 변경이 생기게 되어 있고,규모가 점차 커지고 사용자가 많아지다 보면 문제가 생기게 됩니다.이런 구조에서 다른 팀에서 오류 난 소스를 커밋하는 바람에 Jenkins 빌드가 안돼서내가 수정한 소스가 반영이 안된 경험이 많이 있었죠.(이문제로 프로젝트 내에 빌드관리자라는 특이한 역할자를 두기도 하죠..) 그 외에도 클래스를 직접 참조하다 보니 서비스간 의존성이 높아져서 수정하기 어려워지고,서비스가 커질수록 빌드, 배포하는 시간이 오래 걸리는 등의 문제가 생기게 됩니다.그리고 특정 서비스에 부하가 생겨서 해당 서비스의 인스턴스만 늘리고 싶더라도모든 서비스가 하나의 WAS로 배포되기 때문에 전체 서비스를 함께 늘리는 방법 밖에 없습니다. 즉, 이런 방식은 프로젝트 관리는 용이 하지만 변화를 수용하는 것이 어려운 모델인 것입니다.사람들은 이런 방식을 모놀리틱 아키텍처(Monolithic Architecture)라고 부릅니다. 우리가 만든 서비스를 사용하는 사용자는 점점 글로벌 해지고,클라이언트 종류는 웹, 모바일 뿐만 아니라 수많은 센서로까지 확장되고 있습니다.이처럼 다양한 사용자 및 클라이언트가 보내는 요청에 대해 서비스가 잘 반응해야 됩니다.잘 반응해야 된다는 말을 다시 풀어보면, 요구사항 변경에 대해 빠르게 대처 할 수 있어야 되고,요청 량에 따라서 서비스 별로 스케일 인/아웃이 되는 등시스템이 변화를 수용 할 수 있는 구조여야 된다는 말입니다.모놀리틱 아키텍처만으로는 한계가 있는 시대가 된 것이죠. 마이크로서비스 아키텍처(Micoservices Architecture)그래서 새롭지만 새롭지 않은 마이크로서비스 아키텍처라는 용어가 나오게 되었습니다.기존 CBD나 SOA를 접해본 사람이라면 새롭지 않을 것이고, 그렇지 않은 사람은 새로운 개념 일 것입니다.서비스가 독립적으로 수행되고 재사용 가능해야 된다는 기본적인 사상아래좀 더 대용량, 대규모 개발에 맞도록 경량화되고 변형된 아키텍처로 볼 수 있습니다.그래도 말이 참 어렵고 잘 와 닿지가 안죠? 마이크로 서비스 아키텍처는 옆의 그림처럼 서비스는 각각 다른 WAS로 배포되고 DB도 분리되어 있습니다.즉, 다른 서비스에 영향을 받지 않고 WAS 인스턴스를 늘리고 줄이거나 다른 서비스로 대체할 수 있는 것이지요.각 서비스들은 자신이 가진 기능들을 REST API로 노출 시킵니다.클라이언트나 다른 서비스들과는 정의된 API를 보고 통신을 할 뿐,내부적으로 어떻게 구현되고, 어떻게 변경되든 신경을 쓰지 않아도 됩니다.클래스를 직접 참조하거나 테이블 조인을 하고 있었다면 변경에 대응하기 쉽지 않았겠죠. 마이크로서비스 아키텍처의 장점이처럼 마이크로서비스 아키텍처는 많은 장점을 가지고 있습니다.서비스단위로 작게 개발되기 때문에 빌드 및 배포시간이 상대적으로 짧습니다.서비스 별로 독립적으로 내렸다 올릴 수 있고, 요청 량에 따라 인스턴스를 늘리고 줄이기도 쉽습니다.또한 서비스 별로 적절한 기술 스택을 선택할 수 있죠.예를 들면 파일 관리하는 서비스라면 Java보다는 node.js 같은 기술을 사용하는 것이 좋을 것이고,로그를 관리하는 서비스라면 RDBMS보다는 NoSQL DB를 사용하는 것이 좋겠죠. 마이크로서비스 아키텍처의 담점반면에 단점 또한 존재합니다.무엇보다 분산환경을 구성해야 되기 때문에 복잡합니다.트랜잭션을 구현하는 것도 매우 어렵고, 서비스마다 다른 기술을 사용하기 때문에 운영관점에서 힘든 점도 많이 있죠.그리고 서비스 별로 중복되는 라이브러리도 존재하고,WAS도 여러 개 뜨다 보니 CPU나 메모리 같은 자원의 오버헤드도 존재합니다.따라서 MSA는 상황에 맞게 장단점을 잘 고려해서 도입하는 것이 중요합니다. 마이크로서비스 아키텍처의 구현 기술이제 실제 구현관점에서 패턴이나 관련 기술 대해 간략히 소개해 보겠습니다.크리스 리차드슨의 블로그(http://microservices.io) 에 잘 정리 되어 있으니 한번 들어가보면 좋을 것 같습니다.GitHub(https://github.com/cer) 를 통해 소스코드도 공유하고 있으니 같이 보면 좋을 것 같습니다.MSA를 구현관점에서 고민한 흔적이 많이 보입니다. 각 서비스 별로 독립적인 WAS로 구동되어야 하기 때문에 JVM 기반이라면 Spring Boot 사용을 추천하고 있고,DB처리를 위해서는 JPA기술을 사용 하고 있는 것을 볼 수 있습니다.그리고 각 서비스가 사용하는 주소(IP, Port)는 주로 동적으로 할당 되기 때문에서비스를 등록 관리하기 위한 Service Discovery 패턴도 소개하고 있습니다.Spring Cloud의 Netflix OSS 중 유레카(Eureka)를 사용하면 쉽게 서비스를 관리 할 수 있습니다. 그리고 서비스 별로 다른 주소를 가지고 있기 때문에 클라이언트 입장에서 API를 호출하는 것이 쉽지 않습니다.그래서 단일 엔드포인트를 제공하기 위해 다음 그림과 같은 API Gateway 패턴도 사용합니다.WSO2 APIM이나 Netflix Zuul 등 오픈소스 API Gateway가 많이 있으니 잘 선택해서 사용 하면 될 것 같습니다.배포 관점에서는 도커를 활용해서 서비스를 컨테이너화 해서 쉽게 배포하는 것도 좋은 방법일 것 같습니다. 지금까지 MSA에 대해서 짧게 나마 알아봤습니다.사실 아키텍처라는 것이 개발자 입장에서는 크게 와 닿지 않는 분야지만 워낙 이슈가 되고 있는 개념이라 소개해봤습니다.개발자 관점에서 바라보면 마이크로 서비스는 SOLID 원칙과 많이 닮아있습니다.결국 적절한 책임에 따라 나누고 인터페이스(API)를 통해 서로 통신하라는 것입니다.이를 통해 변경에 적절히 대처 할 수 있는 것이고요. 크리스가 강의 중에 서비스를 나누기 위한 Boundary Context나데이터 관리를 위한 Eventually Consistent 등 강조한 개념이 많이 있는데,지면상 급하게 마무리 해버린 것 같아 아쉬움이 남네요.아래 링크를 통해 추가적인 내용을 보면 좋을 것 같습니다.(Microservices Reading List : http://www.mattstine.com/microservices)","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"6. Choosing a Microservices Deployment Strategy","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/6. Choosing a Microservices Deployment Strategy","date":"2017-01-27T06:44:36.000Z","updated":"2021-08-17T00:04:32.691Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/6. Choosing a Microservices Deployment Strategy/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/6.%20Choosing%20a%20Microservices%20Deployment%20Strategy/","excerpt":"","text":"Choosing a Microservices Deployment StrategyChoosing a Microservices Deployment Strategy에 대한 요약이다. Motivations모놀리틱 어플리케이션은 보통 큰 어플리케이션 하나를 여러개로 복사해서 실행한다.즉, N개의 서버에 각 서버마다 M개의 어플리케이션 인스턴스가 실행되는 것이다.모놀리틱 어플리케이션의 배포가 쉽다는 것은 아니다.하지만 마이크로서비스 어플리케이션의 배포에 비해서 단순하다. 마이크로서비스 어플리케이션은 수십, 수백개의 서비스들로 구성되어 있고,각 서비스 마다 다른 언어, 프레임워크를 사용 할 수 있다.각 서비스들은 자신만의 배포, 자원, 스케일링, 모니터링 등이 필요하다.예를 들면, 서비스는 수요에 따라서 여러 인스턴스를 실행 할 필요가 있고,각 서비스의 성격에 맞게 적절한 CPU, 메모리, I/O 자원 등이 할당 되어야 한다.마이크로 서비스의 배포는 이런 복잡성에도 불구하고, 빠르고 안정적이고, 비용 효율적이어야 한다. Multiple Service Instances per Host Pattern physical/vitual host 를 하나 이상 실행하고, 각 호스트 별로 여러 서비스를 실행하는 패턴이다.각 서비스 인스턴스는 호스트의 well-known port를 사용하여 실행된다. 이 패턴의 주요 장점은 Resource 사용이 상대적으로 효율적이다.여러 서비스 인스턴스가 서버 및 OS를 공유한다.Apache Tomcat이나 JVM 같은 프로세스를 공유하는 상황이라면 더욱 효율적일 것이다.또다른 장점으로 서비스 인스턴스를 배포하는 것이 상대적으로 빠르다.서비스를 호스트에 복사하고 실행하면 된다.Java라면 jar나 war 파일일 테고, Node.js 나 Ruby라면 소스코드를 복사하면 된다.이런 장점에도 불구하고, 이 패턴은 몇가지 주요한 단점이 있다.프로세스로 분리되어 있을 지라도, 서비스 인스턴스들을 격리(Isolation) 시킬 수 없다.각 인스턴스가 사용하는 리소스를 제한 할 수 없다. 특정 서비스가 호스트의 모든 CPU, Memory를 소비해 버릴 수도 있다.또다른 단점은, 운영팀이 각 서비스를 어떻게 배포해야 하는지 상세히 알고 있어야 한다.서비스는 다양한 언어와 프레임워크를 사용하고 있을 수 있고, 기타 수 많은 내용들이 운영 팀에게 모두 공유되어야만 한다.이런 복잡함이 배포 중 에러를 발생시킬 위험을 증가시킨다. Service Instance per Virtual Machine PatternVM 이미지(ex. Amazon EC2)마다 하나의 서비스가 패키징되는 패턴이다.각 서비스 인스턴스는 VM 이미지를 사용하여 실행된 하나의 VM 이다.Netflix에서 사용하는 주요 접근법이다. 서비스들은 Aminator를 통해 EC2로 패키징된다. 이 배포 패턴의 주요 장점은 각 서비스 인스턴스가 완벽하게 격리된 상태로 실행된다는 것이다.고정된 CPU, Memory를 할당 받고, 다른 서비스들의 자원에 영향을 주지 않는다.다른 장점은 Load Balancing, Auto Scaling 등 Cloud Infra를 잘 활용 할 수 있다.또한, 서비스의 구현기술을 캡슐화 할 수 있다. 서비스가 VM으로 패키징되면 블랙박스 처럼 된다.따라서 배포는 훨씬 더 간단하고 안정적으로 이뤄질 수 있다. 하지만, 자원을 사용하는 효율성이 떨어진다는 단점이 있다.모든 VM이 OS를 포함하는 오버헤드가 있고,전형적인 IaaS는 VM을 고정된 크기로 제공하기 때문에 충분히 활용되지 못할 가능성이 있다.IaaS에서 오토 스케일링을 제공하지만 수요의 변화에따라 빠르게 반응하기는 어렵다.(참조: http://techblog.netflix.com/2013/11/scryer-netflixs-predictive-auto-scaling.html)따라서 VM이 불필요하게 할당되고 배포 비용이 증가하게 된다.또다른 단점으로는 서비스의 새로운 버전이 배포되는 속도가 느리다는 것이다.VM 이미지는 size가 크기때문에 빌드되고 실행하는데 느리다.VM내의 OS가 실행되는 시간도 소요된다. Service Instance per Container Pattern각 서비스 인스턴스가 자신 만의 컨테이너(Container) 안에서 실행되는 패턴이다.컨테이너는 OP level의 가상화 기술로 샌드박스 안에서 실행되는 하나이상의 프로세스들로 구성된다.자신만의 port namespace, root filesystem 등을 가지고, 컨테이너 마다 CPU, Memory, I/O 등의 자원을 제한 할 수도 있다.컨테이너 이미지는 어플리케이션 및 서비스가 실행되는데 필요한 라이브러리로 구성된 파일시스템이다.Docker, Solaris Zones 등의 기술이 있다. 서비스가 컨테이너 이미지로 패키징되면, 여러 컨테이너로 실행 시킬 수 있다.보통 한 호스트에 여러 컨테이너가 실행되고, Kubernetes 등의 클러스터 매니져를 사용할 수 있다. 이 패턴의 장점은 VM을 사용할 때와 비슷하다.서비스 인스턴스를 격리된 상태로 실행 할 수 있고, 다른 컨테이너가 사용하는 자원을 쉽게 모니터링 할 수 있다.컨테이너를 통해 서비스의 구현기술을 캡슐화 할 수 도 있다.하지만 컨테이너는 VM에 비해서 경량화된 기술이다.컨테이너 이미지는 매우 빠르게 빌드되고, OS 부팅이 없기 때문에 빠르게 실행된다.즉, 컨테이너가 실행된다는 것은 서비스가 실행된다는 의미이다. 컨테이너를 사용하는 것의 단점은 컨테이너 기술의 발전 속도가 매우 빠르긴 하지만 VM 인프라 정도는 아니다는 것이다.컨테이너는 호스트 OS의 커널을 다른 컨테이너와 공유하기 때문에 VM에 비해 안전하지 않다.또한, 수 많은 컨테이너 이미지를 관리해야 되는 책임을 갖을 뿐만 아니라, 컨테이너가 실행되는 VM 인프라 또한 관리해야 된다.일반적으로 컨테이너가 배포되는 클라우드 인프라는 VM당 가격이 책정되기 때문에로드가 급증하는 경우 과도하게 프로비져닝되어 추가 비용이 발생할 수도 있다. Serverless DeploymentAWS Lambda는 서버리스 배포 기술의 한 예다. Java, Node.js, C#, Python 서비스를 지원한다.마이크로서비스를 Zip 파일로 패키징해서 메타데이터와 함꼐 AWS Lambda로 업로드 하면된다.AWS Lambda는 요청을 처리하기 위해 충분한 인스턴스가 자동으로 실행되고 시간이나 메모리 사용량 등에 따라 요금을 지불한다.AWS Lambda는 여러 제약사항이 있지만, 서버나 VM, 컨테이너 등을 신경쓰지 않아도 되기 때문에 매력적이다.Lambda Function은 Stateless 한 서비스이고, 주로 AWS 서비스를 실행하면서 요청을 처리한다.예를 들어 이미지가 S3에 업로드 됐을 때, DynamoDB에 아이템을 저장하고, 이미지 처리를 위해 Kinesis 스트림에 메시지를 퍼블리싱한다.물론 외부 웹서비스를 실행 할 수도 있다. 12345Lambda function 이 실행되는 경우1. 웹서비스를 통해 직접 요청하여 실행 2. AWS 서비스들로 부터 생성된 이벤트에 의해 자동 실행 3. 어플리케이션의 HTTP요청을 처리하기위해 AWS API Gateway에서 자동 실행 4. 일정에 따라 주기적으로 실행 AWS Lambda는 마이크로서비스를 배포하기 편리한 방법이다.실제로 사용한 만큼만 비용이 발생하며, IT 인프라에 대한 고민 없이 어플리케이션 개발에만 집중하면 된다.하지만 몇가지 주요한 제약사항이 있다.오래 실행되는 서비스를 배포하는 데에는 맞지 않다. 요청은 300초 이내로 끝나야 한다.요청이 있을때마다 별도의 인스턴스가 실행되기 때문에 서비스는 Stateless 해야된다.지원되는 언어도 제약이 있을 뿐만 아니라, Time out되어 종료될 수 도 있기 때문에 서비스는 빠르게 시작되어야 한다. Summary마이크로서비스를 배포하는데는 많은 어려움이 있다.다양한 언어와 프레임워크로 작성된 수십 수백개의 서비스들이 존재한다.각 서비스들은 자신만의 배포환경, 자원, 스케일링, 모니터링 등이 요구된다.서비스를 배포하는 방법으로는 VM당 서비스 하나씩 배포하는 방법,컨테이너당 서비스 하니씩 배포하는 방법, AWS Lambda를 활용하여 서버리스하게 배포하는 방법 등이 있다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"5. Event-Driven Data Management for Microservices","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/5. Event-Driven Data Management for Microservices","date":"2017-01-27T06:44:35.000Z","updated":"2021-08-17T00:04:32.691Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/5. Event-Driven Data Management for Microservices/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/5.%20Event-Driven%20Data%20Management%20for%20Microservices/","excerpt":"","text":"Event-Driven Data Management for MicroservicesEvent-Driven Data Management for Microservices에 대한 요약이다. Microservices and the Problem of Distributed Data Management모놀리틱(monolithic) 어플리케이션은 전형적으로 단일 관계형 데이터베이스를 사용한다.RDB 의 가장 큰 장점 중 하나는 ACID 트랜젝션 을 지원한다는 것이다. 원자성(Atomicity) : Changes are made atomically 일관성(Consistency) : The state of the database is always consistent 격리성(Isolation) : Even though transactions are executed concurrently it appears they are executed serially 지속성(Durable) : Once a transaction has committed it is not undone 또 다른 장점 중 하나는 SQL 을 지원하는 것 이다.여러 테이블을 쉽게 JOIN 할 수 있고, 쿼리를 최적화된 방법으로 실행해 준다.따라서 내부적으로 어떻게 데이터베이스에 접속하고 처리하는지에 대해 자세히 몰라도 된다. 하지만, 마이크로서비스 아키텍쳐는 데이타에 접근하는 것이 더욱 복잡해 진다.각 마이크로서비스 마다 자신의 데이터를 소유하고 다른 서비스에서는 API를 통해서 접근할 수 있다.(참고: Pattern: Database per service)이렇게 데이타를 캡슐화하면 서비스들 간의 결합도를 줄이게 되고(loosely coupled), 다른 서비스들과 독립적으로 수정가능하다.여러서비스가 같은 데이터를 접근한다면, 스키마(schema)를 수정하고관련된 모든 서비스들을 수정해야 되기 때문에 많은 시간이 소요된다. 각 마이크로서비스들은 상황에 따라 다른 데이터베이스를 사용하곤한다. 요즘 어플리케이션이 저장하고 처리하는 데이터의 종류가 다양해졌기 때문에,RDB가 항상 최선의 선택인 것은 아니다.예를 들면, NoSQL database 의 경우 유연한 데이터모델을 가지고 성능이나 확장성(scalability)면에서 더 나을 것이다.예: 텍스트 서치의 경우 Elasticsearch, social graph data의 경우 Neo4j같은 그래프 데이터베이스마이크로서비스 기반의 어플리케이션은 SQL, NoSQL 데이터베이스를 섞어서 사용하는 경우도 있다.(참고: polyglot persistence)polyglot persistence 아키텍쳐는 loosely coupled 한 서비스를 만들고 성능 및 확장성 등 많은 장점들을 갖는 반면분산된 데이터 관리에 대한 어려움이 있다. 여러 서비스간 데이터 일관성(Consistency) 은 어떻게 구현 할 것인가?고객 서비스와 주문 서비스가 있는 경우 monolithic 에서는 ACID 트랜젝션으로 묶어 처리할 수 있지만,MSA 에서는 테이블을 직접 참조하지 못하고 API를 통해서만 접근이 가능할 것이다.이를 위해 2PC라고 알려진 분산 트랜젝션(Distributed Transaction)을 사용 할 수 있을 것이다.하지만 일반적으로 최근 어플리케이션에서는 2PC가 사용되지 않는다.CAP 이론은 가용성(Availability)과 ACID 스타일의 일관성 사이에서 선택을 요구한다.NoSQL DB의 대부분은 2PC를 지원하지 않고 가용성을 더 중요하게 생각한다. 여러 서비스로 부터 데이터 조회 하는 쿼리는 어떻게 구현 할 것인가?고객 정보와 고객의 최근 구매이력을 조회하려고 할 때, 고객 서비스와 주문 서비스의API를 사용하여 application-side join을 할 수 있을 것이다.하지만 만약, 주문 이력이 NoSQL에 저장되어 있고, PK로만 조회가 가능하다면 필요한 정보를 어떻게 받아야 할까? Event-Driven Architecture이런 문제를 해결하기 위해 많은 어플리케이션에서 Event-Driven Architecture가 사용한다.서비스들은 비지니스 엔티티가 변경되는 등의 주요 작업이 발생한 경우, 이벤트를 발행(publish)한다.다른 서비스에서 이 이벤트에 관심이 있는 경우 구독(subscribe) 하여 다음 작업을 처리하면 된다.이런 이벤트를 통해 여러 서비스간 비지니스 트랜젝션을 구현 할 수 있다.서비스에서 이벤트를 받아 다음 스텝의 작업을 처리하고 다시 이벤트를 발행하면서 처리해 나갈 수 있다. The Order Service creates an Order with status NEW and publishes an Order Created event. The Customer Service consumes the Order Created event, reserves credit for the order, and publishes a Credit Reserved event. The Order Service consumes the Credit Reserved event, and changes the status of the order to OPEN. 각 서비스들은 원자적(atomically)으로 데이터베이스를 업데이트하고, 이벤트를 발행한다.Message Broker가 각 이벤트들이 최소 한번은 전달됨을 보장해 줌으로써,이를 통해 여러 서비스간 비지니스 트랜젝션을 구현한다.이는 ACID 트랜젝션은 아니지만 Eventual Consistency 를 제공 할 수 있다.또한 이벤트를 이용하여 pre-join된 view를 제공 할 수 있다.예를 들어, 고객 서비스와 주문 서비스가 발행하는 이벤트를 구독하여 Customer Order View Query 서비스를 만들 수도 있다. Event-Driven Architecture는 몇가지 장단점이 있다.여러 서비스간 사용되는 트랜젝션을 구현 할 수 있고, Eventual Consistency를 제공해 준다.그리고 pre-join된 View를 생성하여 제공 할 수도 있다.반면, ACID 트랜젝션을 사용하는 것에 비해 구현하기 더 복잡하다.오류가 발생한 경우 어플리케이션 레벨에서 취소하는 보상 트랜젝션을 구현해야 한다.또한, View를 사용하는 경우 아직 반영되지 않은 데이터에 대해서 불일치하는 문제가 발행 할 수도 있고,중복된 이벤트를 검출해 내고 이를 무시하는 기능도 구현해야된다. Achieving AtomicityEvent-Driven Architecture에서 데이터베이스를 업데이트하고, 이벤트를 발행하는 작업이 반드시 원자적으로 이루어져야 하는 문제가 있다.만약 데이터베이스를 업데이트하고 이벤트를 발행하기 전에 문제가 생겼다면 시스템은 불일치하게 된다. Publishing Events Using Local Transactions메세지 큐와 같은 기능을 하는 EVENT 테이블을 비지니스 엔티티 테이블과 같은 데이터베이스에 만든다.비지니스 엔티티를 수정하고, 이벤트를 EVENT 테이블에 insert하는 기능을 한 로컬 트랜젝션으로 수행한다.이런 방법은 2PC없이 이벤트가 발행되는 것을 보장해 주는 장점이 있는 반면,개발자가 이벤트 발행하는 것을 잊어버리는 등의 잠재적인 위험이 있다. Mining a Database Transaction Log데이터베이스의 Transaction/commit log를 수집하여 이벤트를 발행하는 방법이 있다.관련 기술로는 LinkedIn Databus, AWS DynamoDB streams mechanism 등이 있다.2PC 없이 이벤트 발행을 보장해주고 비지니스 로직과 이벤트 발행 기능을 분리할 수 있다는 장점이 있다.반면, 데이터베이스마다 로그의 포멧이 다르고, 버전 사이에도 차이가 있을 수있다.또한 low-level 로그를 통해 high-level 비지니스 이벤트를 생성해 내야하는 어려움이 있다. Using Event SourcingEvent Sourcing 은 엔티티의 현재상태를 저장하는 대신, 상태를 변경하는 이벤트를 순서대로 저장하는 방법이다.어플리케이션은 이벤트들을 replay 하면서 현재상태를 재구성한다.이벤트들은 Event Store 라는 데이터베이스에 저장된다.Event Store는 Message Broker와 같은 역할도 동시에 수행한다. Event Sourcing 방법을 사용하면 여러 장점이 있다.상태가 변경될 때마다 이벤트가 발생되는 것을 보장해야 하는 Event-Driven Architecture의 문제를 해결 함으로써MSA의 데이터 일관성 문제를 해결 할 수 있다.또한 이벤트를 저장하기 때문에 객체와 관계형 DB의 불일치 문제를 피할 수도 있다.뿐만아니라 특정 시점의 엔티티의 상태를 조회할 수 있다. Event Sourcing의 단점으로는익숙하지 않은 프로그래밍 스타일이고 학습하는데 시간이 걸린다.Event Store는 PK를 통해서만 엔티티를 조회 할 수 있기 때문에 CQRS를 반드시 적용해야 하고, eventually consistent data를 다뤄야 한다. Summary마이크로서비스 아키텍쳐에서 각 서비스틀은 자신만의 고유한 데이터베이스를 가진다.이런 아키텍쳐는 여러 장점을 가지는 반면에 분산된 데이터를 관리해야 하는 어려움이 있다.서비스간 일관성을 유지하기 위한 트랜젝션을 구현해야 되고, 여러서비스에서 데이터를 조회해야 하는 어려움이 있다. 이를 위해 많은 어플리케이션에서 Event-Driven Architecture 를 사용하고 있다.하지만 엔티티의 상태를 업데이트하고 이벤트를 발행하는 것을 atomically 하게 구현해야 하는 어려움이 있다.이를 해결하기 위해 데이터베이스를 메시지 큐로 사용하는 방법,데이터베이스의 트랜젝션 로그를 수집하는 방법, Event Sourcing을 사용하는 방법 등이 있다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"},{"name":"Event-Driven","slug":"Event-Driven","permalink":"https://kihoonkim.github.io/tags/Event-Driven/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"4. Service Discovery in a Microservices Architecture","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/4. Service Discovery in a MSA","date":"2017-01-27T06:44:34.000Z","updated":"2021-08-17T00:04:32.690Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/4. Service Discovery in a MSA/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/4.%20Service%20Discovery%20in%20a%20MSA/","excerpt":"","text":"Service Discovery in a Microservices ArchitectureService Discovery in a Microservices Architecture에 대한 요약이다. Service DiscoveryREST API, Thrift API등을 가진 서비스를 호출하려고 할때 네트워크 주소(IP, Port)를 알고 있어야 한다.기존 방식에서는 일반적으로 물리적 하드웨어 주소는 고정(static)적 이고 가끔 변경된 경우 설정파일을 수정해주면 됐다.요즘처럼 클라우드 기반의 MSA 어플리케이션인 경우에 네트워크 주소가 동적(dynamic)으로 할당된다.따라서 클라이언트가 서비스를 호출하기위해서 서비스를 찾는 매커니즘(service discovery mechanism)이 필요하다.Client-Side/Server-Side Discovery Pattern 두가지 패턴을 살펴보자. The Client-Side Discovery Pattern 사용가능한 서비스의 네트워크 주소를 찾고 로드밸런싱된 요청을 보내는 일이 클라이언트에서 이뤄진다.즉, 클라이언트가 service registry에 질의를 해서 네트워크 주소를 얻고,로드밸런싱 알고리즘을 통해 서비스를 선택 후 요청(request)을 생성한다.서비스가 실행될 때 Service Registry에 자신의 네트워크 주소를 등록하고, 종료될 때 Service Registry에서 삭제한다. Netflix OSS가 client-side discovery pattern의 대표적인 사례이다. Netflix Eureka: service registry Netflix Ribbon: Eureka와 함께 동작하여 로드밸런싱된 요청(requests)을 생성 Client-Side Discovery Pattern 장점 비교적 간단하다. 클라이언트가 사용가능한 서비스를 알고 있기 때문에서비스별로 알맞은 로드밸런싱 방법을 선택할 수 있다. Client-Side Discovery Pattern 단점 클라이언트와 service registry간 의존성이 생긴다. 클라이언트에서 service를 찾는(discovery)하는 로직을 구현해야 된다. The Server-Side Discovery Pattern클라이언트는 로드밸런서를 통해 서비스에 요청을 보낸다.로드밸런서는 service registry에 서비스의 네트워크 주소를 질의한 뒤, 사용가능한 서비스로 각 요청을 라우팅한다.Client-Side Discovery와 동일하게 각 서비스는 Service Registry에 등록되고 해제된다. AWS Elastic Load Balancer(ELB)가 Server-Side Discovery 라우터의 예이다.ELB는 일반적으로 인터넷에서 들어오는 외부 트래픽을 로드밸런싱하는데 사용된다.클라이언트는 DNS 이름을 사용하여 ELB를 통해 요청을 보낸다.등록되어 있는 EC2 인스턴스나 ECS 컨테이너들이 사이에서 트래픽을 로드밸런싱한다.별도의 Service Registry가 있는 것은 아니고 EC2나 ECS가 ELB에 직접 등록한다. Kubernetes나 Marathon과 같은 배포환경은 클러스터내의 각 호스트에서 프록시(proxy)를 실행한다. 이 프록시는 Server-Side Discovery 로드밸런서 역할을 수행한다. 클라이언트는 서비스에 요청을 보내기위해서, IP나 port정보를 사용한다. 프록시는 클러스터내의 사용가능한 서비스 인스턴스로 해당 요청을 포워딩한다. Server-Side Discovery Pattern 장점 discovery 관련된 세부내용을 클라이언트로 부터 분리할 수 있다. 클라이언트는 discovery관련 로직을 구현 할 필요가 없다. 앞서 언급한 몇몇 배포환경에서는 이 기능을 무료로 제공한다. Server-Side Discovery Pattern 단점 로드밸런서는 배포환경에 구축되어야 한다. 즉, 높은 가용성이 요구되는 시스템 컴포넌트를 설정하고 관리해야한다. The Service Registryservice registry는 service discovery에서 매우 중요한 부분으로,서비스 인스턴스들의 네트워크 주소를 가지고 있는 데이터베이스이다.높은 가용성이 보장되어야 하고 항상 최신정보를 유지해야한다. Netflix Eureka REST API를 통해 서비스 인스턴스를 등록하거나 조회할 수 있다. POST 방식으로 서비스 인스턴스의 네트워크 주소를 등록 PUT 방식으로주기적으로(30초) 등록정보를 리프레쉬 DELETE 방식으로 서비스 인스턴스 등록정보를 삭제 GET 방식으로 등록된 서비스 인스턴스 정보를 조회 참고: Configuring Eureka in AWS Cloud etcd 고가용성, 분산된, 일관성있는 key-value 저장소 설정을 공유하고, service discover를 위해 사용된다. Kubernetes와 Cloud Foundry에서 사용 중 consul 서비스들을 발견discover하고 설정(configure)하기 위한 툴 서비스를 등록하고 찾기위한 API를 제공 health check를 통해 서비스 가용여부를 판별한다. Apache Zookeeper 분산된 어플리케이션을 위해 널리사용되는 고사양 코디네이션(coordination) 서비스 Service Registration Options서비스 인스턴스들은 service registry에 등록되거나 해제되어야 한다.서비스의 등록/해제를 다루는 두가지 방식이 있다. The Self-Registration Pattern서비스 인스턴스는 service registry에 스스로 등록/해제할 책임이 있다.필요하다면 등록정보가 만료되지 않게 하기위해 heartbeat를 service registry에 보내야한다.Netflix OSS Eureka client Eureka client는 Eureka(service registry)에 서비스 등록/해제를 자동으로 처리한다. 서비스의 Java Configuration 클래스에 @EnableEurekaClient 어노테이션만 달아주면 된다. Self-Registration 장점 비교적 단순하다. 별도의 시스템 컴포넌트가 추가될 필요가 없다. Self-Registration 단점 서비스 인스턴스와 Service Registry간의 높은 결합도(coupling)이 생긴다. 서비스에서 등록/해제 관련된 코드를 구현해야된다. The Third-Party Registration Pattern서비스 인스턴스가 직접 service registry에 등록/해제에 대한 책임이 없다.대신, 서비스 등록기(service registrar)가 service registry에 등록을 해준다.서비스 등록기는 실행중인 서비스 인스턴스들에 polling을 하거나 이벤트를 구독하는 등의작업을 통해서 서비스의 변경을 감지하고, service registry에 등록/해제를 한다. Registrator Docker 컨테이너로 배포된 서비스 인스턴스들을 자동으로 등록/해제 하는 오픈소스 프로젝트 etcd 나 Consul 같은 다양한 service registry를 지원한다. NetflixOSS Prana non-JVM 언어로 작성된 서비스를 위해 같이 실행시켜서 Eureka에 등록/해제를 한다.(sidecar application) Third-Party Registration 장점 서비스 인스턴스와 service registry가의 결합도를 끊을(decoupled) 수 있다. 서비스에 별도의 등록/해제 로직을 구현할 필요가 없다. Third-Party Registration 단점 운영환경에 추가적인 시스템 컴포넌트가 필요하다. 이 시스템은 설치 및 관리되어야 하고, 고가용성을 유지해야 한다. Summary마이크로서비스 어플리케이션은 서비스 인스턴스가 동적으로 변경되고 네트워크 주소도 동적으로 할당된다.따라서 클라이언트에서 서비스에 요청을 보내려면 service discovery 메카니즘이 필요하다. service discovery에서 매우 중요한 부분이 service registry이다.service registry는 사용가능한 서비스 인스턴스의 목록을 관리하고,서비스 등록/해제/조회 등을 할 수 있는 API를 제공해야 한다. service-discovery 패턴에는 client-side와 server-side discovery 패턴이 있다. service registry에 등록/해제 하는 방법에는 self-registration과 third-party registration 패턴이 있다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"},{"name":"service discovery","slug":"service-discovery","permalink":"https://kihoonkim.github.io/tags/service-discovery/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"3. Inter-Process Communication in a Microservices Architecture","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/3. Inter-Process Communication in a MSA","date":"2017-01-27T06:44:32.000Z","updated":"2021-08-17T00:04:32.690Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/3. Inter-Process Communication in a MSA/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/3.%20Inter-Process%20Communication%20in%20a%20MSA/","excerpt":"","text":"Building Microservices: Inter-Process Communication in a Microservices ArchitectureInter-Process Communication in a Microservices Architecture에 대한 요약이다. Monolithic 어플리케이션에서는 언어레벨의 메소드나 함수를 호출 함으로써 다른 컴포넌트를 실행 할 수 있었다. MSA기반 어플리케이션은 분산환경에서 개별 프로세스로 동작하기 때문에, inter-process communication (IPC) mechanism이 필요하다. Design시 고려사항Interaction Styles각 서비스들은 아래의 통신 스타일을 조합해서 사용하게 된다. One-to-One One-to-Many Synchronous Request/response — Asynchronous Notification Publish/subscribe Request/async response Publish/async responses Synchronous : 요청에대한 적절한 응답을 기대하고, 그때까지 기다리며 block. Asynchronous: 응답을 기다리며 block하지 않음. One-to-one: 각 요청이 한 서비스에서 실행됨 Request/response : 서비스에 요청을 하고, 응답을 기다린다.적당한 시간 내에 응답이 올것을 기대하며, block 된 상태로 기다린다. Notification(one-way request): 서비스에 요청을 보내고, 응답을 받지 않는다. Request/async response: 서비스에 요청을 보내고, 비동기로 응답을 받는다. One-to-many: 각 요청이 여러 서비스에서 실행됨 Publish/subscribe: 메시지를 발행(publish)하면, 관심있는 서비스들이 이를 소비(consume)한다. Publish/async responses: 메시지를 publish하고, 이를 소비하는 서비스로 부터 응답을 기다린다. Defining APIsAPI는 서비스와 이를 사용하는 클라이언트 간의 일종의 계약(contract)이다.그렇기 때문에 API를 상세하게 정의하는 것이 중요하다. (참고 : API-first Approach)어떤 IPC 메카니즘을 사용하느냐에 따라 API를 정의하는 것이 달라질 것이다. messaging : message channels, message types HTTP : URLs, request/response formats Evolving APIs서비스의 API는 시간이 지남에 따라 변경된다.모놀리틱 어플리케이션에서는 API를 변경하고, 이를 호출하는 부분을 수정하면 간단히 해결된다.하지만, MSA기반 어플리케이션에서는 매우 어렵기 때문에 전략적인 접근이 필요하다.어떻게 API 변경에 대처할 지는, 변경의 크기에 따라 다르다. 속성이 추가되는 것과 같이 변경이 작고 사소한 것이라면,기본값을 주거나 새로운 속성을 무시하게 함로써 쉽게 변경 할 수 있다. major하고 큰 변경이라면, 클라이언트에게 즉시 변경하도록 강요 할 수 없기 때문에서비스는 일정기간동안 두 버전의 API를 지원해야 한다. 참조 : Deploying the Netflix API Handling Partial Failure분산 시스템에서는 partial failure 위험이 항상 존재한다.장애가 났거나, 유지보수상 이유로, 혹은 시스템 부하로 인해 응답속도가 너무 느린경우 발생 할 수 있다.응답을 무한정 기다리며 block상태에 있다면, 사용자에게 안좋은 UX를 제공할 뿐만 아니라,block상태인 thread가 늘어나면서 결국 해당 서비스도 장애가 발생 할 수 있다. Network timeouts Limiting the number of outstanding requests Circuit breaker pattern Provide fallbacks: cached data, default value 참조 :Fault Tolerance in a High Volume, Distributed SystemNetflix Hystrix IPC TechnologiesAsynchronous, Message-Based Communication 메시지(Message) 기반 통신은 메시지를 비동기 로 주고 받는 것이다. 만약 응답을 받기 원한다면 별도의 메시지를 보내야 한다. 비동기로 통신하기 때문에 응답을 받기위해 block상태로 기다리지 않는다. 메시지는 헤더(header) 와 바디(message body) 로 구성된다. 메시지는 채널(Channel) 을 통해 주고받는다. point‑to‑point 채널: 한 consumer에게 메시지를 전달. 1:1로 직접 통신시 사용 publish‑subscribe 채널: 여러 consumer에게 메시지를 전달. 1:N 통신시 사용 표준 프로토콜: AMQP, STOMP 오픈소스: RabbitMQ, Apache Kafka, Apache ActiveMQ, NSQ 메지징 사용의 장점 서비스와 클라이언트간 의존성을 줄임. 서비스의 위치를 몰라도 됨. 메시지 버퍼링. consumer에의해 메시지가 소비될때까지 큐에 보관함. 1:1, 1:N 등 모든 통신 스타일을 지원함 메지징 사용의 단점 운영복잡도 증가: 메시징 시스템도 설치하고, 설정하고, 운영해야되는 시스템이다. request/response기반 통신 구현시 복잡함. 응답을 받기위해 추가작업 필요.(correlation ID) Synchronous, Request/Response IPC Request/Response 기반 통신은 클라이언트에서 서비스로 요청을 동기 로 보내는 것이다. 응답을 받기위해 클라이언트의 thread는 block상태로 기다린다. client code에 Futures, Rx.. 를 사용하여 asynchronous, event-driven하게 처리할 수도 있다. REST RESTful스타일의 API 개발 방법 HTTP를 사용하는 IPC 메카니즘 비지니스 객체(object)같은 자원(resources)을 표현(represent)하는 것이 주요 컨셉이다. GET, POST, PUT, DELETE..같은 HTTP 용어와 URL을 사용하여 자원을 조작한다. HTTP-based API가 RESTful 한 것은 아니다. (참고: REST 성숙도 모델) RAML이나 Swagger를 사용하여 RESTful API를 디자인 할 수 있다. 장점 : HTTP 는 단순하고 친숙하다. HTTP API는 browser나 curl을 사용하여 테스트하기 쉽다. request/response 스타일 통신을 지원한다. HTTP는 방화벽에 친화적이다. 메시지 브로커 같은 중간 매개체가 필요없어 시스템 아키텍쳐가 단순하다. 단점 : request/response 스타일 통신만 지원한다.notification(one-way)을 HTTP로 구현하더라도 응답을 받아야한다. 클라이언트와 서비스가 직접 통신하기 때문에 반드시 둘 다 동작 중이어야 한다. 클라이언트는 서비스들의 위치를 알고있어야 한다. Thrift 다른 언어로 개발된 서비스들간 RPC통신을 위한 프레임워크 클라이언트의 stub코드와 서비스의 skeleton코드를 생성(generate)해준다. request/response 스타일 통신과 one-way 스타일의 통신 모두 가능하다. C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml, Delphi… JSON, binary, compact binary 등의 메시지 포멧을 지원. TCP, HTTP 프로토콜 지원. Message Formats서비스들이 여러 언어로 개발되어 있는 경우, 통신시 사용할 메시지 포멧을 결정하는 것이 중요하다. 텍스트 기반 포멧(text-based format) JSON: 키(name)와 값(value)의 쌍으로 속성을 표현. XML Schema XML: 요소(element)와 값(value)으로 속성을 표현. JSON Schema 장점 : 사람이 이해하기 쉽고, 그 자체로 설명가능(self-describing) 하다. 관심있는 값만 보고 나머지는 무시한다. 속성 변경에 대처하기 쉽다. 단점 : 메시지가 너무 크고 정보가 많다. 특히 XML.. 텍스트 파싱(parsing)에 대한 오버해드가 있다. 바이너리 포멧(binary format) Thrift RPC Apache Avro: schema Protocol Buffers: tagged fields 참고: Thrift vs Protocol Buffers vs Avro - Biased Comparison 결론Microservices는 IPC 메카니즘을 사용하여 통신해야 한다.설계시 고려할 사항으로는 서비스간 어떻게 통신할지, API를 어떻게 정의할지,API 변경에 어떻게 대응할지, 부분장애(partial failure)에 어떻게 대응할지등이 있다.IPC 메카니즘으로는 메시지기반의 비동기 방식과 request/response기반의 동기 방식이 있다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"},{"name":"IPC","slug":"IPC","permalink":"https://kihoonkim.github.io/tags/IPC/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"2. Using an API Gateway","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/2. Using an API Gateway","date":"2017-01-27T06:44:31.000Z","updated":"2021-08-17T00:04:32.690Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/2. Using an API Gateway/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/2.%20Using%20an%20API%20Gateway/","excerpt":"","text":"Building Microservices: Using an API GatewayUsing an API Gateway에 대한 요약이다. Client와 Microservices 간에 어떻게 통신을 할 것인가? 모놀리틱(monolithic) 어플리케이션은 엔드포인트가 하나만 존재하는 반면에,MSA 어플리케이션은 서비스마다 다른 엔드포인트를 갖는한다. API Gateway를 사용하여 client-application간 통신 문제를 해결해보자. Introduction모놀로틱 어플리케이션이었으면 한번의 Rest 호출(~/productdetails/{productId})로 모든 정보를 받아왔을 것이다.하지만, MSA라면 여러 서비스로부터 각 정보를 받아와야 한다. Client와 Microservice간 직접(direct) 통신각 서비스가 public 엔드포인트를 가지고 있다면, client에서 직접 서비스들을 호출할 수 있다.하지만, 다음과 같이 많은 문제가 있어, 직접 통신하는 경우는 매우 드물다. 직접 통신의 문제점 클라이언트가 원하는 정보를 얻기 위해 각 서비스의 잘게 나눠놓은(fine-grained) API들을 너무 많이 호출하게 될 수도 있다. 이런 요청이 LAN이 아닌 공공 internet을 통하기 때문에 비효율 적이고, 특히 모바일 네트워크는 더욱 심하다. 클라이언트 코드가 매우 복잡해 질 것이다. HTTP 프로토콜을 사용하지 않는 서비스가 있는 경우 클라이언트가 직접 통신하기 어렵다.(Thrift, AMQP..) 서비스를 여러개로 나누거나, 혹은 합치거나 하는 등.. 필요에 의해 변경해야 할 경우 반영하기 힘들다. API Gateway 사용하여 통신 API Gateway는 단일 엔트리포인트를 제공하는 서버이다. OOP의 Facade Pattern과 유사하다. 각 클라이언트에 적절한 API를 노출시키고, 내부 시스템 아키텍쳐는 숨길 수 있다. API Gateway가 할 수 있는 일 request routing: 모든 요청은 API Gateway를 통해서 들어와 적절한 서비스로 라우팅된다. 클라이언트 별로 알맞게 변경한 API를 제공할 수 있다. 여러 서비스를 호출해서 클라이언트별로 필요한 항목만 조합해서 API를 만들 수 있다. composition: 여러 서비스를 호출하고 결과를 모아(aggregate) 한번에 전달 할 수도 있다. protocol translation: 다른 프로토콜을 사용하는 경우 Web 프로토콜(HTTP, WebSocket..)로 변환해서 보낼 수 있다. 이외에도.. Message Exchange Pattern, 인증, 모니터링, 로드밸런싱, 캐싱, QoS, Metering 등 여러가지 일을 할 수 있다. 장점: single entry point 내부 구조를 숨길(encapsulate) 수 있다. client와 어플리케이션간 통신을 줄 일수 있다. 클라이언트 코드가 단순해 진다. 단점: highly available component API Gateway 역시 개발,배포,관리 되어야하고 매우 높은 수준의 가용성을 보장해야하는 컴포넌트이다. 각 서비스의 API를 외부로 노출하기 위해서 반드시 API Gateway를 update해야 된다. 이는 개발의 병목이 될 수 도 있다. API Gateway 구현(혹은 설계 이슈)구현시 고려해야하는 여러 설계 이슈를 알아보자. Performance and Scalability asynchronous, non-blocking I/O 를 지원해야 한다. JVM NIO-based frameworks: Netty, Vertx, Spring Reactor, JBoss Undertow non-JVM: Node.js Reactive Programming Model여러 요청을 서비스로 라우팅하거나, 그 결과를 조합해야 하는 경우에 응답시간을 최소화 하기위해서 동시에 독립적으로 수행할 수 있어야 한다.API Gateway를 asynchronous하고, reactive하게 구현하는 것이 좋다. Future in Scala CompletableFuture in Java 8 Promise in JavaScript RxJava, RxJS… Service InvocationMSA는 분산 환경이기 때문에 다양한 내부 프로세스간 통신 메카니즘이 필요하다. asynchronous, messaging-based mechanism: JMS, AMQP, Zeromq.. synchronous mechanism: HTTP, Thrift Service Discovery API Gateway는 각 서비스의 위치(IP, Port)를 알고 있어야한다. Message Broker나 Database와 같은 인프라 서비스는 고정(static) 위치를 가지고 있지만,어플리케이션 서비스는 주로 동적(dynamic) 위치를 할당 받고 scale in/out 되는 경우 자주 변경될 수 있다. 따라서 service discovery 메카니즘이 필요하다. 각 서비스 인스턴스의 위치는 Service Registry에 등록되어 있어야 하고,API Gateway는 서비스의 위치를 조회하여 라우팅한다. Handling Partial Failures분산 환경에서 서비스가 다른 서비스를 호출하는 경우, 응답이 느리거나 안올 수 있다. 이런 경우에 API Gateway는 해당 서비스를 계속 기다리며 block되서는 안된다. 특정 서비스에 장애가 있는 경우, 미리 지정된 시나리오에 따라 처리될 수 있어야 한다. 장애난 서비스의 결과는 비워두고 남은 서비스의 데이터가 사용자에게 의미있다면 그것 만이라도 결과를 응답해야 한다. 사용자에게 의미있거나 꼭 필요한 서비스가 장애난 경우에는 error를 리턴해야 된다. 자주 변경되지 않는 데이터의 경우, 정상적인 상황에 리턴했던 결과가 cache에 있다면 그것을 리턴할 수도 있다. Netflix Hystrix: circuit breaker, default value 리턴 등 가능.. 결론 MSA기반의 어플리케이션에서 API Gateway를 사용하는 것은 single entry point를 제공한다는 측면에서 의미가있다. 요청에 대한 라우팅, 조합, 프로토콜 변환 등의 작업을 하거나 클라이언트별로 custom API를 제공할 수도 있다. API Gateway를 통해 캐싱된 값이나 기본값을 리턴하는 등, 장애에 대응 할 수 있다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"},{"name":"api gatewary","slug":"api-gatewary","permalink":"https://kihoonkim.github.io/tags/api-gatewary/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"1. Introduction to Microservices","slug":"Microservices Architecture/Chris Richardson-NGINX Blog Summary/1. Introduction to Microservices","date":"2017-01-27T06:44:30.000Z","updated":"2021-08-17T00:04:32.689Z","comments":true,"path":"2017/01/27/Microservices Architecture/Chris Richardson-NGINX Blog Summary/1. Introduction to Microservices/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/Microservices%20Architecture/Chris%20Richardson-NGINX%20Blog%20Summary/1.%20Introduction%20to%20Microservices/","excerpt":"","text":"Introduction to MicroservicesIntroduction to Microservices에 대한 요약이다. Monolithic architecture hexagonal architecture 논리적으로 모듈화되고 패키지된 아키텍쳐를 갖더라도, 배포는 모놀리틱하게 되는 경우가 많다. 프로그래밍언어나 프래임워크에 의해 배포 형식이 결정된다. 장점 : 개발, 관리, 테스트, 배포가 쉽다. 같은 표준, 스타일의 개발 방법 같은 개발(언어, IDE, tools..), 배포(WAR, Tomcat, Server..) 환경 end-to-end 테스트가 쉽다. 이슈해결이 쉽다. 배포는 패키징된 소스를 서버에 복사해 넣으면 된다. 단점 : 시간이 지나면서, 어플리케이션은 크고 복잡해진다. 어플리케이션이 소스양도 많고, 기능도 많고, 너무 복잡해진다. 한 개발자가 이해해야되는 범위가 너무 크다. 타 업무간 소스 직접 참조, DB Join등.. dependency가 높아진다. 일부만 수정하려고 할때 혹은 버그를 수정하려고 할때,소스는 이해하기 어렵고, 새로운 기능을 어디에 넣어야 할지도 판단하기 어렵고,다른 모듈에 영향을 줄 수도 있고(테스트는 또 언제해..ㅎㄷㄷ)심지어 전체 서비스를 재배포, 재시작해야됨. 그런데.. 서버 기동시간이 너무 오래걸림. 만약 CPU를 많이 쓰는 모듈이랑 Memory를 많이 쓰는 모듈이 같이 있을때..Scale out 어떻게?? 하드웨어 자원 낭비.. 특정 모듈의 문제(bug, memory leak..)가 전체 시스템에 영향을 줌 새로운 기술, 언어, 프레임워크 등을 적용하기 어려움 -&gt; 시간이 지나면 개발자 고용이 어려움.. 이런 상황에서.. agile한 development, deployment, delivery가 가능할 까..?? 차세대가 답일까?? Microservices architecture MSA는 쉽게 말해서 Scale Cube에서 Y축 확장을 의미한다. 서비스는 비지니스 로직을 가지고 자신의 hexagonal architecture를 갖는 작은 어플리케이션이다. 각 서비스는 자신의 기능을 API를 통해 노출하거나 Web UI를 제공한다. Agile 한 어플리케이션의 개발, 배포를 위해 서비스로 잘 나누는 것이 목적이다. 각 서비스는 db schema를 공유하기 보다는 자신의 schema or database를 갖는다.심지어 다른 종류의 database 를 사용 할 수도 있다.(polyglot persistence)이는 중복 데이타를 가질 수 도 있지만, 서비스간 느슨한 결합(loose coupling)을 보장한다.다른 서비스의 데이터에 대한 CRUD는 그 서비스의 API를 통해서 한다. 장점 거대한 Monolithic 어플리케이션을 서비스들로 나눈다.각 서비스는 API를 통해서 boundary를 잘 나눌 수 있고, 이를 통해 잘 모듈화 할 수 있다.이를 통해 더 빠르게 개발할 수 있고, 소스를 이해하거나 유지보수하기 쉬워진다. 한 서비스 개발팀은 자신의 서비스에만 집중해서 독립적으로 개발을 한다. 개발자는 API 계약만 잘 유지 한다면, 내부적으로는 의미있는 기술을 자유롭게 사용 할 수 있다. 각 서비스를 독립적으로 배포할 수 있다. 빠르게 테스트하고 배포 할 수 있다. 각 서비스 별로 독립적으로 확장(scale out)될 수 있다. 그리고 각 서비스에 맞는 리소스 자원을 선택하여 하드웨어를 구성할 수 있다. there are no silver bullets 단점 Microservices라는 이름때문에 service의 크기(size)가 너무 강조된다. 서비스가 작으면 좋지만, 그게 최종 목적이 되면 안된다. Line of Code는 중요하지 않은데.. Microservices 어플리케이션은 분산시스템(distributed system)에서 동작하기 때문에 매우 복잡하다. 서비스간 통신을 위해 여러 통신방법을 선택, 구현해야 될 뿐만 아니라, 서비스 실패를 고려한 개발을 해야된다. 그냥 method 호출하던 방식에 비해 매우 복잡하다. MSA는 partitioned database architecture 를 갖기 때문에, 비지니스 트랜젝션을 보장하기 어렵다. 분산 트랜젝션을 사용하는 것은 일반적이지 않고 eventual consistency 를 사용하게 될 것이다. 테스트 하기 너무 복잡하다. 서비스간 dependency가 존재한 다면, 변경에 주의를 기울여야 한다. 배포하는 것이 복잡하다. 각 서비스나 database의 host,port를 설정하기 어렵다. 너무 많고 자주 바뀌기 때문에.. service discovery 메카니즘이 필요하고, 매우 높은 수준의 자동화가 필요하다. 결론 작고 가벼운 어플리케이션에 Monolithic architecture를 사용하는 것은 좋다. 크고, 복잡하고, 장기적으로 운영되는 어플리케이션은 Microservices architecture가 더 좋은 선택일 것이다.","categories":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}],"tags":[{"name":"microservices","slug":"microservices","permalink":"https://kihoonkim.github.io/tags/microservices/"},{"name":"msa","slug":"msa","permalink":"https://kihoonkim.github.io/tags/msa/"},{"name":"architecture","slug":"architecture","permalink":"https://kihoonkim.github.io/tags/architecture/"}],"keywords":[{"name":"Microservices","slug":"Microservices","permalink":"https://kihoonkim.github.io/categories/Microservices/"}]},{"title":"(JPA - 7) Spring Data JPA","slug":"JPA(Java ORM)/7. JPA-String Data JPA","date":"2017-01-27T03:19:37.000Z","updated":"2021-08-17T00:04:32.688Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/7. JPA-String Data JPA/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/7.%20JPA-String%20Data%20JPA/","excerpt":"","text":"MyBatis나 JDBC로 데이터 엑세스 계층을 개발하다보면 테이블 단위의 단순 CRUD 코드가 반복되고,조회 조건에 따라 findByXXXandYYY() 와 같은 메소드와 매핑된 SQL이 늘어난게 된다. Spring Data JPA는 CRUD와 같은 공통 인터페이스를 제공하고,findByXXXandYYY() 와 같은 메소드를 인터페이스에 정의만 해두면,실행시점에 구현 객체를 만들어서 주입해 준다. 1234567public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123;&#125;@Servicepublic class EmployeeService &#123; @Autowired EmployeeRepository employeeRepository; // 실행시점에 구현체 자동 생성 후 주입&#125; JpaRepository&lt;T, ID&gt; 쿼리 메소드 기능 메소드 이름으로 쿼리 자동 생성위의 예제에서 EmployeeRepository에 Employee의 이름과 나이로 조회를 하고 싶다면 아래와 같이 추가만 해주면 된다. 123public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123; Employee findByNameAndAge(String name, Integer age); // 메소드 이름 규칙에 따라 쿼리 자동 생성&#125; Spring Data JPA 쿼리 메소드 생성 규칙 을 참조 하자. 메소드 이름으로 NamedQuery 호출엔티티 명 + .(dot) + 메소드 이름으로 NamedQuery를 찾는다.없으면 위와 같이 메소드 이름 규칙에 따라 쿼리를 생성한다. 1234567891011@Entity@Table(name=&quot;EMPLOYEE&quot;)@NamedQuery( name=&quot;Employee.findByNameAndAge&quot;, query=&quot;select e from EMPLOYEE e where e.name= :name and e.age= :age&quot;)public class Employee &#123;....&#125;public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123; Employee findByNameAndAge(@Param(&quot;name&quot;) String name, @Param(&quot;age&quot;) Integer age); // NamedQuery 호출&#125; 메소드에 @Query 어노테이션을 활용해 쿼리 직접 정의 1234567public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123; @Query(&quot;select e form Employee e where e.name = ?1&quot;) // 1부터 시작 Employee findByName(String name); @Query(value=&quot;select * from EMPLOYEE where age = ?0&quot;, nativeQuery=true) // 네이티브 쿼리는 0 부터 시작 Employee findByAge(String age); &#125; NOTE JPA는 위 예제와 같이 두가지 파라메터 바인딩 을 지원한다. 위치 기반 : … where e.name = ?1 이름 기반 : … where e.name = :name – &lt;== @Param(“name”) 페이징, 정렬 기능 페이징 : org.springframework.data.domain.Pageable1234public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123; Page&lt;Employee&gt; findByName(String name, Pageable pageable); // Page 객체로 리턴 List&lt;Employee&gt; findByAge(Integer age, Pageable pageable); // List 객체로 리턴&#125; 정렬 : org.springframework.data.domain.Sort123public interface EmployeeRepository extends JpaRepository&lt;Employee, Long&gt; &#123; List&lt;Employee&gt; findByAge(Integer age, , Sort sort);&#125; 12PageRequest page = new PageRequest(0, 10, new Sort(Direction.DESC, &quot;name&quot;));Page&lt;Employee&gt; result = employeeRepository.findByName(&quot;kihoon&quot;, page);","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA - 6) 트랜잭션","slug":"JPA(Java ORM)/6. JPA-트랜젝션","date":"2017-01-27T03:19:36.000Z","updated":"2021-08-17T00:04:32.688Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/6. JPA-트랜젝션/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/6.%20JPA-%ED%8A%B8%EB%9E%9C%EC%A0%9D%EC%85%98/","excerpt":"","text":"영속성 컨텍스트의 내용이 트랜잭션이 커밋 될때 실제 데이터베이스에 반영이 된다.따라서 JPA에서 영속성 컨텍스트와 트랜잭션이 어떻게 관리되는지 아는 것이 매우 중요하다. 트랜잭션 범위J2SE 환경에서 트랜잭션엔티티 매니져로 부터 EntityTransaction 을 얻어서 트랜잭션을 관리한다.J2SE 환경에서는 엔티티 매니져마다 다른 영속성 컨텍스트를 사용한다. 12345678EntityTransaction tx = entityManger.getTransaction();tx.begin(); // -- 트랜잭션 시작Customer newCustomer = new Customer(); // NEW 상태entityManger.persist(newCustomer); // 영속(Managed) 상태tx.commit(); // -- 트랜잭션 종료newCustomer.getName(); // 준영속(Detached) 상태 Spring과 같은 컨테이너 환경에서 트랜잭션@Transactional 어노테이션을 선언해서 트랜잭션을 관리한다.스프링 컨테이너는 기본적으로 트랜잭션 범위 내에서만 영속성 컨텍스트가 유효 하도록 설정되어 있다.컨테이너 환경에서는 엔티티 매니져가 같은 영속성 컨텍스트를 공유 할 수 도 있다. 같은 트랜잭션 내에서는 같은 영속성 컨텍스트를 사용한다. 여러 요청을 받아 각 쓰레드에서 동일한 엔티티매니져를 사용하더라도,다른 트랙잭션 내에서는 다른 영속성 컨텍스트를 사용한다. 12345678910111213141516171819@Controllerpublic class CustomerController &#123; @Autowired CustomerService customerService; public void doSome(...) &#123; // customer 엔티티는 트랜잭션 범위 밖이기 때문에 준영속(detached) 상태이다. Customer customer = customerService.doSomeThing1(); &#125;&#125;@Servicepublic class CustomerService &#123; .... @Transactional public Customer doSomeThing1() &#123; // 트랜잭션 시작 // do something // 트랜잭션 종료 &#125; ....&#125; 트랜잭션 밖의 준영속 상태에서 지연로딩앞에서 본 것과 같이 트랜잭션 밖에 있는 엔티티는 준영속 상태이다.준영속 상태 에서 지연로딩 이 발생하는 경우 예외가 발생 한다. 12Customer some = customerService.doSomeThing1();some.getOrder(); // 지연 로딩. 예외 발생 이를 해결하기 위한 다양한 방법이 존재한다. 글로벌 페치 전략을 즉시로딩(FetchType.EAGER)으로 수정 사용하지 않는 엔티티가 로딩 됨 N+1 문제가 발생 해당 경우만 JPQL fetch 조인을 사용 Repository에 메소드가 늘어난다. 트랜잭션 내에서 프록시 객체를 강제로 초기화 프레젠테이션 계층을 위해 서비스 계층의 로직을 수정해야 됨 FACADE 계층 추가하여 프레젠테이션과 서비스 계층의 의존성을 분리123456789101112131415161718@Servicepublic class CustomerFacade &#123; @Autowired CustomerService customerService; @Transactional // 트랜잭션 시작은 Facade 계층에서 시작 public Customer doSomeThing1() &#123; Customer customer customerService.doSomeThing1(); customer.getOrder(); // 프록시 객체를 강제로 초기화 return customer; &#125;&#125;@Servicepublic class CustomerService &#123; public Customer doSomeThing1() &#123; &#125;&#125; OSIVOSIV(Open Session In View) 는 트랜잭션 범위 밖인 프레젠테이션 영역에서지연로딩이 안되는 문제를 해결하기 위해 영속성 컨텍스트의 범위를 View 계층까지 열어 두는 것이다.하지만, 엔티티가 변경되는 경우 View 단까지 수정이 생긴다.따라서 OSIV를 사용하는 것보다는 DTO를 사용하는 것이 안전하다. JPA의 표준 용어는 OEIV(Open EntityManager In View)이지만 Hibernate에 의해서 관습적으로 OSIV로 불린다. 설정아래와 같이 설정하면 엔티티매니져에 OpenEntityManagerInViewInterceptor 가 등록된다. 123spring: jpa: open-in-view: true Spring에서 OSIV 클라이언트의 요청이 들어오면 영속성 컨텍스트를 생성하고 요청이 끝날 때까지 유지한다. 엔티티에 대한 수정은 트랜잭션 범위 내에서만 가능하다. 트랜잭션 범위 밖에서는 조회만 가능하다.(지연로딩도 가능) 동일 요청내의 여러 트랜잭션에서 같은 영속성 컨텍스트를 사용한다.즉, 한 트랜잭션이 종료되고, 엔티티의 속성을 수정한 경우 다른 트랜잭션이 시작할 때해당 수정이 반영된다. 의도하지 않은 일이 발생할 수도 있다.","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA  - 5) 객체지향 쿼리 언어","slug":"JPA(Java ORM)/5. JPA-객체지향 쿼리","date":"2017-01-27T03:19:35.000Z","updated":"2021-08-17T00:04:32.687Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/5. JPA-객체지향 쿼리/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/5.%20JPA-%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%20%EC%BF%BC%EB%A6%AC/","excerpt":"","text":"EntityManager.find()는 식별자로 하나의 엔티티를 조회할 수 있었다.JPA는 좀 더 복잡한 검색을 위해서 다양한 객체지향 쿼리 기술을 제공 한다. JPQL: Java Persistence Query Language 네이티브 SQL: SQL을 직접 사용 Criteria 쿼리: JPQL을 쉽게 사용하더록 도와주는 API(빌더 클래스) QueryDSL: Criteria 쿼리와 같음. 비표준 오픈소스 프레임워크. 기타: JDBC나 MyBatis같은 매퍼 프레임워크를 JPA와 함께 사용 하는 방법도 제공한다. JPQLJPQL은 엔티티 객체를 조회하는 JPA 표준 객체지향 쿼리로 SQL과 유사하다.JPQL은 SQL을 추상화 하기 때문에 데이터베이스에 종속되지 않고,설정된 데이터베이스 Dialect가 각 데이터베이스 맞는 SQL을 생성 및 실행한다.JPQL로 조회된 엔티티는 영속성 컨텍스트에서 관리된다.em.createQuery() 로 JPQL을 실행한다. 12String jpql = &quot;select e from Employee e where e.name = &#x27;kihoon&#x27;&quot;;List&lt;Employee&gt; employees = em.createQuery(jpql, Employee.class).getResualtList(); 네이티브 SQLem.createNativeQuery() 로 SQL을 직접 실행한다. 12String sql = &quot;select ID, NAME, DEPARTMENT_ID from EMPLOYEE where NAEM = &#x27;kihoon&#x27;&quot;;List&lt;Employee&gt; employees = em.createNativeQuery(sql, Employee.class).getResualtList(); Criteria 쿼리Criteria 쿼리는 JPQL을 생성하는 빌더 클래스이다.프로그래밍 코드 형식으로 JPQL 을 작성하기 때문에 컴파일 시점에 오류를 발견할 수 있는 등 여러 장점이 있지만,아래 코드와 같이 코드자체가 복잡하고 가독성도 떨어진다. 12345678// JPQL: &quot;select e from Employee e where e.name = &#x27;kihoon&#x27;&quot;CriteriaBuilder cb = em.getCriteriaBuilder();CriteriaQuery&lt;Employee&gt; query = cb.createQuery(Employee.class);Root&lt;Employee&gt; e = query.from(Employee.class);CriteriaQuery&lt;Employee&gt; cq = query.select(e).where(cb.equal(e.get(&quot;name&quot;), &quot;kihoon&quot;));List&lt;Employee&gt; employees = cq.createQuery(cq).getResualtList(); QueryDSLCriteria 쿼리와 같은 JPQL을 생성하는 빌더 클래스이지만 더 단순하고 쉽다.JPA표준은 아니지만 가장 많이 사용되는 오픈소스 프로젝트이다.많이 사용되기 때문에 아래쪽에서 상세히 알아보도록 하자. 12345678910111213141516171819// JPQL: &quot;select e from Employee e where e.name = &#x27;kihoon&#x27;&quot;JPAQuery query = new JPAQuery(entityManager);QEmployee employee = QEmployee.employee; // 엔티티 클래스 기반으로 쿼리전용 클래스를 미리 만들어야 된다.List&lt;Employee&gt; employees = query.from(employee) .where(employee.name.eq(&quot;kihoon&quot;)) .list(employee);``` #### JDBC나 MyBatis 직접 사용JDBC나 MyBatis를 직접 사용하는 경우 영속성 컨텍스트에서 관리가 되지 않기 때문에 SQL 실행 전에 **강제로 플러시** 해줘야 된다. ```JavaSession session = entityManager.unwrap(Session.class);session.doWork(new Work() &#123; @Override public void execute(Connection connection) throws SQLException &#123; // do something.. &#125;&#125;); QueryDSL 상세QueryDSL 레퍼런스 문서 메이븐 환경 설정 Dependency 설정: querydsl-apt, querydsl-jpa APT 빌드 플러그인 설정: JPAAnnotationProcessor 는 @Entity 을 가진 도메인 타입을 찾아서 쿼리 타입 을 생성 1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.mysema.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-apt&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.mysema.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-jpa&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; ... &lt;plugin&gt; &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt; &lt;artifactId&gt;apt-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;process&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;target/generated-sources/java&lt;/outputDirectory&gt; &lt;processor&gt;com.mysema.query.apt.jpa.JPAAnnotationProcessor&lt;/processor&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ... &lt;/plugins&gt;&lt;/build&gt; NOTE pom.xml에 메이븐 설정 후 아래와 같은 에러가 난다면.. You need to run build with JDK or have tools.jar on the classpath. If this occures during eclipse build make sure you run eclipse under JDK as well (com.mysema.maven:apt-maven-plugin:1.1.3:process:default:generate-sources) eclipse.ini 파일에 JDK가 설치된 경로를 추가해준다.(-vmargs 바로 위에 적어야 된다.) -vm C:\\Program Files\\Java\\jdk1.8.0_25\\bin\\javaw.exe 조회 쿼리쿼리타입을 사용한다. 쿼리타입의 변수명을 from에 넘겨주는데 이는 JPQL 생성시 alias로 사용된다.from(), where(), orderBy(), offset(), limit(), groupBy(), having() 등을 사용하고,최종 결과를 조회 할때 list(), uniqueResult(), singleResult() 를 사용할 수 있다. 1234567891011public void selectQueryDSL() &#123; JPAQuery query = new JPAQuery(em); QMember member = QMember.member; // 쿼리 타입 List&lt;Member&gt; list = query.from(member) .where(member.username.eq(&quot;kihoon&quot;)) .groupBy(member.age) .having(member.age.gt(30)) .orderBy(member.age.desc()) // 정령 .offset(10).limit(20) // 페이징 .list(member); // 결과 조회&#125; 1234567891011-- hibernate에 의해 자동 생성된 SQLselect member0_.ID as ID1_0_, member0_.age as age2_0_, member0_.NAME as NAME3_0_ from MEMBER member0_ where member0_.NAME=?group by member0_.age having member0_.age&gt;?order by member0_.age desc limit ? offset ? 조인innerJoin(), leftJoin(), rightJoin(), fullJoin()을 지원하고,조인 조건을 위해 on(), 페치 조인을 위해 fetch()를 지원한다. 1234567891011121314// Inner 조인query.from(employee) .innerJoin(department) .on(department.name.eq(&quot;dev&quot;)) .list();// fetch 조인query.from(employee) .innerJoin(department).fetch() .leftJoin(meeting).fetch() .list();// theta 조인query.from(employee, department) .where(employee.department.eq(department)) .list(); 서브 쿼리com.mysema.query.jpa.JPASubQuery 를 사용한다. 12345query.from(member) .where(member.age.eq( new JPASubQuery().from(subMember).unique(subMember.age.max()) )) .list(member); 프로젝션프로젝션 이란 select 절이 조회할 대상을 지정하는 것이다.JPA는 Map과 비슷한 com.mysema.query.Tuple 이라는 타입을 통해 결과를 반환하거나,com.mysema.query.types.Projections 를 통해 특정 객체(DTO)로 결과를 반환 할 수 있다.프로젝션으로 조회된 값들은 엔티티가 아니므로 영속성 컨텍스트에서 관리되지 않는다. 프로젝션 대상 컬럼이 하나일때123456JPAQuery query = new JPAQuery(em);QMember member = QMember.member;List&lt;String&gt; names = query.from(member).list(member.username);for (String name : names) &#123; System.out.println(name);&#125; 프로젝션 대상 컬럼이 여러개 일때1234567JPAQuery query = new JPAQuery(em);QMember member = QMember.member;List&lt;Tuple&gt; tupleList = query.from(member).list(member.username, member.age);for (Tuple tuple : tupleList) &#123; System.out.println(tuple.get(member.username)); System.out.println(tuple.get(member.age));&#125; 특정 객체에 자동 매핑하려고 할 때 123456789101112131415161718192021222324252627282930313233343536373839JPAQuery query = new JPAQuery(em);QMember member = QMember.member;// setter를 통해 값을 세팅List&lt;MemberDTO&gt; dtoList1 = query.from(member).list( Projections.bean(MemberDTO.class, member.username, member.age) );// 멤버 필드를 통해 값을 세팅 List&lt;MemberDTO&gt; dtoList2 = query.from(member).list( Projections.fields(MemberDTO.class, member.username, member.age) );// 생성자를 통해 값을 세팅. 파라메터 순서와 동일한 생성자가 존재해야 된다.List&lt;MemberDTO&gt; dtoList3 = query.from(member).list( Projections.constructor(MemberDTO.class, member.username, member.age) );// DTO 객체class MemberDTO &#123; private String username; private int age; public MemberDTO() &#123;&#125; public MemberDTO(String username, int age) &#123; this.setUsername(username); this.setAge(age); &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 수정, 삭제 쿼리수정, 삭제 쿼리는 영속성 컨텍스트와 상관없이 데이터베이스에 직접 실행하므로 주의해야 한다. 123456QMember member = QMember.member;JPAUpdateClause updateClause = new JPAUpdateClause(em, member);updateClause.where(member.id.eq(&quot;id001&quot;)) .set(member.username, &quot;kihoon&quot;) .set(member.age, 30) .execute(); 1234QMember member = QMember.member;JPADeleteClause deleteClause = new JPADeleteClause(em, member);deleteClause.where(member.id.eq(&quot;id001&quot;)) .execute() 동적 쿼리com.mysema.query.BooleanBuilder 를 사용하여 동적쿼리를 작성할 수 있다. 123456789101112131415String search_name = &quot;&quot;;Integer search_age=30;JPAQuery query = new JPAQuery(em);QMember member = QMember.member;BooleanBuilder builder = new BooleanBuilder();if(StringUtils.hasText(search_name)) &#123; builder.and(member.username.contains(search_name));&#125;if(search_age != null) &#123; builder.and(member.age.lt(search_age));&#125;List&lt;Member&gt; members = query.from(member).where(builder).list(member);","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA - 4) 프록시 객체, 즉시로딩, 지연로딩","slug":"JPA(Java ORM)/4. JPA-프록시 와 지연로딩","date":"2017-01-27T03:19:34.000Z","updated":"2021-08-17T00:04:32.687Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/4. JPA-프록시 와 지연로딩/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/4.%20JPA-%ED%94%84%EB%A1%9D%EC%8B%9C%20%EC%99%80%20%EC%A7%80%EC%97%B0%EB%A1%9C%EB%94%A9/","excerpt":"","text":"엔티티를 조회할 때 연관관계를 맺고있는 다른 엔티티도 같이 조회된다.하지만 항상 연관된 엔티티 정보가 필요한 것은 아니므로 불필요한 데이터베이스 조회가 생기는 것이다.Employee 정보를 얻기위해 아래와 같이 조회한다면 내부적으로 Department 정보까지 동시에 조회를 한다. 1234567891011121314151617181920212223@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToOne @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) Department dept; ...&#125;@Entitypublic class Department &#123; @Id @GeneratedValue @Column(&quot;DEPARTMENT_ID&quot;) private int id; ...&#125;// 조회Employee employee = em.find(Employee.class, &quot;id1&quot;); 실제로 Department 정보가 필요한 시점에 데이터를 조회하는 방법이 있을까? 1Department department = employee.getDept(); // 이 시점에 조회되게 할 수 있을까? JPA에서는 프록시 객체를 사용하여 위 문제를 해결한다. 프록시프록시 패턴프록시 패턴은 어떤 일을 대리인(프록시)에게 위임하여 처리하는 패턴이다.원격 객체에 접근하기 위해 사용하거나, 이미지 로딩과 같이 객체 생성 작업이 오래걸리는 경우에 사용된다. 12345678910111213141516171819202122public class RealSubject &#123; public request() &#123;...&#125;&#125;public class ProxySubject extends RealSubject &#123; private RealSubject realSubject = null; public String request() &#123; // 실제 데이터가 필요한 시점에 객체 초기화 및 데이터를 불러온다. if(realSubject == null) &#123; // 초기화 및 참조 보관 // JPA의 경우 DB 조회 realSubject = new RealSubject(); &#125; return realSubject.request(); &#125;&#125;public class Client &#123; public void selectName() &#123; RealSubject proxy = new ProxySubject(); proxy.request(); ..... &#125;&#125; JPA에서 프록시 객체123// EmployeeProxy 객체가 리턴된다.Employee employeeProxy = em.getReference(Employee.class, &quot;id1&quot;); 프록시 객체를 얻고 초기화하는 작업은 영속성 컨텍스트를 통해서 한다.즉, 프록시 객체는 영속성 컨텍스트에서 관리되고 있는 객체이다.준영속(detached) 상태의 프록시 객체를 사용하려고 하면 예외가 발생된다. 엔티티매니져의 getReference() 메소드를 통해서 프록시 객체를 얻을 수 있다. getReference()로 프록시 객체를 얻으려고 할때 이미 영속성 컨텍스트에 실제 객체가 있는경우프록시 객체가 아닌 실제 객체를 리턴한다.반면, 프록시 객체를 조회 했다면 find()로 조회 하더라도 실제 객체가 아닌 프록시 객체가 리턴된다.이는 영속성 컨텍스트가 항상 엔티티의 동일성(identity)을 보장하기 위함이다.123456789101112131415// 실제 객체가 먼저 조회되어 영속성 컨텍스트에 존재하는 경우Employee realEmployee = em.find(Employee.class, &quot;id1&quot;);Employee proxyEmployee = em.getReference(Employee.class, &quot;id1&quot;);// realEmployee, proxyEmployee 모두 실제 엔티티 이다.Assert.assertTrue(realEmployee == proxyEmployee); // 성공// 프록시 객체를 조회한 뒤 실제 객체를 조회하려고 하는 경우Employee proxyEmployee = em.getReference(Employee.class, &quot;id1&quot;);Employee realEmployee = em.find(Employee.class, &quot;id1&quot;);// realEmployee, proxyEmployee 모두 프록시 객체이다.Assert.assertTrue(realEmployee == proxyEmployee); // 성공// 타입 비교Assert.assertFalse(proxyEmployee.getClass() == Employee.class);Assert.assertTrue(proxyEmployee instanceof Employee); 프록시 객체를 사용시 동등성(equal) 비교시 주의 해야한다.IDE를 통해 자동으로 equals() 오버라이딩 메소드를 생성한 경우 제대로 동작하지 않는다.내부적으로 같은 타입인지 비교하기 위해 getClass()를 사용하고,(프록시 객체는 실제 객체를 상속받음)필드 값들을 비교하기 위해서 getter 메소드가 아닌 필드에 직접 접근하여 값을 얻는다.(프록시 객체가 초기화 되지 않았 을 수 있음)타입비교는 instanceof를 사용하고, 필드 값은 getter 메소드를 통해 얻어야 한다. 12345678910@Overridepublic boolean equals(Object obj) &#123; ... if(this.getClass() != obj.getClass()) return false; ... Employee employee = (Employee) obj; ... if(name!=null ? !name.equals(employee.name) : employee.name != null) return false; ...&#125; 12345678910@Overridepublic boolean equals(Object obj) &#123; ... if(!(obj instanceof Employee)) return false; ... Employee employee = (Employee) obj; ... if(name!=null ? !name.equals(employee.getName()) : employee.getName() != null) return false; ...&#125; 즉시로딩, 지연로딩JPA에서 엔티티와 연관관계를 맺고있는 엔티티들 을 지연로딩 할 때 프록시 객체 를 사용한다. 즉시로딩: 엔티티 조회시 연관된 모든 엔티티를 함께 조회연관된 엔티티는 조인쿼리(LEFT OUTTER JOIN) 을 통해 함께 조회된다. 12345678@Entitypublic class Employee &#123; ... @ManyToOne(fetch= FetchType.EAGER) @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) private Department department; ...&#125; NOTE JPA에서 즉시 로딩을 할때 내부조인(INNER JOIN)이 아니라 외부조인(LEFT OUTTER JOIN)을 사용한다. 이는 null값이 허용되는 경우 데이터가 누락되는 것은 막을 수 있지만, 성능상 안좋을 수 있다. INNER JOIN을 사용해야 되는 경우에는 아래와 같이 설정해 주면된다. (둘중 한가지 방법 선택) @JoinColumn(name=”DEPARTMENT_ID”, nullable=false) @ManyToOne(fetch= FetchType.EAGER, optional=false) 지연로딩: 엔티티 조회시 연관된 엔티티는 실제 사용시(호출시) 조회 12345678@Entitypublic class Employee &#123; ... @ManyToOne(fetch= FetchType.LAZY) @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) private Department department; ...&#125; 컬렉션의 즉시로딩, 지연로딩 컬렉션을 즉시로딩으로 설정(FetchType.EAGER)한 경우 optional 설정에 관계 없이 무조건 OUTTER JOIN을 한다. 컬렉션을 지연로딩 하는 경우 컬렉션 래퍼(PersistentBag)으로 감싸져서 프록시 역할을 수행한다. 12345678910111213@Entitypublic class Department &#123; ... @OneToMany(mappedBy=&quot;department&quot;, fetch= FetchType.LAZY) @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) private List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); ...&#125;Department department = em.find(Department.class, &quot;did01&quot;);List&lt;Employee&gt; employees = department.getEmployees(); // 아직 조회 안됨.employees.get(0); // 실제 호출시 Employee를 조회한다.// employees.getClass().getName() ==&gt; org.hibernate.collection.internal.PersistentBag 영속성 전이(Transitive Persistence)엔티티를 저장할 때 연관된 엔티티의 경우 외래키만 참조하여 저장한다.엔티티 저장시 연관된 엔티티를 함께 저장하려면 CASCADE 옵션을 사용하면 된다.CASCADE 타입 : ALL, PERSIST, MERGE, REMOVE, REFRESH, DETACH 12345@Entitypepublic class Department &#123; @OneToMany(mappedBy=&quot;department&quot;, cascade=CascadeType.PERSIST) private List&lt;Employee&gt; employees = new ArrayList&lt;&gt;();&#125; 12345678// 영속성 전이 미 사용Department dept = new Department();em.persist(dept);Employee employee = new Employee();employee.setDepartment(dept);dept.getEmployees().add(employee);em.persist(employee); 12345678// 영속성 전이 사용Department dept = new Department();Employee employee = new Employee();employee.setDepartment(dept);dept.getEmployees().add(employee);em.persist(dept); // 한 번에 저장 고아객체(ORPHAN) 제거JPA는 부모 엔티티와 연관관계가 끊긴 경우 자동으로 삭제해 주는 옵션을 제공한다.해당 옵션을 설정하면 아래와 같이 remove하는 경우 List 에서만 삭제하는 것이 아니라 DB에서도 삭제한다.@OneToMany, @OneToOne에서만 지원된다. 12345@Entitypepublic class Department &#123; @OneToMany(mappedBy=&quot;department&quot;, orphanRemoval=true) private List&lt;Employee&gt; employees = new ArrayList&lt;&gt;();&#125; 1234Department dept = em.find(Department.class, &quot;id01&quot;);dept.getEmployees().remove(0); // 연관관계 삭제// DELETE FROM EMPLOYEE WHERE EMPLOYEE_ID = ? 실행 됨dept.getEmployees().clear(); // 연관된 모든 Employee 삭제됨","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA - 3) 엔티티 매핑","slug":"JPA(Java ORM)/3. JPA-엔티티 매핑","date":"2017-01-27T03:19:33.000Z","updated":"2021-08-17T00:04:32.687Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/3. JPA-엔티티 매핑/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/3.%20JPA-%EC%97%94%ED%8B%B0%ED%8B%B0%20%EB%A7%A4%ED%95%91/","excerpt":"","text":"앞에서 영속성 컨텍스트에 객체(엔티티)를 저장하는 것을 보았다.객체와 관계형 데이터베이스의 다른 개념을 어떻게 매핑하고 데이터가 반영되는지 알아보자. 객체(엔티티)를 영속성 컨테스트에 저장(persist) 후 트랜젝션이 커밋되는 시점에각 데이터베이스에 맞는 SQL을 생성하여 데이터베이스로 보내진다.객체를 어떻게 엔티티로 만들고 테이블과 매핑하는지 알아보자. 객체와 테이블 매핑 Annotation객체(Entity)와 데이터베이스 Table을 매핑할 때 아래의 어노테이션을 사용한다. @Entity: JPA에서 테이블에 매핑할 클래스에 붙임. 해당 클래스는 엔티티라 부른다. 기본생성자(default constructor)는 필수 final class, enum, interface, inner class에 사용 불가. final 필드 사용 불가 -&gt; runtime시에 javassist에 의해 Entity의 서브클래스 생성하기 때문. 클래스 상속 불가하면 안됨 @Table: 엔티티와 매핑할 테이블명을 지정 @Id: 기본키(primary Key) 매핑 @Column: 테이블의 컬럼명 매핑. 지정안하는 경우 객체 필드명과 동일하게 지정 @Enumerated: 자바의 enum 타입을 사용하는 경우 지정 @Temporal: 날짜 타입(Data, Calendar) 매핑시 사용. (DATE, TIME, TIMESTAMP) @Lob: CLOB, BLOB 타입과 매핑시 @Transient: 테이블 컬럼에 매핑되지 않는 필드에 지정. @Access: JPA가 엔티티 데이터에 접근하는 방식 지정. FILED가 기본값. 필드(FILED) or Getter(PROPERTY). 1234567891011121314151617181920212223242526272829@Enitity@Table(name=&quot;CUSTOMER&quot;)public class Customer &#123; @Id private String id; @Column(&quot;FIRST_NAME&quot;) private String firstName; @Column(&quot;LAST_NAME&quot;) private String lastName; @Enumerated(EnumType.STRING) private CustomerType type; // public enum CustomerType &#123; GOLD, SILVER, BASIC &#125; @Temporal(TemporalType.TIMESTAMP) private java.util.Date createdDate; @Lob private String description; @Transient private String tempVal; @Access(AccessType.PROPERTY) public String getFullName() &#123; return firstName + &quot; &quot; + lastName; &#125;&#125; DB Schema 자동생성엔티티에 DB Schema 정보를 위의 어노테이션을 이용해 매핑해 놓았기 때문에JPA를 통해 DDL을 자동 생성할 수 있는 기능을 제공한다.(실제 운영환경에서 사용하기에는 위험한 기능이다.) spring.jpa.hibernate.ddl-auto 속성을 통해 설정한다. 1spring.jpa.hibernate.ddl-auto: validate # spring.jpa.properties.hibernate.hbm2ddl.auto 속성과 와 동일 create: 기존 테이블 삭제 후 새로 생성 create-drop: 기존 테이블 삭제 후 새로 생성 + 어플리케이션 종료시 DDL 제거 update: 테이블과 엔티티 매핑정보 비교 후 변경내용만 반영 validate: (권장) 테이블과 엔티티 매핑정보 비교 후 변경사항 있는 경우 경고 출력. 어플리케이션 실행 안됨. 기본키 매핑 전략각 테이블 마다 데이타를 유니크하게 식별하기 위해 기본키를 가지고 있다.JPA에서는 다음과 같은 기본키 생성 전략을 지원한다. 직접 할당: em.persist() 호출전에 직접 세팅한다.123Order order = new Order();order.setId(&quot;ORDER_00001&quot;); // pk 직접 생성 후 세팅em.persist(order); IDENTITY: 기본키 생성을 데이터베이스에 위임. MySQL에서 AUTO_INCREMENT 를 지정해 둔 경우 사용.영속성 컨텍스트에 엔티티를 저장하려면 반드시 식별자가 필요하기 때문에, IDENTITY 전략 사용시 즉시 DB반영된다.(쓰기지연 X)1234567@Entitypublic class Order &#123; @Id @GeneratedValue(strategy=GenerationType.IDENTITY) private String id; ...&#125; SEQUENCE: 데이터베이스 시퀀스를 사용하여 기본키를 생성한다.123456789// CREATE SEQUENCE ORDER_SEQ START WITH 1 INCREMENT BY 1;@Entity@SequenceGenerator(name=&quot;ORDER_SEQ_GENERATOR&quot;, sequenceName=&quot;ORDER_SEQ&quot;, initialValue=1, allocationSize=1)public class Order &#123; @Id @GeneratedValue(strategy=GenerationType.SEQUENCE, getnerator=&quot;ORDER_SEQ_GENERATOR&quot;) private String id; ...&#125; TABLE: 키생성을 위한 전용 테이블을 사용하여 시퀀스와 비슷하게 기본키를 생성한다. 123456789// CREATE TABLE TB_SEQUENCE ( sequence_name varchar(255) not null, next_val bigint, primary key (sequence_name) )@Entity@TableGenerator(name=&quot;ORDER_SEQ_GENERATOR&quot;, table=&quot;TB_SEQUENCE&quot;, pkColumnValue=&quot;ORDER_SEQ&quot;, allocationSize=1)public class Order &#123; @Id @GeneratedValue(strategy=GenerationType.TABLE, getnerator=&quot;ORDER_SEQ_GENERATOR&quot;) private String id; ...&#125; sequence_name next_val CUSTOMER_SEQ 2 ORDER_SEQ 100 … … Tip.기본키는 변경되면 안되기 때문에,직접할당 전략이 아니라면 엔티티에서 setId() 메소드를 비공개(private)하는 것이 좋다. 연관관계 매핑객체 는 다른 객체와 참조(reference) 를 통해 관계를 맺고,테이블 은 외래키(foreign key) 를 통해서 관계를 맺는다. 객체와 테이블간 연관 관계를 맺는 방식의 차이를 JPA는 다음과 같은 특성을 이용해서 해결한다. 방향(Direction): 객체가 다른 객체를 참조하는 방향. 단방향/양방향테이블은 외래키를 기반으로 테이블간 양방향으로 JOIN이 가능하다. 하지만, 객체의 참조는 항상 단방향이다. 다중성(Multiplicity): 객체의 관계(Relationships) 표현. 다대일(N:1), 일대다(1:N), 일대일(1:1), 다대다(N:M) 연관관계의 주인(Owner): 객체간 양방향 으로 방향성을 가질때 연관관계에 있어 누가 주인 인가를 정해야 된다.테이블로 보면 누가 FK를 가져야 하는가의 문제이다. 연관관계의 주인인 엔티티가 FK를 업데이트 한다. 주요 Annotation @ManyToOne: 다대일 관계 매핑 @OneToMany(mappedBy=””): 일대다 관계 매핑. mappedBy 속성을 통해 연관관계의 주인을 지정. @OneToOne: 일대일 관계 매핑 @ManyToMany: 다대다 관계 매핑 @JoinColumn(name=””): 외래키 매핑시 사용 @JoinTable: 다대다 관계를 풀기위해 연결테이블을 사용시 별도 엔티티 생성 없이 매핑 다대일(Many To One) 다대일 관계의 반대는 항상 일대다 관계이다. 연관관계의 주인은 항상 다 쪽이 갖는다. 즉, 다 쪽에 외래키가 존재한다. 단방향![fig](/images/unidirectional ManyToOne.png “”) 123456789101112131415161718192021@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToOne @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) Department dept; ...&#125;@Entitypublic class Department &#123; @Id @GeneratedValue @Column(&quot;DEPARTMENT_ID&quot;) private int id; ...&#125; 양방향![fig](/images/bidirectional ManyToOne.png “”) 1234567891011121314151617181920212223@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToOne @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) Department dept; ...&#125;@Entitypublic class Department &#123; @Id @GeneratedValue @Column(&quot;DEPARTMENT_ID&quot;) private int id; @OneToMany(mappedBy=&quot;dept&quot;) // Employee 엔티티를 연관관계 주인으로 지정 private List&lt;Employee&gt; employees = new ArrayList&lt;Employee&gt;(); ...&#125; 일대다(One To Many) 일대다 관계는 항상 다대일 관계의 반대 방향이다. 참조 대상이 다 건이므로 Collection, List, Set, Map 자료구조를 사용한다. 단방향 일대다 단방향 관계는 다대일 양방향 관계로 바꿔서 사용하는 것이 좋다. Department에서 Employee 쪽에 있는 외래키를 수정해야 되기때문에 SQL이 더 많이 실행된다. Department에 Employee 추가하는 경우 INSERT 실행 후 외래키 UPDATE 하는 SQL이 한번 더 실행된다. 1234567891011121314151617181920@Entitypublic class Department &#123; @Id @GeneratedValue @Column(&quot;DEPARTMENT_ID&quot;) private int id; @OneToMany @JoinColumn(name=&quot;EMPLOYEE_ID&quot;) private List&lt;Employee&gt; employees = new ArrayList&lt;Employee&gt;(); ...&#125;@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; ...&#125; 양방향 일대다(1:N) 관계의 양방향은 다대일(N:1) 관계의 양방향과 같은 의미이다. 단, 일(1) 을 연관관계 주인으로 설정하는 방법은 존재하지 않는다.연관관계 주인은 외래키가 있는 곳 인데, 이는 항상 다(N) 쪽에 존재한다. 연관관계 주인 설정은 할 수 없지만, 의미상 표현은 다음과 같이 하면된다. 1234567891011121314151617181920212223@Entitypublic class Department &#123; @Id @GeneratedValue @Column(&quot;DEPARTMENT_ID&quot;) private int id; @OneToMany @JoinColumn(name=&quot;EMPLOYEE_ID&quot;) private List&lt;Employee&gt; employees = new ArrayList&lt;Employee&gt;(); ...&#125;@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToOne @JoinColumn(name=&quot;DEPARTMENT_ID&quot;, insertable=false, updatable=false) Department dept; // &lt;=== ReadOnly 설정 ...&#125; 일대일(One To One)일대일은 관계에서 주(Source) 테이블, 대상(Target) 테이블 모두 외래키를 갖을 수 있다.따라서 어느 테이블에 외래키를 갖을지, 엔티티에서 누가 연관관계의 주인인지를 선택해야 한다.아래 그림들에서는 왼쪽을 주 테이블, 오른쪽이 대상 테이블로 정의한다. 단방향(주 테이블이 외래키를 가짐)![fig](/images/unidirectional OneToOne-source.png “”) 1234567891011121314151617181920@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @OneToOne @JoinColumn(name=&quot;LOCKER_ID&quot;) private Locker locker; ...&#125;@Entitypublic class Locker &#123; @Id @GeneratedValue @Column(&quot;LOCKER_ID&quot;) private int id; ...&#125; 양방향(주 테이블이 외래키를 가짐)![fig](/images/bidirectional OneToOne.png “”) 12345678910111213141516171819202122@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @OneToOne @JoinColumn(name=&quot;LOCKER_ID&quot;) private Locker locker; ...&#125;@Entitypublic class Locker &#123; @Id @GeneratedValue @Column(&quot;LOCKER_ID&quot;) private int id; @OneToOne(mappedBy=&quot;locker&quot;) // 연관관계 주인 설정. 주 테이블(Employee)이 외래키를 가짐. private Employee employee; ... &#125; 단방향(대상 테이블이 외래키를 가짐)![fig](/images/unidirectional OneToOne-source.png “”)LOCKER 테이블에서 EMPLOYEE의 ID를 외래키로 갖고 있는데,Employee 엔티티에서 참조를 가지려고 하는 경우 JPA에서 지원하지 않는다. 양방향(대상 테이블이 외래키를 가짐)12345678910111213141516171819202122@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @OneToOne(mappedBy=&quot;employee&quot;) // 연관관계 주인 설정. 대상 테이블(LOCKER)이 외래키를 가짐. private Locker locker; ...&#125;@Entitypublic class Locker &#123; @Id @GeneratedValue @Column(&quot;LOCKER_ID&quot;) private int id; @OneToOne @JoinColumn(name=&quot;EMPLOYEE_ID&quot;) private Employee employee; ... &#125; 다대다(Many To Many)관계형 데이터베이스에서는 N:M 관계를 테이블 2개로 표현 할 수 없다.N:M관계를 중간에 관계테이블을 만들어 1:N - M:1 관계로 풀어서 해결한다.이런 테이블 구조를 그대로 엔티티로 만드는 것은 객체지향 개념과 잘 맞지 않는다.JPA에서는 N:M관계를 위해 @ManyToMany 어노테이션을 지원한다. NOTE 관계 테이블이 두 테이블의 ID를 PK로 갖는 단순한 구조라면 @ManyToMany 를 사용하면 되지만, 관계 테이블에 추가적인 컬럼이 존재 한다면, 관계 테이블에 매핑되는 엔티티를 만들어 1:N - M:1 관계로 풀어야 된다. 단방향![fig](/images/unidirectional ManyToMany.png “”) 12345678910111213141516171819202122@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToMany @JoinTable(name=&quot;EMPLOYEE_MEETING&quot;, joinColumns=@JoinColumn(name=&quot;EMPLOYEE_ID&quot;), inverseJoinColumns=@joinColumn(name=&quot;MEETING_ID&quot;)) private List&lt;Meeting&gt; meetings = new ArrayList&lt;Meeting&gt;(); ...&#125;@Entitypublic class Meeting &#123; @Id @GeneratedValue @Column(&quot;MEETING_ID&quot;) private int id; ... &#125; 양방향양방향 관계는 항상 연관관계의 주인을 지정해 줘야된다.다대다 관계에서는 양쪽에 아무곳이나 지정해도 상관없다.![fig](/images/bidirectional ManyToMany.png “”) 123456789101112131415161718192021222324@Entitypublic class Employee &#123; @Id @GeneratedValue @Column(&quot;EMPLOYEE_ID&quot;) private int id; @ManyToMany @JoinTable(name=&quot;EMPLOYEE_MEETING&quot;, joinColumns=@JoinColumn(name=&quot;EMPLOYEE_ID&quot;), inverseJoinColumns=@joinColumn(name=&quot;MEETING_ID&quot;)) private List&lt;Meeting&gt; meetings = new ArrayList&lt;Meeting&gt;(); ...&#125;@Entitypublic class Meeting &#123; @Id @GeneratedValue @Column(&quot;MEETING_ID&quot;) private int id; @ManyToMany(mappedBy=&quot;meetings&quot;) private List&lt;Employee&gt; employees = new ArrayList&lt;Employee&gt;(); ... &#125; 기타 매핑Self-Join 매핑123456789101112131415161718192021222324252627282930313233343536373839@Entity@Table(name=&quot;MEMBER&quot;)public class Member &#123; public Member() &#123;&#125; public Member(String username, Integer age) &#123; this.username = username; this.age = age; &#125; @Id @GeneratedValue @Column(name=&quot;ID&quot;) private String id; @Column(name=&quot;NAME&quot;) private String username; private Integer age; @ManyToOne(fetch= FetchType.LAZY) @JoinColumn(name=&quot;MANAGER_ID&quot;) private Member manager; @OneToMany(mappedBy=&quot;manager&quot;, fetch= FetchType.LAZY) private List&lt;Member&gt; subMembers = new ArrayList&lt;Member&gt;(); public void setManager(Member manager) &#123; this.manager = manager; this.manager.getSubMembers().add(this); &#125; public Member getManager() &#123; return manager; &#125; public List&lt;Member&gt; getSubMembers() &#123; return this.subMembers; &#125; // getter setter&#125; 상속 관계 매핑 조인 전략(Joined Strategy): 각 테이블로 분할 장점: 정규화된 테이블로 유지 가능 단점: 조인이 많아져서 쿼리가 복잡 해지고 느려짐 12345678910111213141516@Entity@Inheritance(strategy= InheritanceType.JOINED)@DiscriminatorColumn(name=&quot;DTYPE&quot;)public abstract class Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;A&quot;)public class Album extends Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;B&quot;)public class Book extends Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;D&quot;)public class DVD extends Item &#123;&#125; 단일 테이블 전략(Single-Table Strategy): 모든 컬럼을 한 테이블로 합침. 구분 컬럼으로 구분. 장점: 조인이 없어 쿼리가 단순하고 빠름. 단점: 모든 컬럼이 null을 허용해야됨. 테이블에 컬럼이 너무 많아짐. 12345678910111213141516@Entity@Inheritance(strategy= InheritanceType.SINGLE_TABLE)@DiscriminatorColumn(name=&quot;DTYPE&quot;)public abstract class Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;A&quot;)public class Album extends Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;B&quot;)public class Book extends Item &#123;&#125;@Entiry@DiscriminatorValue(&quot;D&quot;)public class DVD extends Item &#123;&#125; 구현 클래스 별 테이블 전략(Table per Concrete Class Strategy): 엔티티마다 테이블을 별도로 만듬. 장점: 타입별로 처리할때 효과적. not null 제약조건 사용 가능. 단점: 모든 ITEM을 한번에 조회 할 때 UNION을 사용해야 되서 느리다. 123456789101112@Entity@Inheritance(strategy= InheritanceType.TABLE_PER_CLASS)public abstract class Item &#123;&#125;@Entirypublic class Album extends Item &#123;&#125;@Entirypublic class Book extends Item &#123;&#125;@Entirypublic class DVD extends Item &#123;&#125; @MappedSuperclass위 그림과 같이 여러 테이블에서 공통적으로 사용하는 컬럼을 모든 엔티티의 속성으로 추가해야 될까?JPA에서는 공통 속성만 정의된 클래스를 상속 받아 사용 할 수 있는 @MappedSuperclass 어노테이션을 제공한다.@MappedSuperclass을 지정한 클래스는 엔티티가 아니므로 영속성 컨텍스트에서 조회 할 수 없다.실제 new를 사용하여 생성 할 필요가 없으므로 추상클래스로 만드는 것이 좋다. 필드에 @Column(name=””)을 사용하여 별도로 매핑 정보를 주지 않으면, 네이밍 규칙에 따라 컬럼과 자동으로 매핑한다.상속받은 엔티티의 필드명과 데이틀의 컬럼 명이 다른경우, @AttributeOverride 를 사용하여 컬럼명을 직접 지정할 수 있다. 123456789101112131415161718192021222324252627282930313233343536373839@MappedSuperclasspublic abstract class BaseInfo &#123; @Id @GeneratedValue private int id; private String name; @Temporal(TemporalType.TIMESTAMP) private Date updatedDate; private int updatedUserId; @Temporal(TemporalType.TIMESTAMP) private Date createdDate; private int createdUserId;&#125;@Entitypublic class Department extends BaseInfo &#123; // 공통 속성 상속 받음&#125;@Entitypublic class Employee extends BaseInfo &#123; // 공통 속성 상속 받음 // 나머지 속성만 추가 private BigDecimal salary; @ManyToOne @JoinColumn(name=&quot;DEPARTMENT_ID&quot;) private Department dept;&#125;@Entity@AttributeOverrides(&#123; @AttributeOverride(name=&quot;id&quot;, column=@Column(name=&quot;MEETING_ID&quot;)), @AttributeOverride(name=&quot;name&quot;, column=@Column(name=&quot;MEETING_NAME&quot;))&#125;)public class Meeting extends BaseInfo &#123; ...&#125; 복합키 매핑지금까지는 기본키가 하나로 구성된 예제만 살펴보았다.기본키가 둘 이상으로 구성된 복합키인 경우 매핑하는 방법을 알아보자.@IdClass 와 @EmbeddedId 를 통해 두가지 방식으로 매핑할 수 있다.두방식 모두 복합키를 필드로 가지고 있는 식별자 클래스를 만들어야 된다. 두 방식중 무엇을 사용하든 복합키에는 @GeneratedValue를 통해 기본키를 자동생성 할 수 없다. 반드시 직접할당 전략을 사용해야 된다. @IdClass 방식 식별자 클래스는 반드시 public 이어야 한다. 식별자 클래스는 Serializalbe 인터페이스를 구현해야 된다. 식별자 클래스는 반드시 기본 생성자가 있어야 한다. 식별자 클래스는 equals, hashCode를 오버라이딩 해야된다.(엔티티는 식별자 비교를 통해 동등(equals)한지 판단한다.) 식별자 클래스의 속성명과 엔티티 클래스의 속성명은 동일해야 된다. 1234567891011121314151617181920212223// 식별자 클래스public class MyId implements Serializalbe &#123; // Serializalbe 인터페이스 구현해야 된다. private String id1; private String id2; public MyId()&#123;&#125; // default 생성자가 반드시 존재해야 된다. public MyId(String id1, String id2)&#123;.......&#125; // equals, hashCode를 overriding 해야된다. @Override public boolean equals(Object o) &#123;......&#125; @Override public int hashCode() &#123;......&#125;&#125;// 엔티티 클래스@Entity@IdClass(MyId.class)public class MyClass &#123; @Id @Column(name=&quot;MY_ID1&quot;) private String id1; // MyId 클래스와 엔티티의 속성명이 동일해야 된다. @Id @Column(name=&quot;MY_ID2&quot;) private String id2;&#125; 12345678910/* 저장 */MyClass myclass = new MyClass();myclass.setId1(&quot;myid1_001&quot;);myclass.setId2(&quot;myid2_001&quot;);// ......추가 속성 세팅......em.persist(myclass);/* 조회 */MyId myid = new MyId(&quot;myid1_001&quot;, &quot;myid2_001&quot;);MyClass myclass = em.find(MyClass.class, myid); @EmbeddedId 방식 식별자 클래스는 @Embeddable 어노테이션을 붙여야 한다. 식별자 클래스는 반드시 public 이어야 한다. 식별자 클래스는 Serializalbe 인터페이스를 구현해야 된다. 식별자 클래스는 반드시 기본 생성자가 있어야 한다. 식별자 클래스는 equals, hashCode를 오버라이딩 해야된다.(엔티티는 식별자 비교를 통해 동등(equals)한지 판단한다.) 1234567891011121314151617181920212223// 식별자 클래스@Embeddablepublic class MyId implements Serializalbe &#123; @Column(name=&quot;MY_ID1&quot;) private String id1; @Column(name=&quot;MY_ID2&quot;) private String id2; public MyId()&#123;&#125; public MyId(String id1, String id2)&#123;.......&#125; @Override public boolean equals(Object o) &#123;......&#125; @Override public int hashCode() &#123;......&#125;&#125;// 엔티티 클래스@Entitypublic class MyClass &#123; @EmbeddedId // 복합키 매핑 private MyId id;&#125; 12345678910/* 저장 */MyClass myclass = new MyClass();MyId myid = new MyId(&quot;myid1_001&quot;, &quot;myid2_001&quot;);myclass.setId(myid);// ......추가 속성 세팅......em.persist(myclass);/* 조회 */MyId myid = new MyId(&quot;myid1_001&quot;, &quot;myid2_001&quot;);MyClass myclass = em.find(MyClass.class, myid); 식별관계와 비식별관계 매핑데이터베이스 테이블 간의 관계는 외래키를 통해 맺는다.외래키가 기본키로 포함되는지 null값을 가질 수 있는지에 따라 아래와 같이 구분된다. 비식별관계(Non Identifying Relationship)@JoinColumns 로 JoinColumn을 여러개 지정할 수 있다.외래키의 컬럼 명을 다르게 지정한 경우 참조 테이블의 컬럼명을 referencedColumnName을 통해 매핑 할 수 있다. 123456789101112@Entitypublic class YourClass &#123; @Id private String id; @ManyToOne @JoinColumns(&#123; @JoinColumn(name=&quot;M_ID1&quot;, referencedColumnName=&quot;MY_ID1&quot;), @JoinColumn(name=&quot;M_ID2&quot;, referencedColumnName=&quot;MY_ID2&quot;) &#125;) private MyClass myclass;&#125; 식별관계(Identifying Relationship) @IdClass 123456789101112131415161718192021222324252627@Entitypublic class MyClass &#123; @Id @Column(name=&quot;MY_ID&quot;) private String id; .....&#125;@Entity@IdClass(YourId.class) // 복합키 매핑public class YourClass &#123; @Id @Column(name=&quot;YOUR_ID&quot;) private String yourId; @Id // &lt;--------------- 외래키 매핑 @ManyToOne @JoinColumn(name=&quot;MY_ID&quot;) private MyClass myclass;&#125;public class YourId implements Serializalbe &#123; private String myclass; // YourClass.myclass private String yourId; // YourClass.yourId //... default 생성자 ... //... equals, hashCode ...&#125; @EmbeddedId 1234567891011121314151617181920212223242526272829@Entitypublic class MyClass &#123; @Id @Column(name=&quot;MY_ID&quot;) private String id; .....&#125;@Entitypublic class YourClass &#123; @EmbeddedId private YourId yourId; @MapsId(myId) // &lt;--------------- 외래키 매핑 @ManyToOne @JoinColumn(name=&quot;MY_ID&quot;) private MyClass myclass;&#125;@Embeddablepublic class YourId implements Serializalbe &#123; private String myId; // YourClass에서 @MapsId(myId)로 매핑 @Column(name=&quot;YOUR_ID&quot;) private String yourId; // YourClass.yourId //... default 생성자 ... //... equals, hashCode ...&#125; 값 타입12345678910111213141516171819202122@Entitypublic class Employee &#123; @Id @GeneratedValue private Long id; // 기본값 타입 private String name; private int age; // 임베디드 타입 @Embedded private Address address;&#125;@Embeddablepublic class Address &#123; private String city; @Column(name=&quot;ZIP_CD&quot;) // 매핑 컬럼 정의도 가능 private String zipCode; // 메소드 정의도 가능&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA - 2) 영속성(Persistence) 관리","slug":"JPA(Java ORM)/2. JPA-영속성 관리","date":"2017-01-27T03:19:31.000Z","updated":"2021-08-17T00:04:32.686Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/2. JPA-영속성 관리/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/2.%20JPA-%EC%98%81%EC%86%8D%EC%84%B1%20%EA%B4%80%EB%A6%AC/","excerpt":"","text":"JPA를 사용하면 어플리케이션과 데이터베이스 사이에 영속성 컨텍스트(Persistence Context)라는 개념을 두고 데이터를 관리한다.영속성 컨텍스트란 무엇인지 어떻게 생성, 관리되는지 알아보자. 참조 : https://docs.jboss.org/hibernate/entitymanager/3.6/reference/en/html_single/ 엔티티 매니저 팩토리(EntityManagerFactory) 주 목적은 EntityManager 인스턴스를 관리하는 것이다. EntityManagerFactory 생성시 커넥션 풀도 함께 생성한다. 같은 EntityManagerFactory를 통해 생성되는 EntityManager는 같은 database에 접속한다. 한 번 생성 후 어플리케이션 전체에서 공유된다. J2SE 환경에서 javax.persistence.Persistence 부트스트랩 클래스를 통해 생성할 수 있다.1EntityManagerFactory emf = Persistence.createEntityManagerFactory(&quot;mydb&quot;); Spring과 같은 J2EE환경에서는 @PersistenceUnit 을 통해 EntityManagerFactory를 얻을 수 있다.하지만, @PersistenceContext 를 통해 EntityManager 를 주입 받아 사용할 수 있기 때문에 잘 사용하지 않는다.123456@Repositorypublic class MyRepository &#123; @PersistenceUnit EntityManagerFactory emf; ....&#125; EntityManagerFactory는 hibernate의 SessionFactory와 유사하다. 엔티티 매니저(EntityManager) 엔티티를 저장, 수정, 삭제, 조회등 엔티티와 관련된 작업을 수행 Application-managed entity manager: 다음과 같은 코드로 엔티티매니져를 생성 및 제어한다.1EntityManger em = emf.createEntityManager(); Container-managed entity manager: J2EE환경에서 컨테이너가 엔티티매니져를 생성하고 트랜젝션 경계(boundary)를 결정.123456@Repositorypublic class MyRepository &#123; @PersistenceContext EnitityManger em; ....&#125; EntityManager(javax.persistence.EntityManager)는 hibernate의 Session(org.hibernate.Session)과 유사12345678em.find(); // 엔티티 조회em.persist(); // 엔티티 저장em.remove(); // 엔티티 삭제em.flush(); // 영속성 컨텍스트 내용을 데이터베이스에 반영em.detach(); // 엔티티를 준영속 상태로 전환em.merge(); // 준영속 상태의 엔티티를 영속상태로 변경em.clear(); // 영속성 컨텍스트 초기화em.close(); // 영속성 컨텍스트 종료 영속성 컨텍스트(persistence context)1entityManager.persist(entity); // 엔티티를 영속성 컨텍스트에 저장 어플리케이션과 데이터베이스 사이에 존재하는 논리적인 개념으로 엔티티를 저장하는 환경을 의미한다. 엔티티매니저를 통해서만 접근이 가능하다. J2EE 환경에서는 여러 엔티티메니저가 하나의 영속성컨텍스트를 공유한다. 영속성 컨텍스트에 존재하는 엔티티는 플러시 호출시 데이터베이스에 반영 된다. entityManger.flush() 로 플러시 직접 호출 트랜젝션 커밋(commit) 시 플러시 자동 호출 JPQL 쿼리 실행 시 플러시 자동 호출 영속성 컨텍스트의 장점 1차 캐시: 엔티티 조회시 영속성 컨테스트에 존재하면 바로 리턴, 없으면 데이터베이스 조회 후 리턴. 동일성(==)보장: 조회시 항상 같은 엔티티 인스턴스를 리턴(주소값이 같음) 트랜잭션을 지원하는 쓰기 지연(Transactional write-behind): 트랜젝션 커밋 될때까지 내부 쿼리저장소에 모아뒀다가 한번에 실행 변경감지(Dirty Checking): 엔티티의 스냅샷을 유지하면서 엔티티의 변경사항을 체크한다. update쿼리가 항상 같음. 지연로딩(Lazy Loading): 연관된 엔티티를 모두 불러오는 것이 아니라, 실제 호출될때 로딩되도록 지원(프록시 객체 사용) 엔티티 생명주기 New(Transient): new 로 생성만 된 상태로, 영속성 컨텍스트와 관련이 없는 엔티티1Customer customer = new Customer(); Managed(Persistent) : 영속성 컨테스트에서 관리되는 엔티티. 반드시 식별자를 갖는다.1entityManger.persist(customer); Detached: 영속성 컨텍스트에 존재하다가 분리된 엔티티. 식별자를 갖고 있다.123entityManger.detach(customer);entityManger.clear();entityManger.close(); Removed: 영속성 컨텍스트와 데이터베이스에서 삭제된 엔티티1entityManger.remove(customer); 엔티티 CRUD 엔티티 조회: em.find(entity) 로 영속성 컨텍스트 내의 1차 캐시에서 먼저 찾고 없으면 데이터베이스에서 조회.em.find를 통해 새로 DB에서 조회된 엔티티는 영속성 컨텍스트에서 관리한다. 1Customer customer = entityManger.find(Customer.class, &quot;cutomerId1&quot;); 엔티티 등록: em.persist(entity) 로 영속성 컨텍스트에 저장.트랜젝션 커밋 전까지 메모리에 SQL을 유지하며 쓰기 지연 후 커밋시 db에 일괄 반영한다. 123456// J2SE에서 트랜젝션 사용. Spring에서는 @Transaction 으로 트랜젝션 지정EntityTransaction tx = entityManger.getTransaction();tx.begin();entityManger.persist(newCustomer1); // 영속성 컨텍스트에 반영entityManger.persist(newCustomer2); // 영속성 컨텍스트에 반영. 여기까지 쓰기 지연 발생tx.commit(); // 데이터베이스에 반영 엔티티 수정: 엔티티 수정을 위한 별도의 API가 없다. 영속성 컨텍스트에서 엔티티의 스냅샷을 유지하며트랜젝션 커밋시 변경감지(dirty checking) 를 통해 수정된 엔티티의 UPDATE SQL 생성 후 반영 12Customer customer = entityManger.find(Customer.class, &quot;cutomerId1&quot;);customer.setName(&quot;new name&quot;); // 트랜젝션 커밋시 변경감지 후 반영 됨. 수정 쿼리를 작성하다보면, 이름만 변경하는 쿼리, 이름+나이를 변경하는 쿼리 등..요건에 따라 속성별로 수정하는 UPDATE SQL 문이 계속 추가된다.이 경우.. 스키마 변경시 수정할 쿼리도 많아질 뿐만 아니라..SQL이 비즈니스 로직에 종속될 뿐만 아니라, 데이터베이스에서 쿼리 재사용이 어렵다. 엔티티 삭제: em.remove(entity) 로 엔티티를 삭제.영속성 컨텍스트에서 바로 삭제되고, 트랜젝션 커밋 될때까지 쓰기 지연된다.삭제한 엔티티는 재사용하지 말고, JVM에의해 가비지컬랙션 되도록 한다. 12Customer customer = entityManger.find(Customer.class, &quot;cutomerId1&quot;);entityManger.remove(customer); // 트랜젝션 커밋시 반영됨.","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"(JPA - 1) JPA사용을 위한 환경 설정","slug":"JPA(Java ORM)/1. JPA-환경 설정","date":"2017-01-27T03:19:30.000Z","updated":"2021-08-17T00:04:32.685Z","comments":true,"path":"2017/01/27/JPA(Java ORM)/1. JPA-환경 설정/","link":"","permalink":"https://kihoonkim.github.io/2017/01/27/JPA(Java%20ORM)/1.%20JPA-%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95/","excerpt":"","text":"Spring boot + Spring Data JPA(하이버네이트)Spring Data JPA를 사용하면 JPA구현체로 Hibernate를 사용한다.Dependency를 따라가 보면 관련된 여러 라이브러리들이 추가되어 있는 것을 확인 할 수 있다. spring-orm: 스프링과 JPA를 연동하기 위한 라이브러리 hibernate-core hibernate-entitymanager: 하이버네이트가 JPA 구현체로 동작하도록 JPA 표준을 구현한 라이브러리 hibernate-jap-2.1: JPA2.1 표준 API 라이브러리. *javax.persistence.** 를 포함하고 있다. tomcat-jdbc: 커넥션 풀 12345678910# pom.xml&lt;dependencies&gt; ... &lt;!-- Spring Data JPA --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; ...&lt;/dependencies&gt; spring-data-jpa 및 hibernate 설정 및 속성 의미설정 방법src/main/resources 및에 application.properties 나application.yml 에 관련 속성을 설정하면 된다. 123456789101112131415161718192021# src/main/resources/application.ymlspring: datasource: dataSourceClassName: org.h2.jdbcx.JdbcDataSource url: jdbc:h2:mem:test;DB_CLOSE_DELAY=-1 username: password: jpa: database-platform: org.hibernate.dialect.H2Dialect database: H2 generate-ddl: false open-in-view: false show-sql: true hibernate: ddl-auto: validate naming-strategy: org.hibernate.cfg.EJB3NamingStrategy properties: hibernate.cache.use_second_level_cache: true hibernate.cache.use_query_cache: false hibernate.generate_statistics: true hibernate.cache.region.factory_class: org.hibernate.cache.ehcache.SingletonEhCacheRegionFactory 각 속성의 의미 spring.data.jpa.repositories.enabled=true # Enable JPA repositories. spring.jpa.database-platform= # Name of the target database to operate on, auto-detected by default. Can be alternatively set using the “Database” enum. spring.jpa.database= # Target database to operate on, auto-detected by default. Can be alternatively set using the “database-platform” property. spring.jpa.generate-ddl=false # Initialize the schema on startup. spring.jpa.open-in-view=true # Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request. spring.jpa.show-sql=false # Enable logging of SQL statements. spring.jpa.hibernate.ddl-auto= # DDL mode. This is actually a shortcut for the “hibernate.hbm2ddl.auto” property. Default to “create-drop” when using an embedded database, “none” otherwise. spring.jpa.hibernate.naming-strategy= # Naming strategy fully qualified name. spring.jpa.properties= # Additional native properties to set on the JPA provider.hibernate 상세 설정 참조 NOTE SpringBoot에서 환경설정 spring boot에서는 /src/main/resources 밑에 application.properties와 application.yml 설정을 자동으로 읽어들인다. Common application properties Using YAML instead of Properties","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"https://kihoonkim.github.io/tags/jpa/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"JPA","slug":"Java/JPA","permalink":"https://kihoonkim.github.io/categories/Java/JPA/"}]},{"title":"ELK Installation Guide v5","slug":"Elasticsearch/belk_v5","date":"2017-01-11T07:17:39.000Z","updated":"2021-08-17T00:04:32.685Z","comments":true,"path":"2017/01/11/Elasticsearch/belk_v5/","link":"","permalink":"https://kihoonkim.github.io/2017/01/11/Elasticsearch/belk_v5/","excerpt":"","text":"➜ mkdir elkstack➜ cd elkstack Elasticsearchinstall➜ curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.1.1.tar.gz➜ tar xzvf elasticsearch-5.1.1.tar.gz➜ cd elasticsearch-5.1.1 run➜ bin/elasticsearch testhttp://localhost:9200?pretty=true Kibanainstall➜ curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.1.1-darwin-x86_64.tar.gz➜ tar xzvf kibana-5.1.1-darwin-x86_64.tar.gz➜ cd kibana-5.1.1-darwin-x86_64 config➜ kibana-5.1.1-darwin-x86_64 vi config/kibana.yml 12(default)# elasticsearch.url: &quot;http://localhost:9200&quot; run➜ ./bin/kibana testhttp://localhost:5601 Logstashinstall➜ curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.1.1.tar.gz➜ tar xzvf logstash-5.1.1.tar.gz config➜ vi config/logstash.conf 1234567891011121314input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; sniffing =&gt; true manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; run➜ bin/logstash -f config/logstash.conf Filebeatinstall➜ curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.1.1-darwin-x86_64.tar.gz➜ tar xzvf filebeat-5.1.1-darwin-x86_64.tar.gz➜ cd filebeat-5.1.1-darwin-x86_64 filebeat.yml12345678910111213filebeat.prospectors:- input_type: log # Paths that should be crawled and fetched. Glob based paths. paths: - /tmp/*.log &lt;— Path변경#-------------------------- Elasticsearch output ------------------------------output.elasticsearch: # Array of hosts to connect to. #hosts: [&quot;localhost:9200&quot;] &lt;— 주석#----------------------------- Logstash output --------------------------------#output.logstash: # The Logstash hosts hosts: [&quot;localhost:5044&quot;] &lt;— 주석 해제 dynamic template 설정curl -XPUT ‘http://localhost:9200/_template/filebeat?pretty&#39; -d@filebeat.template.json 123&#123; &quot;acknowledged&quot; : true&#125; run➜ sudo ./filebeat -e -c filebeat.yml test➜ echo {“hello”:”world”} &gt; /tmp/mylog.log➜ echo {“hello”:”world”} &gt;&gt; /tmp/mylog.log","categories":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"ELK","slug":"DevTools/ELK","permalink":"https://kihoonkim.github.io/categories/DevTools/ELK/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://kihoonkim.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://kihoonkim.github.io/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://kihoonkim.github.io/tags/logstash/"},{"name":"filebeat","slug":"filebeat","permalink":"https://kihoonkim.github.io/tags/filebeat/"}],"keywords":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"ELK","slug":"DevTools/ELK","permalink":"https://kihoonkim.github.io/categories/DevTools/ELK/"}]},{"title":"Java 8 알아보기","slug":"functional_programming/java8","date":"2017-01-01T07:17:39.000Z","updated":"2021-08-17T00:04:32.697Z","comments":true,"path":"2017/01/01/functional_programming/java8/","link":"","permalink":"https://kihoonkim.github.io/2017/01/01/functional_programming/java8/","excerpt":"","text":"Java 8 알아보기덧셈 모듈을 만들어 주세요12345public class Calculator &#123; public int add(int a, int b) &#123; return a + b; &#125;&#125; 뺄셈 모듈도 만들어 주세요12345678public class Calculator &#123; public int add(int a, int b) &#123; return a + b; &#125; public int subtract(int a, int b) &#123; return a - b; &#125;&#125; 숫자 여러개 받을 수 있게 해주세요12345678910111213141516public class Calculator &#123; public int add(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; result += a; &#125; return result; &#125; public int subtract(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; result -= a; &#125; return result; &#125;&#125; 0 보다 작은 수가 입력된 경우엔 무시해 주세요123456789101112131415161718public class Calculator &#123; public int add(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; if(a &lt;= 0) continue; result += a; // (1) &#125; return result; &#125; public int subtract(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; if(a &lt;= 0) continue; result -= a; // (2) &#125; return result; &#125;&#125; 메소드 이름 과 (1) (2) 부분 빼고는 모두 중복 코드 Refactoring123456789101112131415161718192021public class Calculator &#123; private boolean isLessThanZero(int a)&#123; return a &lt;= 0; &#125; public int add(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; if(isLessThanZero(a)) continue; result += a; &#125; return result; &#125; public int subtract(int[] arrs) &#123; int result = 0; for(int a : arrs) &#123; if(isLessThanZero(a)) continue; result -= a; &#125; return result; &#125;&#125; 그래도 중복은 여전하네..익명 클래스를 사용해서 실제 계산하는 부분만 처리하자 Refactoring continue..123456789101112131415161718192021222324252627282930313233343536public class Calculator &#123; interface Operator &#123; int operate(int a, int b); &#125; private boolean isGreaterThanZero(int a)&#123; return a &lt;= 0; &#125; private List&lt;Integer&gt; getOnlyNaturalnumbers(int[] arrs)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int a : arrs) &#123; if(isGreaterThanZero(a)) list.add(a); &#125; return list; &#125; private int calcuate(List&lt;Integer&gt; arrs, Operator opt) &#123; int result = 0; for(int a : arrs) &#123; result = opt.operate(result, a); &#125; return result; &#125; public int add(int[] arrs) &#123; return calcuate(getOnlyNaturalnumbers(arrs), new Operator() &#123; public int operate(int a, int b) &#123; return a + b; &#125; &#125;); &#125; public int subtract(int[] arrs) &#123; return calcuate(getOnlyNaturalnumbers(arrs), new Operator() &#123; public int operate(int a, int b) &#123; return a - b; &#125; &#125;); &#125;&#125; 곱셈, 나눗셈이 추가되더라도..12345678910111213141516...public int multiply(int[] arrs) &#123; return calcuate(getOnlyNaturalnumbers(arrs), new Operator() &#123; public int operate(int a, int b) &#123; return a * b; &#125; &#125;);&#125;public int divide(int[] arrs) &#123; return calcuate(getOnlyNaturalnumbers(arrs), new Operator() &#123; public int operate(int a, int b) &#123; return a / b; &#125; &#125;);&#125;... 이름을 좀 바꿔 볼까요123456789101112131415161718192021222324252627282930313233343536public class Calculator &#123; interface Function &#123; int apply(int a, int b); &#125; private boolean isGreaterThanZero(int a)&#123; return a &lt;= 0; &#125; private List&lt;Integer&gt; filter(int[] arrs)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int a : arrs) &#123; if(isGreaterThanZero(a)) list.add(a); &#125; return list; &#125; private int calcuate(List&lt;Integer&gt; arrs, Function opt) &#123; int result = 0; for(int a : arrs) &#123; result = opt.apply(result, a); &#125; return result; &#125; public int add(int[] arrs) &#123; return calcuate(filter(arrs), new Function() &#123; public int apply(int a, int b) &#123; return a + b; &#125; &#125;); &#125; public int subtract(int[] arrs) &#123; return calcuate(filter(arrs), new Function() &#123; public int apply(int a, int b) &#123; return a - b; &#125; &#125;); &#125;&#125; Java8 Stream API와 Lambda 로 바꿔 볼까요123456789101112131415public class Calculator &#123; private Predicate&lt;Integer&gt; ltzero = a -&gt; a &lt;= 0; public int add(List&lt;Integer&gt; arrs) &#123; return arrs.stream().filter(ltzero).reduce((a, b) -&gt; a + b).get(); &#125; public int subtract(List&lt;Integer&gt; arrs) &#123; return arrs.stream().filter(ltzero).reduce((a, b) -&gt; a - b).get(); &#125; public int multiply(List&lt;Integer&gt; arrs) &#123; return arrs.stream().filter(ltzero).reduce((a, b) -&gt; a * b).get(); &#125; public int divide(List&lt;Integer&gt; arrs) &#123; return arrs.stream().filter(ltzero).reduce((a, b) -&gt; a / b).get(); &#125;&#125; Java8 에 대한 자세한 내용은..http://www.slideshare.net/gyumee/java-8-lambda-35352385http://www.slideshare.net/gyumee/8-37599530","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}],"tags":[{"name":"java 8","slug":"java-8","permalink":"https://kihoonkim.github.io/tags/java-8/"},{"name":"FP","slug":"FP","permalink":"https://kihoonkim.github.io/tags/FP/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}]},{"title":"FP 주요 용어","slug":"functional_programming/fp_용어정리","date":"2016-12-31T07:17:39.000Z","updated":"2021-08-17T00:04:32.696Z","comments":true,"path":"2016/12/31/functional_programming/fp_용어정리/","link":"","permalink":"https://kihoonkim.github.io/2016/12/31/functional_programming/fp_%EC%9A%A9%EC%96%B4%EC%A0%95%EB%A6%AC/","excerpt":"","text":"Functional ProgrammingStateOOP makes code understandable by encapsulating moving partFP makes code understandable by minimizing moving part. FP is programming without assignment statements. 절차보다는 결과에 집중 명령형 처리 : 상태 를 변경하는 일련의 명령들로 구성된 프로그래밍 방식 상태관리를 개발자가 아닌 언어/런타임이 하도록 한다 Pure Functionside effect가 없는 함수 -&gt; 쓰레드에 안전, 병렬적 수행 가능 First class Function 변수에 할당 가능 인자로 전달 가능 반환값으로 전달 가능 런다임 생성 가능 익명으로 생성 가능 High order Function함수를 다루는 함수. filter : Collection의 부분 집합 구할때 map : Collection의 그자리의 값을 변형 할때 fold / reduce : Collection의 요소들을 처리하여 다른 길이의 결과를 원할때 Closure (enclosing context)내부에 참조되는 모든 인수에 대한 암묵적인 바인딩을 지닌 함수즉, 자신이 참조하는 것들의 context를 포함 Memoization반복해서 사용되는 연산 값을 함수 레벨에서 캐시하는 것캐싱가능하려면 pure function 이어야 됨trade-off : 성능 vs 메모리 Lazy evaluation (strict vs nonstrict)무한 컬렉션을 전달 할 수 있을까?연산을 미리 하는 것이 아니라, 필요한 시점에 연산 커링(curring)multiple agrument 함수를 single agrument 함수들의 chain으로 변경하는 것process(x, y, z) –&gt; process(x)(y)(z) 부분 적용 (partial application)몇몇 인수에 미리 값을 적용하고 나머지 인수만 받는 함수를 리턴process(1,2,z) –&gt; prc(z) Recursion상태관리를 런타임에게 양도 참조 투명성 (referentially transpprent)표현식을 그 결과로 치환해도 프로그램에 아무 영향이 없다면 참조에 투명하다 코드 재사용100개의 함수를 하나의 자료구조에 적용하는 것이10개의 함수를 10개의 자료구조에 적용하는 것보다 낫다 주요 자료구조(list, set, map)와 거기에 최적화된 연산을 선호 오류 처리예외 발생은 side effect를 발생함수형 언어들은 주로 값을 처리하기 때문에 흐름을 막기보다는 오류를 나타내는 리턴 값에 반응","categories":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}],"tags":[{"name":"FP","slug":"FP","permalink":"https://kihoonkim.github.io/tags/FP/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://kihoonkim.github.io/categories/Java/"},{"name":"Java8","slug":"Java/Java8","permalink":"https://kihoonkim.github.io/categories/Java/Java8/"}]},{"title":"ELK Installation Guide v2","slug":"Elasticsearch/Install Beat-Logstash-Elasticsearch-Kibana","date":"2016-01-20T07:17:39.000Z","updated":"2021-08-17T00:04:32.685Z","comments":true,"path":"2016/01/20/Elasticsearch/Install Beat-Logstash-Elasticsearch-Kibana/","link":"","permalink":"https://kihoonkim.github.io/2016/01/20/Elasticsearch/Install%20Beat-Logstash-Elasticsearch-Kibana/","excerpt":"","text":"E(B)LK Installation Guide Log Collection : [log file] -&gt; [file beat] —–&gt; [logstash] -&gt; [elasticseach] Visualization : [Kibana] -&gt; [elasticseach] �����غ�12# JDK &amp; JAVA_HOME$ sudo apt-get install openjdk-7-jre Elasticsearch ��ġ Download and unzip the latest Elasticsearch distribution : Elasticsearch 2.0.0 12$ curl -L -O https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.0.0/elasticsearch-2.0.0.tar.gz$ tar xzvf elasticsearch-2.0.0.tar.gz Run 1$ bin/elasticsearch Test 1http://localhost:9200?pretty=true Kibana Installation Download and unzip Kibana 4.X : Kibana 4.2.1 123$ curl -L -O https://download.elastic.co/kibana/kibana/kibana-4.2.1-linux-x64.tar.gz$ tar xzvf kibana-4.2.1-linux-x64.tar.gz$ cd kibana-4.2.1-linux-x64/ edit config/kibana.yml 12(default)# elasticsearch.url: &quot;http://localhost:9200&quot; Run 1./bin/kibana Test 1http://localhost:5601 Logstash(Log Aggregation) ��ġ Download and unzip the latest Logstash release : Logstash 2.0.0 12$ curl -L -O https://download.elastic.co/logstash/logstash/logstash-2.0.0.tar.gz$ tar xzvf logstash-2.0.0.tar.gz create a config file 123456789101112131415# config/logstash.confinput &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; sniffing =&gt; true manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; plugin updates 1234$ ./plugin update logstash-input-beatsor$ ./plugin uninstall logstash-input-beats$ ./plugin install logstash-input-beats Run 1$ ./logstash agent -f ../config/logstash.conf Filebeat(Log forwarder) ��ġ Download and install or unzip Filebeat : Filebeat 1.0.0 12$ curl -L -O https://download.elastic.co/beats/filebeat/filebeat-1.0.0-rc2-x86_64.tar.gz$ sudo tar xzvf filebeat-1.0.0-rc2-x86_64.tar.gz Edit the filebeat.yml 12345678910111213#filebeat.yml... prospectors: ... paths: - /tmp/*.log ... output: #elasticsearch: #hosts: [&quot;localhost:9200&quot;] ... logstash: hosts: [&quot;localhost:5044&quot;] dynamic template ���� : filebeat.template.json 1$ curl -XPUT &#x27;http://localhost:9200/_template/filebeat?pretty&#x27; -d@filebeat.template.json Run 1$ sudo ./filebeat -e -c filebeat.yml Test 1$ echo &#123;&quot;hello&quot;:&quot;world&quot;&#125; &gt; /tmp/mylog.log","categories":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"ELK","slug":"DevTools/ELK","permalink":"https://kihoonkim.github.io/categories/DevTools/ELK/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://kihoonkim.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://kihoonkim.github.io/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://kihoonkim.github.io/tags/logstash/"},{"name":"filebeat","slug":"filebeat","permalink":"https://kihoonkim.github.io/tags/filebeat/"}],"keywords":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"ELK","slug":"DevTools/ELK","permalink":"https://kihoonkim.github.io/categories/DevTools/ELK/"}]},{"title":"Docker Commands","slug":"Docker/Docker Commands","date":"2016-01-20T07:16:39.000Z","updated":"2021-08-17T00:04:32.684Z","comments":true,"path":"2016/01/20/Docker/Docker Commands/","link":"","permalink":"https://kihoonkim.github.io/2016/01/20/Docker/Docker%20Commands/","excerpt":"","text":"search image12docker search ubuntudocker search mongo pull image1docker pull mongo image 목록 보기1docker images image를 container로 실행123docker run --name mgdb mongodocker ps -adocker rm mgdb 실행중인 container에 접속123456docker run -d --name mgdb mongodocker psdocker logs -f mgdbdocker attach mgdbdocker start mgdbdocker exec mgdb echo &quot;test&quot; dockerfile 만들기1vi dockerfile 12345FROM java:openjdk-8u45-jdkMAINTAINER koreakihoon@gmail.comADD user-0.0.1-SNAPSHOT.jar .CMD java -jar user-0.0.1-SNAPSHOT.jarEXPOSE 8081 dockerfile로 image 만들기12docker build -t user_svc .docker images container link12docker run -d -p 8081:8081 --link mgdb:mgdb --name user_svc user_svcdocker ps container 중지 및 삭제12docker stop user_svc mgdbdocker rm user_svc mgdb image 삭제12docker rmi user_svcdocker rmi mongo docker compose 설정1vi docker-compose.yml 12345678users: buaild: . ports: - &quot;8081:8081&quot; links: - mgdbmgdb: image: mongo docker compose로 실행123docker-compose updocker imagesdocker ps","categories":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"Docker","slug":"DevTools/Docker","permalink":"https://kihoonkim.github.io/categories/DevTools/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://kihoonkim.github.io/tags/docker/"}],"keywords":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"Docker","slug":"DevTools/Docker","permalink":"https://kihoonkim.github.io/categories/DevTools/Docker/"}]},{"title":"Docker 소개","slug":"Docker/docker_소개","date":"2015-07-29T13:06:39.000Z","updated":"2021-08-17T00:04:32.684Z","comments":true,"path":"2015/07/29/Docker/docker_소개/","link":"","permalink":"https://kihoonkim.github.io/2015/07/29/Docker/docker_%EC%86%8C%EA%B0%9C/","excerpt":"","text":"Docker 소개 Slide","categories":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"Docker","slug":"DevTools/Docker","permalink":"https://kihoonkim.github.io/categories/DevTools/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://kihoonkim.github.io/tags/docker/"}],"keywords":[{"name":"DevTools","slug":"DevTools","permalink":"https://kihoonkim.github.io/categories/DevTools/"},{"name":"Docker","slug":"DevTools/Docker","permalink":"https://kihoonkim.github.io/categories/DevTools/Docker/"}]}]}